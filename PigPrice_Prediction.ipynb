{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bed5b46",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68d65696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T04:41:26.004985Z",
     "start_time": "2023-06-30T04:41:25.973526Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61bc3d",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e6db94",
   "metadata": {},
   "source": [
    "## Data Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc602d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T04:41:43.080114Z",
     "start_time": "2023-06-30T04:41:43.010889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date  Hog prices  Piglet price  Pig inventory  Breeding cost  \\\n",
      "0  2009-02     12.5550        20.202          44594         4987.0   \n",
      "1  2009-03     11.6275        19.862          44861         4942.0   \n",
      "2  2009-04     10.4680        18.274          45489         4922.0   \n",
      "3  2009-05      9.7275        15.500          45325         4880.0   \n",
      "4  2009-06      9.9900        15.184          44720         4832.0   \n",
      "\n",
      "   Sow inventory  Slaughtering quantity   Corn price  Soybean meal price  \\\n",
      "0       1016.285                 1259.3  1483.971000         3170.550000   \n",
      "1       1040.105                 1562.8  1566.604091         3026.863636   \n",
      "2       1030.886                 1672.5  1596.388095         3212.714286   \n",
      "3        993.740                 1717.5  1604.325882         3194.705882   \n",
      "4        999.050                 1741.5  1614.331818         3407.727273   \n",
      "\n",
      "   Disposable income of urban residents  White chicken price  Beef price  \\\n",
      "0                           1408.416667              16.1175   33.725100   \n",
      "1                           1408.416667              16.1175   33.104880   \n",
      "2                           1408.416667              16.1075   32.773150   \n",
      "3                           1408.416667              16.0360   32.601775   \n",
      "4                           1408.416667              15.9425   32.492775   \n",
      "\n",
      "   Baidu search index      M2  Total retail sales  Shenwan idex  \n",
      "0                 662  506708              9323.8       2086.15  \n",
      "1                1000  530627              9317.6       1881.78  \n",
      "2                 771  540481              9343.2       2179.89  \n",
      "3                1414  548264             10028.4       2061.27  \n",
      "4                2085  568916              9941.6       2123.11  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 151 entries, 0 to 150\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   date                                  151 non-null    object \n",
      " 1   Hog prices                            151 non-null    float64\n",
      " 2   Piglet price                          151 non-null    float64\n",
      " 3   Pig inventory                         151 non-null    int64  \n",
      " 4   Breeding cost                         151 non-null    float64\n",
      " 5   Sow inventory                         151 non-null    float64\n",
      " 6   Slaughtering quantity                 151 non-null    float64\n",
      " 7   Corn price                            151 non-null    float64\n",
      " 8   Soybean meal price                    151 non-null    float64\n",
      " 9   Disposable income of urban residents  151 non-null    float64\n",
      " 10  White chicken price                   151 non-null    float64\n",
      " 11  Beef price                            151 non-null    float64\n",
      " 12  Baidu search index                    151 non-null    int64  \n",
      " 13  M2                                    151 non-null    int64  \n",
      " 14  Total retail sales                    151 non-null    float64\n",
      " 15  Shenwan idex                          151 non-null    float64\n",
      "dtypes: float64(12), int64(3), object(1)\n",
      "memory usage: 19.0+ KB\n",
      "Empty DataFrame\n",
      "Columns: [Number_missing, Percentage_missing]\n",
      "Index: [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"D:/data/pig_price_raw.csv\")\n",
    "# 修改列名\n",
    "raw_data = raw_data.rename(columns={'时间':'date','生猪价格': 'Hog prices', '仔猪价格': 'Piglet price','生猪存栏': 'Pig inventory', '能繁母猪存栏': 'Breeding cost','养殖成本': 'Sow inventory',\n",
    "                              '规模以上生猪定点屠宰企业屠宰量': 'Slaughtering quantity','玉米价格': 'Corn price','豆粕价格': 'Soybean meal price','城镇居民可支配收入': 'Disposable income of urban residents',\n",
    "                              '白条鸡价格': 'White chicken price','牛肉价格': 'Beef price','百度搜索指数': 'Baidu search index','M2': 'M2','社会消费品零售总额': 'Total retail sales','申万行业指数——生猪养殖': 'Shenwan idex' })\n",
    "\n",
    "#修改date列\n",
    "\n",
    "# 将 'date' 列中的字符串解析为日期对象\n",
    "raw_data['date'] = pd.to_datetime(raw_data['date'], format='%Y年%m月')\n",
    "\n",
    "# 将日期对象转换为字符串格式，按照 'xx-xx' 形式重新赋值给 'date' 列\n",
    "raw_data['date'] = raw_data['date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# 显示修改后的DataFrame\n",
    "print(raw_data .head())\n",
    "raw_data.info()\n",
    "raw_data.duplicated().sum()\n",
    "\n",
    "#缺失值可视化\n",
    "import missingno as miss\n",
    "import fancyimpute as fan\n",
    "na_cols=raw_data.columns[raw_data.isna().any()].tolist()\n",
    "mv=pd.DataFrame(raw_data[na_cols].isna().sum(), columns=['Number_missing'])\n",
    "mv['Percentage_missing']=np.round(100*mv['Number_missing']/len(raw_data),2)\n",
    "print(mv, '\\n')\n",
    "# miss.heatmap(raw_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97787335",
   "metadata": {},
   "source": [
    "## Optimize data set structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b1ccdb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T04:41:45.618790Z",
     "start_time": "2023-06-30T04:41:45.589779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Hog prices  Piglet price  Pig inventory  Breeding cost  \\\n",
      "2009-02   12.555000     20.202000          44594    4987.000000   \n",
      "2009-03   11.627500     19.862000          44861    4942.000000   \n",
      "2009-04   10.468000     18.274000          45489    4922.000000   \n",
      "2009-05    9.727500     15.500000          45325    4880.000000   \n",
      "2009-06    9.990000     15.184000          44720    4832.000000   \n",
      "...             ...           ...            ...            ...   \n",
      "2021-04   23.330495     82.212273          43911    4365.498000   \n",
      "2021-05   18.854412     61.561579          43911    4400.421984   \n",
      "2021-06   14.720000     38.170000          43911    4564.000000   \n",
      "2021-07   15.820000     25.640000          43764    4541.000000   \n",
      "2021-08   14.650000     24.200000          43764    4500.000000   \n",
      "\n",
      "         Sow inventory  Slaughtering quantity   Corn price  \\\n",
      "2009-02       1016.285                1259.30  1483.971000   \n",
      "2009-03       1040.105                1562.80  1566.604091   \n",
      "2009-04       1030.886                1672.50  1596.388095   \n",
      "2009-05        993.740                1717.50  1604.325882   \n",
      "2009-06        999.050                1741.50  1614.331818   \n",
      "...                ...                    ...          ...   \n",
      "2021-04       2699.230                1804.53  2849.137273   \n",
      "2021-05       2687.165                1995.65  2906.538421   \n",
      "2021-06       2734.670                2200.00  2860.030000   \n",
      "2021-07       2895.080                2195.00  2825.060000   \n",
      "2021-08       2630.540                2329.00  2810.930000   \n",
      "\n",
      "         Soybean meal price  Disposable income of urban residents  \\\n",
      "2009-02         3170.550000                           1408.416667   \n",
      "2009-03         3026.863636                           1408.416667   \n",
      "2009-04         3212.714286                           1408.416667   \n",
      "2009-05         3194.705882                           1408.416667   \n",
      "2009-06         3407.727273                           1408.416667   \n",
      "...                     ...                                   ...   \n",
      "2021-04         3466.666500                           3668.333333   \n",
      "2021-05         3629.780526                           3668.333333   \n",
      "2021-06         3554.240000                           3668.333333   \n",
      "2021-07         3624.980000                           3940.333333   \n",
      "2021-08         3695.620000                           3940.333333   \n",
      "\n",
      "         White chicken price  Beef price  Baidu search index       M2  \\\n",
      "2009-02              16.1175   33.725100                 662   506708   \n",
      "2009-03              16.1175   33.104880                1000   530627   \n",
      "2009-04              16.1075   32.773150                 771   540481   \n",
      "2009-05              16.0360   32.601775                1414   548264   \n",
      "2009-06              15.9425   32.492775                2085   568916   \n",
      "...                      ...         ...                 ...      ...   \n",
      "2021-04              17.0400   86.766667                2807  2262110   \n",
      "2021-05              16.4475   86.205000                2285  2275540   \n",
      "2021-06              16.4300   85.330000                3325  2317790   \n",
      "2021-07              15.9600   84.920000                2048  2302150   \n",
      "2021-08              16.1100   85.120000                1782  2312270   \n",
      "\n",
      "         Total retail sales  Shenwan idex  num  \n",
      "2009-02              9323.8       2086.15    1  \n",
      "2009-03              9317.6       1881.78    2  \n",
      "2009-04              9343.2       2179.89    3  \n",
      "2009-05             10028.4       2061.27    4  \n",
      "2009-06              9941.6       2123.11    5  \n",
      "...                     ...           ...  ...  \n",
      "2021-04             33152.6       8553.05  147  \n",
      "2021-05             35945.1       8020.15  148  \n",
      "2021-06             37585.8       8020.15  149  \n",
      "2021-07             34925.1       6704.61  150  \n",
      "2021-08             34394.9       5990.75  151  \n",
      "\n",
      "[151 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "factors = ['Hog prices', 'Piglet price', 'Pig inventory', 'Breeding cost',\n",
    "       'Sow inventory', 'Slaughtering quantity', 'Corn price',\n",
    "       'Soybean meal price', 'Disposable income of urban residents',\n",
    "       'White chicken price', 'Beef price', 'Baidu search index', 'M2',\n",
    "       'Total retail sales', 'Shenwan idex','num']\n",
    "\n",
    "\n",
    "raw_data['num'] = list(range(1, len(raw_data) + 1))\n",
    "\n",
    "data = np.array(raw_data)\n",
    "\n",
    "final_data=pd.DataFrame(data=data[:,1:],index=data[:,0],columns=factors)\n",
    "final_data = final_data.apply(pd.to_numeric, errors='coerce')\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68e93c88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T05:31:40.037039Z",
     "start_time": "2023-06-30T05:31:39.465743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import datestr2num,DateFormatter\n",
    "\n",
    "# 获取除num列外的所有列名\n",
    "columns = final_data.columns.tolist()\n",
    "columns.remove('num')\n",
    "\n",
    "# 创建子图\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 遍历每个列名，并绘制折线图\n",
    "for i, column in enumerate(columns):\n",
    "    if column == 'Hog prices':\n",
    "        # 如果是price列，使用较深的颜色进行突出显示\n",
    "        ax.plot(final_data['num'], final_data[column], label=column, color='red')\n",
    "    else:\n",
    "        # 对于其他列，使用较淡的颜色\n",
    "        color = f'C{i}'  # 根据索引i选择不同的颜色\n",
    "        ax.plot(final_data['num'], final_data[column], label=column, color=color, alpha=0.5)\n",
    "\n",
    "# 设置x轴日期格式\n",
    "date_ticks = ['2009-02', '2021-08']\n",
    "date_num = datestr2num(date_ticks)\n",
    "date_formatter = DateFormatter('%Y-%m')\n",
    "ax.xaxis.set_major_locator(plt.FixedLocator(date_num))\n",
    "ax.xaxis.set_major_formatter(date_formatter)\n",
    "\n",
    "# 设置图形属性\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('Value')\n",
    "ax.set_title('Line plot of Data Columns')\n",
    "ax.legend()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186973d",
   "metadata": {},
   "source": [
    "## Data standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51d3e15b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T04:41:48.831774Z",
     "start_time": "2023-06-30T04:41:48.806053Z"
    }
   },
   "outputs": [],
   "source": [
    "#先标准化和后标准化选择的特征变量结果一致\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 选择除了 \"num\" 列以外的数据列\n",
    "data_columns = final_data.columns.drop(\"num\")\n",
    "data = final_data[data_columns]\n",
    "\n",
    "# 使用 StandardScaler 对数据进行标准化\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# 将标准化后的数据替换原始数据中除了 \"num\" 列以外的数据\n",
    "final_data[data_columns] = scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812258fe",
   "metadata": {},
   "source": [
    "## Feature extraction, feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92f6fb90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T04:41:50.706879Z",
     "start_time": "2023-06-30T04:41:50.638779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "被选择的特征列:\n",
      "Pig inventory\n",
      "Breeding cost\n",
      "Sow inventory\n",
      "Disposable income of urban residents\n",
      "Beef price\n",
      "M2\n",
      "Total retail sales\n"
     ]
    }
   ],
   "source": [
    "#使用滞后期，选择7个\n",
    "# 按照滞后期和预测步长进行特征提取\n",
    "lag = 12\n",
    "prediction_step = 12\n",
    "\n",
    "# 提取特征列和目标变量列\n",
    "X = final_data.drop(['Hog prices','num'], axis=1)\n",
    "y = final_data['Hog prices']\n",
    "\n",
    "# 滞后期处理\n",
    "X_lagged = X.shift(lag)\n",
    "y_lagged = y.shift(-prediction_step)\n",
    "\n",
    "# 去除滞后期导致的缺失值\n",
    "X_lagged = X_lagged.iloc[:-prediction_step]\n",
    "y_lagged = y_lagged.iloc[:-prediction_step]\n",
    "# 去除滞后期导致的缺失值\n",
    "X_lagged_dropna = X_lagged.dropna().reset_index(drop=True)\n",
    "y_lagged_dropna = y_lagged.dropna().reset_index(drop=True)\n",
    "\n",
    "# 重新设置索引\n",
    "y_lagged_dropna = y_lagged_dropna.reindex(X_lagged_dropna.index)\n",
    "\n",
    "assert X_lagged_dropna.shape[0] == y_lagged_dropna.shape[0]\n",
    "\n",
    "# 进行特征选择\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k=7)  # 选择前7个特征\n",
    "X_selected = selector.fit_transform(X_lagged_dropna, y_lagged_dropna)\n",
    "\n",
    "selected_columns = X.columns[selector.get_support()]\n",
    "print(\"被选择的特征列:\")\n",
    "for column in selected_columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d55910f",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37cf77ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T04:43:41.320275Z",
     "start_time": "2023-06-30T04:43:41.304390Z"
    }
   },
   "outputs": [],
   "source": [
    "#构造X集，无滞后期\n",
    "X_selected_columns = ['Pig inventory', 'Breeding cost', 'Sow inventory', 'Disposable income of urban residents', 'Beef price', 'M2', 'Total retail sales', 'num']\n",
    "final_data_feature_lag = final_data[selected_columns]\n",
    "\n",
    "\n",
    "#构造Y集\n",
    "y_selected_columns = ['Hog prices']\n",
    "final_data_feature_lag = final_data[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "162abd55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T08:13:01.020911Z",
     "start_time": "2023-07-01T08:13:00.988881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Pig inventory  Breeding cost  Sow inventory  \\\n",
      "2009-02       0.721782       1.036882      -1.034265   \n",
      "2009-03       0.759559       0.984301      -0.987471   \n",
      "2009-04       0.848412       0.960932      -1.005582   \n",
      "2009-05       0.825209       0.911856      -1.078554   \n",
      "2009-06       0.739609       0.855770      -1.068123   \n",
      "...                ...            ...            ...   \n",
      "2021-04       0.625146       0.310681       2.271857   \n",
      "2021-05       0.625146       0.351488       2.248155   \n",
      "2021-06       0.625146       0.542623       2.341478   \n",
      "2021-07       0.604348       0.515748       2.656602   \n",
      "2021-08       0.604348       0.467841       2.136916   \n",
      "\n",
      "         Disposable income of urban residents  Beef price        M2  \\\n",
      "2009-02                             -1.515185   -1.510606 -1.601250   \n",
      "2009-03                             -1.515185   -1.548264 -1.555362   \n",
      "2009-04                             -1.515185   -1.568406 -1.536457   \n",
      "2009-05                             -1.515185   -1.578812 -1.521526   \n",
      "2009-06                             -1.515185   -1.585430 -1.481905   \n",
      "...                                       ...         ...       ...   \n",
      "2021-04                              1.339532    1.709927  1.766473   \n",
      "2021-05                              1.339532    1.675824  1.792239   \n",
      "2021-06                              1.339532    1.622697  1.873295   \n",
      "2021-07                              1.683121    1.597803  1.843290   \n",
      "2021-08                              1.683121    1.609946  1.862705   \n",
      "\n",
      "         Total retail sales  \n",
      "2009-02           -1.734488  \n",
      "2009-03           -1.735214  \n",
      "2009-04           -1.732219  \n",
      "2009-05           -1.652068  \n",
      "2009-06           -1.662222  \n",
      "...                     ...  \n",
      "2021-04            1.052864  \n",
      "2021-05            1.379515  \n",
      "2021-06            1.571434  \n",
      "2021-07            1.260201  \n",
      "2021-08            1.198181  \n",
      "\n",
      "[151 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(final_data_feature_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "50de420f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T10:40:11.961924Z",
     "start_time": "2023-07-01T10:40:11.901000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "         Pig inventory  Breeding cost  Sow inventory  \\\n",
      "2010-02       0.684429       0.923541      -0.818751   \n",
      "2010-03       0.656132       0.865118      -0.845806   \n",
      "2010-04       0.581144       0.771641      -0.842909   \n",
      "2010-05       0.548602       0.701534      -0.812823   \n",
      "2010-06       0.591048       0.678164      -0.789912   \n",
      "...                ...            ...            ...   \n",
      "2021-04       0.625146       0.310681       2.271857   \n",
      "2021-05       0.625146       0.351488       2.248155   \n",
      "2021-06       0.625146       0.542623       2.341478   \n",
      "2021-07       0.604348       0.515748       2.656602   \n",
      "2021-08       0.604348       0.467841       2.136916   \n",
      "\n",
      "         Disposable income of urban residents  Beef price        M2  \\\n",
      "2010-02                             -1.317495   -1.463860 -1.353067   \n",
      "2010-03                             -1.317495   -1.502659 -1.326448   \n",
      "2010-04                             -1.317495   -1.527613 -1.313759   \n",
      "2010-05                             -1.317495   -1.540212 -1.300732   \n",
      "2010-06                             -1.317495   -1.544759 -1.280452   \n",
      "...                                       ...         ...       ...   \n",
      "2021-04                              1.339532    1.709927  1.766473   \n",
      "2021-05                              1.339532    1.675824  1.792239   \n",
      "2021-06                              1.339532    1.622697  1.873295   \n",
      "2021-07                              1.683121    1.597803  1.843290   \n",
      "2021-08                              1.683121    1.609946  1.862705   \n",
      "\n",
      "         Total retail sales  Pig inventory_lag1  Pig inventory_lag2  \\\n",
      "2010-02           -1.382350            0.849969            1.048050   \n",
      "2010-03           -1.500786            0.684429            0.849969   \n",
      "2010-04           -1.478713            0.656132            0.684429   \n",
      "2010-05           -1.368212            0.581144            0.656132   \n",
      "2010-06           -1.382853            0.548602            0.581144   \n",
      "...                     ...                 ...                 ...   \n",
      "2021-04            1.052864            0.297463            0.297463   \n",
      "2021-05            1.379515            0.625146            0.297463   \n",
      "2021-06            1.571434            0.625146            0.625146   \n",
      "2021-07            1.260201            0.625146            0.625146   \n",
      "2021-08            1.198181            0.604348            0.625146   \n",
      "\n",
      "         Pig inventory_lag3  ...  Total retail sales_lag4  \\\n",
      "2010-02            1.004189  ...                -1.454476   \n",
      "2010-03            1.048050  ...                -1.498762   \n",
      "2010-04            0.849969  ...                -1.350088   \n",
      "2010-05            0.684429  ...                -1.337443   \n",
      "2010-06            0.656132  ...                -1.382350   \n",
      "...                     ...  ...                      ...   \n",
      "2021-04            0.297463  ...                 1.920040   \n",
      "2021-05            0.297463  ...                 1.622815   \n",
      "2021-06            0.297463  ...                 1.622815   \n",
      "2021-07            0.625146  ...                 1.325589   \n",
      "2021-08            0.625146  ...                 1.052864   \n",
      "\n",
      "         Total retail sales_lag5  Total retail sales_lag6  \\\n",
      "2010-02                -1.548617                -1.641868   \n",
      "2010-03                -1.454476                -1.548617   \n",
      "2010-04                -1.498762                -1.454476   \n",
      "2010-05                -1.350088                -1.498762   \n",
      "2010-06                -1.337443                -1.350088   \n",
      "...                          ...                      ...   \n",
      "2021-04                 1.797007                 1.687320   \n",
      "2021-05                 1.920040                 1.797007   \n",
      "2021-06                 1.622815                 1.920040   \n",
      "2021-07                 1.622815                 1.622815   \n",
      "2021-08                 1.325589                 1.622815   \n",
      "\n",
      "         Total retail sales_lag7  Total retail sales_lag8  \\\n",
      "2010-02                -1.662818                -1.662222   \n",
      "2010-03                -1.641868                -1.662818   \n",
      "2010-04                -1.548617                -1.641868   \n",
      "2010-05                -1.454476                -1.548617   \n",
      "2010-06                -1.498762                -1.454476   \n",
      "...                          ...                      ...   \n",
      "2021-04                 1.303435                 1.101760   \n",
      "2021-05                 1.687320                 1.303435   \n",
      "2021-06                 1.797007                 1.687320   \n",
      "2021-07                 1.920040                 1.797007   \n",
      "2021-08                 1.622815                 1.920040   \n",
      "\n",
      "         Total retail sales_lag9  Total retail sales_lag10  \\\n",
      "2010-02                -1.652068                 -1.732219   \n",
      "2010-03                -1.662222                 -1.652068   \n",
      "2010-04                -1.662818                 -1.662222   \n",
      "2010-05                -1.641868                 -1.662818   \n",
      "2010-06                -1.548617                 -1.641868   \n",
      "...                          ...                       ...   \n",
      "2021-04                 0.941727                  1.096531   \n",
      "2021-05                 1.101760                  0.941727   \n",
      "2021-06                 1.303435                  1.101760   \n",
      "2021-07                 1.687320                  1.303435   \n",
      "2021-08                 1.797007                  1.687320   \n",
      "\n",
      "         Total retail sales_lag11  Total retail sales_lag12  num  \n",
      "2010-02                 -1.735214                 -1.734488   13  \n",
      "2010-03                 -1.732219                 -1.735214   14  \n",
      "2010-04                 -1.652068                 -1.732219   15  \n",
      "2010-05                 -1.662222                 -1.652068   16  \n",
      "2010-06                 -1.662818                 -1.662222   17  \n",
      "...                           ...                       ...  ...  \n",
      "2021-04                  0.914858                  0.470942  147  \n",
      "2021-05                  1.096531                  0.914858  148  \n",
      "2021-06                  0.941727                  1.096531  149  \n",
      "2021-07                  1.101760                  0.941727  150  \n",
      "2021-08                  1.303435                  1.101760  151  \n",
      "\n",
      "[139 rows x 92 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3149922603.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_final_data_feature_lag12[f\"{col}_lag{i}\"] = X_final_data_feature_lag12[col].shift(i)\n",
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3149922603.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_final_data_feature_lag12[f\"{col}_lag{i}\"] = X_final_data_feature_lag12[col].shift(i)\n",
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3149922603.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_final_data_feature_lag12[f\"{col}_lag{i}\"] = X_final_data_feature_lag12[col].shift(i)\n",
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3149922603.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_final_data_feature_lag12[f\"{col}_lag{i}\"] = X_final_data_feature_lag12[col].shift(i)\n",
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3149922603.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_final_data_feature_lag12[f\"{col}_lag{i}\"] = X_final_data_feature_lag12[col].shift(i)\n",
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3149922603.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_final_data_feature_lag12[f\"{col}_lag{i}\"] = X_final_data_feature_lag12[col].shift(i)\n",
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3149922603.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_final_data_feature_lag12[f\"{col}_lag{i}\"] = X_final_data_feature_lag12[col].shift(i)\n",
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3149922603.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_final_data_feature_lag12[f\"{col}_lag{i}\"] = X_final_data_feature_lag12[col].shift(i)\n"
     ]
    }
   ],
   "source": [
    "lag = 12  # 滞后期\n",
    "\n",
    "# 选取需要的列\n",
    "selected_columns = ['Pig inventory', 'Breeding cost', 'Sow inventory', 'Disposable income of urban residents', 'Beef price', 'M2', 'Total retail sales']\n",
    "X_final_data_feature_lag12 = final_data[selected_columns]\n",
    "\n",
    "# 创建滞后期特征\n",
    "for col in selected_columns:\n",
    "    for i in range(1, lag+1):\n",
    "        X_final_data_feature_lag12[f\"{col}_lag{i}\"] = X_final_data_feature_lag12[col].shift(i)\n",
    "\n",
    "# 添加 num 列\n",
    "X_final_data_feature_lag12['num'] = final_data['num']\n",
    "\n",
    "# 去除包含 NaN 值的行\n",
    "X_final_data_feature_lag12 = X_final_data_feature_lag12.dropna()\n",
    "\n",
    "# 输出修改后的数据集\n",
    "print(len(X_final_data_feature_lag12))\n",
    "\n",
    "y_selected_columns = ['num', 'Hog prices']\n",
    "# 添加 num 列\n",
    "y_final_data_feature_lag12 = final_data[y_selected_columns].iloc[12:]\n",
    "\n",
    "# 输出修改后的数据集\n",
    "print(X_final_data_feature_lag12)\n",
    "\n",
    "# 去掉 'num' 列\n",
    "X_final_data_feature_lag12_cnn = X_final_data_feature_lag12.drop('num', axis=1)\n",
    "y_final_data_feature_lag12_cnn = y_final_data_feature_lag12.drop('num', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5c232",
   "metadata": {},
   "source": [
    "#  ML Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f764283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T06:14:47.221725Z",
     "start_time": "2023-06-30T06:14:47.209641Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0b588",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d02bc674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T04:35:47.607433Z",
     "start_time": "2023-07-02T04:14:54.247465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 1th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE  R Squared  \\\n",
      "15                     stacking  0.914743   1.664411  1.290121   0.171125   \n",
      "1              Ridge Regression  1.153880   2.182073  1.477184  -0.086670   \n",
      "9                  XGBRegressor  1.269764   2.246201  1.498733  -0.118606   \n",
      "8           ExtraTreesRegressor  1.238871   2.316146  1.521889  -0.153439   \n",
      "3       Decision Tree Regressor  1.225855   2.337684  1.528949  -0.164165   \n",
      "5   Gradient Boosting Regressor  1.284549   2.487554  1.577198  -0.238800   \n",
      "11                     LightGBM  1.298248   2.509446  1.584123  -0.249702   \n",
      "13                      bagging  1.271205   2.563845  1.601201  -0.276793   \n",
      "10               XGBRFRegressor  1.268995   2.577733  1.605532  -0.283709   \n",
      "4       Random Forest Regressor  1.282402   2.632936  1.622632  -0.311200   \n",
      "14                     boosting  1.299351   2.726882  1.651327  -0.357985   \n",
      "6            Adaboost Regressor  1.345029   2.793062  1.671246  -0.390943   \n",
      "7              BaggingRegressor  1.304921   2.829381  1.682076  -0.409029   \n",
      "2              Lasso Regression  1.203176   2.884693  1.698438  -0.436575   \n",
      "12                          SVM  1.393287   3.542906  1.882261  -0.764364   \n",
      "0             Linear Regression  3.797005  25.100483  5.010038 -11.500020   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.036094         -1.968657  \n",
      "1        2.358338         -1.889948  \n",
      "9        2.398258         -1.141495  \n",
      "8        2.441798         -1.135800  \n",
      "3        2.455206         -2.325228  \n",
      "5        2.548499         -0.798028  \n",
      "11       2.562128         -0.519452  \n",
      "13       2.595991         -0.600866  \n",
      "10       2.604636         -0.881151  \n",
      "4        2.639000         -0.598751  \n",
      "14       2.697481         -0.831411  \n",
      "6        2.738678         -0.631998  \n",
      "7        2.761286         -0.842449  \n",
      "2        2.795718         -1.445863  \n",
      "12       3.205455         -0.740387  \n",
      "0       16.625025         -2.166286  \n",
      "ok\n",
      "Predictions for the next 12 periods (101-112) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[15.90364162 15.91486723 15.94402435 15.54253229 14.83741311 14.12444549\n",
      " 14.05310822 14.62478462 14.80323914 14.81434225 14.06261065 14.47930803]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.13599223 -0.1343674  -0.13014711 -0.1882603  -0.29032142 -0.39351854\n",
      " -0.40384411 -0.32109792 -0.29526786 -0.29366076 -0.4024687  -0.34215464]\n",
      "This is the 2th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE  R Squared  \\\n",
      "15                     stacking  0.924997   1.692000  1.300769   0.157385   \n",
      "1              Ridge Regression  1.117016   2.148626  1.465819  -0.070014   \n",
      "3       Decision Tree Regressor  1.233329   2.367001  1.538506  -0.178764   \n",
      "9                  XGBRegressor  1.255602   2.417148  1.554718  -0.203738   \n",
      "5   Gradient Boosting Regressor  1.279253   2.595440  1.611037  -0.292527   \n",
      "6            Adaboost Regressor  1.285768   2.619073  1.618355  -0.304296   \n",
      "10               XGBRFRegressor  1.265772   2.621722  1.619173  -0.305615   \n",
      "7              BaggingRegressor  1.296495   2.626573  1.620671  -0.308031   \n",
      "13                      bagging  1.258174   2.627024  1.620810  -0.308256   \n",
      "11                     LightGBM  1.309674   2.639668  1.624705  -0.314552   \n",
      "14                     boosting  1.278268   2.669070  1.633729  -0.329195   \n",
      "8           ExtraTreesRegressor  1.236204   2.674767  1.635471  -0.332032   \n",
      "4       Random Forest Regressor  1.288039   2.723912  1.650428  -0.356506   \n",
      "2              Lasso Regression  1.203139   2.888218  1.699476  -0.438330   \n",
      "12                          SVM  1.381853   3.588797  1.894412  -0.787218   \n",
      "0             Linear Regression  4.124132  29.678147  5.447765 -13.779692   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.053268         -1.777748  \n",
      "1        2.337518         -1.681589  \n",
      "3        2.473455         -1.701919  \n",
      "9        2.504672         -0.890211  \n",
      "5        2.615658         -0.754067  \n",
      "6        2.630371         -0.880440  \n",
      "10       2.632019         -0.756427  \n",
      "7        2.635039         -0.439861  \n",
      "13       2.635320         -0.467115  \n",
      "11       2.643190         -0.436465  \n",
      "14       2.661493         -0.472882  \n",
      "8        2.665040         -0.882558  \n",
      "4        2.695632         -0.550587  \n",
      "2        2.797912         -1.120151  \n",
      "12       3.234022         -0.725773  \n",
      "0       19.474615         -2.269679  \n",
      "ok\n",
      "Predictions for the next 12 periods (102-113) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[15.09370642 14.88772323 14.56336147 14.35188093 15.05268244 14.98356203\n",
      " 14.47407054 14.02900569 13.98014455 14.98324114 15.08732178 15.33297152]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.25322473 -0.28303937 -0.32998849 -0.36059883 -0.25916267 -0.26916737\n",
      " -0.34291273 -0.40733279 -0.4144051  -0.26921382 -0.25414887 -0.21859277]\n",
      "This is the 3th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "15                     stacking  1.074981  2.133719  1.460726  -0.062590   \n",
      "1              Ridge Regression  1.133524  2.318837  1.522773  -0.154779   \n",
      "3       Decision Tree Regressor  1.226391  2.369954  1.539466  -0.180235   \n",
      "9                  XGBRegressor  1.261479  2.511845  1.584880  -0.250897   \n",
      "11                     LightGBM  1.256799  2.553433  1.597946  -0.271607   \n",
      "6            Adaboost Regressor  1.266996  2.616451  1.617545  -0.302991   \n",
      "10               XGBRFRegressor  1.240327  2.617316  1.617812  -0.303421   \n",
      "5   Gradient Boosting Regressor  1.250461  2.701216  1.643538  -0.345203   \n",
      "13                      bagging  1.273501  2.753104  1.659248  -0.371043   \n",
      "4       Random Forest Regressor  1.266651  2.780640  1.667525  -0.384756   \n",
      "8           ExtraTreesRegressor  1.234284  2.884651  1.698426  -0.436554   \n",
      "2              Lasso Regression  1.203084  2.893497  1.701028  -0.440959   \n",
      "7              BaggingRegressor  1.277109  2.897196  1.702115  -0.442801   \n",
      "14                     boosting  1.308466  2.932907  1.712573  -0.460585   \n",
      "12                          SVM  1.370179  3.669767  1.915664  -0.827541   \n",
      "0             Linear Regression  1.748202  6.484148  2.546399  -2.229101   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.328238         -0.983122  \n",
      "1        2.443474         -1.773529  \n",
      "3        2.475294         -0.809147  \n",
      "9        2.563621         -0.934398  \n",
      "11       2.589509         -0.271423  \n",
      "6        2.628738         -0.927427  \n",
      "10       2.629276         -0.528075  \n",
      "5        2.681504         -0.611269  \n",
      "13       2.713804         -0.336026  \n",
      "4        2.730945         -0.426477  \n",
      "8        2.795692         -0.869065  \n",
      "2        2.801199         -0.842509  \n",
      "7        2.803501         -0.409810  \n",
      "14       2.825732         -0.699542  \n",
      "12       3.284426         -0.701188  \n",
      "0        5.036376         -5.025967  \n",
      "ok\n",
      "Predictions for the next 12 periods (103-114) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.21751397 14.12693407 13.99960075 16.62220661 16.59882057 14.91334016\n",
      " 13.94977148 13.95037534 16.60523618 16.62913469 16.64180136 16.70332932]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.38004752 -0.39315833 -0.41158895 -0.03198492 -0.03536989 -0.2793315\n",
      " -0.41880139 -0.41871399 -0.03444128 -0.03098213 -0.02914872 -0.02024297]\n",
      "This is the 4th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "15                     stacking  1.044506  2.056762  1.434142  -0.024266   \n",
      "9                  XGBRegressor  1.230682  2.312338  1.520637  -0.151543   \n",
      "3       Decision Tree Regressor  1.270091  2.453326  1.566310  -0.221754   \n",
      "7              BaggingRegressor  1.242701  2.534282  1.591943  -0.262070   \n",
      "10               XGBRFRegressor  1.230871  2.554131  1.598165  -0.271955   \n",
      "1              Ridge Regression  1.205792  2.585909  1.608076  -0.287781   \n",
      "11                     LightGBM  1.250506  2.593951  1.610575  -0.291786   \n",
      "5   Gradient Boosting Regressor  1.233125  2.615871  1.617366  -0.302702   \n",
      "4       Random Forest Regressor  1.237411  2.643475  1.625877  -0.316449   \n",
      "13                      bagging  1.245314  2.660095  1.630980  -0.324725   \n",
      "14                     boosting  1.275211  2.686341  1.639006  -0.337796   \n",
      "6            Adaboost Regressor  1.284226  2.707001  1.645297  -0.348084   \n",
      "8           ExtraTreesRegressor  1.204920  2.805474  1.674955  -0.397124   \n",
      "2              Lasso Regression  1.203042  2.897568  1.702224  -0.442986   \n",
      "12                          SVM  1.372043  3.796915  1.948567  -0.890860   \n",
      "0             Linear Regression  2.096406  7.598547  2.756546  -2.784070   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.280332         -1.236567  \n",
      "9        2.439428         -0.945782  \n",
      "3        2.527193         -0.858067  \n",
      "7        2.577588         -0.392870  \n",
      "10       2.589944         -0.423372  \n",
      "1        2.609726         -1.889935  \n",
      "11       2.614732         -0.185263  \n",
      "5        2.628377         -0.528475  \n",
      "4        2.645561         -0.421096  \n",
      "13       2.655906         -0.363361  \n",
      "14       2.672245         -0.720683  \n",
      "6        2.685106         -0.629323  \n",
      "8        2.746405         -0.757181  \n",
      "2        2.803733         -0.737967  \n",
      "12       3.363575         -0.721330  \n",
      "0        5.730087         -5.507729  \n",
      "ok\n",
      "Predictions for the next 12 periods (104-115) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.92021424 13.7937586  16.13529676 16.11715111 14.98579678 13.60746524\n",
      " 13.61183259 16.15554132 16.16583908 16.16773059 16.18052518 16.21241619]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.4230796  -0.44138317 -0.10246175 -0.10508821 -0.26884391 -0.46834785\n",
      " -0.4677157  -0.09953149 -0.09804096 -0.09776718 -0.09591525 -0.09129925]\n",
      "This is the 5th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model        MAE         MSE       RMSE   R Squared  \\\n",
      "3       Decision Tree Regressor   1.186076    2.133737   1.460732   -0.062599   \n",
      "9                  XGBRegressor   1.224244    2.383655   1.543909   -0.187058   \n",
      "15                     stacking   1.168602    2.503094   1.582117   -0.246539   \n",
      "10               XGBRFRegressor   1.232327    2.534793   1.592103   -0.262325   \n",
      "6            Adaboost Regressor   1.262091    2.592373   1.610085   -0.290999   \n",
      "11                     LightGBM   1.263554    2.621397   1.619073   -0.305454   \n",
      "5   Gradient Boosting Regressor   1.229694    2.631996   1.622343   -0.310732   \n",
      "4       Random Forest Regressor   1.241129    2.638766   1.624428   -0.314103   \n",
      "13                      bagging   1.215383    2.639874   1.624769   -0.314655   \n",
      "7              BaggingRegressor   1.241221    2.682287   1.637769   -0.335777   \n",
      "14                     boosting   1.264960    2.721757   1.649775   -0.355433   \n",
      "1              Ridge Regression   1.244650    2.725627   1.650947   -0.357360   \n",
      "8           ExtraTreesRegressor   1.181427    2.742570   1.656071   -0.365798   \n",
      "2              Lasso Regression   1.203018    2.899850   1.702894   -0.444123   \n",
      "12                          SVM   1.378189    3.833595   1.957957   -0.909127   \n",
      "0             Linear Regression  17.011775  759.743095  27.563438 -377.351428   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "3        2.328249         -0.607552  \n",
      "9        2.483823         -0.472785  \n",
      "15       2.558173         -0.857150  \n",
      "10       2.577906         -0.316529  \n",
      "6        2.613749         -0.579397  \n",
      "11       2.631817         -0.089118  \n",
      "5        2.638415         -0.725641  \n",
      "4        2.642629         -0.341256  \n",
      "13       2.643319         -0.279717  \n",
      "7        2.669721         -0.408687  \n",
      "14       2.694291         -0.745767  \n",
      "1        2.696700         -1.795501  \n",
      "8        2.707247         -0.647670  \n",
      "2        2.805153         -0.596785  \n",
      "12       3.386409         -0.449771  \n",
      "0      473.939285         -7.063207  \n",
      "ok\n",
      "Predictions for the next 12 periods (105-116) using Decision Tree Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[12.77507851 19.8948667  19.8948667  15.84460971 13.20214355 13.20214355\n",
      " 20.68343092 20.68343092 20.68343092 20.68343092 20.13076411 18.20414732]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.58883006  0.44170995  0.44170995 -0.14453669 -0.52701535 -0.52701535\n",
      "  0.55584916  0.55584916  0.55584916  0.55584916  0.47585446  0.19699003]\n",
      "This is the 6th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model        MAE          MSE       RMSE  \\\n",
      "15                     stacking   1.090512     2.169639   1.472969   \n",
      "7              BaggingRegressor   1.198147     2.411997   1.553060   \n",
      "3       Decision Tree Regressor   1.264470     2.475946   1.573514   \n",
      "10               XGBRFRegressor   1.225114     2.509819   1.584241   \n",
      "9                  XGBRegressor   1.266588     2.533717   1.591766   \n",
      "4       Random Forest Regressor   1.226488     2.551726   1.597412   \n",
      "14                     boosting   1.224487     2.568640   1.602698   \n",
      "5   Gradient Boosting Regressor   1.236778     2.589155   1.609085   \n",
      "11                     LightGBM   1.255674     2.592898   1.610248   \n",
      "13                      bagging   1.233421     2.641935   1.625403   \n",
      "1              Ridge Regression   1.225922     2.656092   1.629752   \n",
      "6            Adaboost Regressor   1.258661     2.713244   1.647193   \n",
      "8           ExtraTreesRegressor   1.210098     2.842574   1.685994   \n",
      "2              Lasso Regression   1.202999     2.901719   1.703443   \n",
      "12                          SVM   1.377228     3.828776   1.956726   \n",
      "0             Linear Regression  24.114397  1494.880890  38.663690   \n",
      "\n",
      "     R Squared  adj R Squared  Cross Validation  \n",
      "15   -0.080478       2.350598         -0.551550  \n",
      "7    -0.201172       2.501465         -0.367401  \n",
      "3    -0.233019       2.541274         -1.333451  \n",
      "10   -0.249888       2.562360         -0.083667  \n",
      "9    -0.261789       2.577236         -0.049671  \n",
      "4    -0.270757       2.588447         -0.256361  \n",
      "14   -0.279181       2.598976         -0.377441  \n",
      "5    -0.289397       2.611746         -0.467712  \n",
      "11   -0.291261       2.614076          0.049134  \n",
      "13   -0.315682       2.644602         -0.282477  \n",
      "1    -0.322731       2.653414         -2.056782  \n",
      "6    -0.351193       2.688991         -0.551409  \n",
      "8    -0.415600       2.769500         -0.468728  \n",
      "2    -0.445054       2.806317         -0.492454  \n",
      "12   -0.906727       3.383409         -0.523751  \n",
      "0  -743.449436     931.561795         -6.047491  \n",
      "ok\n",
      "Predictions for the next 12 periods (106-117) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[16.64161304 16.62974357 14.90013956 13.80573837 13.80905343 16.65427305\n",
      " 16.66146935 16.65866032 16.66403173 16.89882668 15.86239592 16.83877863]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.02917598 -0.030894   -0.2812422  -0.43964919 -0.43916935 -0.02734353\n",
      " -0.02630191 -0.0267085  -0.02593103  0.00805391 -0.14196226 -0.00063762]\n",
      "This is the 7th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model        MAE         MSE       RMSE   R Squared  \\\n",
      "15                     stacking   1.090175    2.236926   1.495636   -0.113987   \n",
      "1              Ridge Regression   1.167831    2.440510   1.562213   -0.215372   \n",
      "7              BaggingRegressor   1.237877    2.470201   1.571687   -0.230158   \n",
      "9                  XGBRegressor   1.257594    2.477108   1.573883   -0.233598   \n",
      "10               XGBRFRegressor   1.202956    2.491009   1.578293   -0.240521   \n",
      "3       Decision Tree Regressor   1.255571    2.499945   1.581122   -0.244971   \n",
      "6            Adaboost Regressor   1.227119    2.531005   1.590913   -0.260438   \n",
      "4       Random Forest Regressor   1.236297    2.567622   1.602380   -0.278674   \n",
      "11                     LightGBM   1.236954    2.574053   1.604385   -0.281876   \n",
      "5   Gradient Boosting Regressor   1.226661    2.582342   1.606967   -0.286004   \n",
      "13                      bagging   1.239894    2.696538   1.642114   -0.342874   \n",
      "14                     boosting   1.244270    2.782332   1.668032   -0.385599   \n",
      "8           ExtraTreesRegressor   1.183147    2.839010   1.684936   -0.413825   \n",
      "2              Lasso Regression   1.202969    2.904600   1.704289   -0.446488   \n",
      "12                          SVM   1.376516    3.825485   1.955885   -0.905088   \n",
      "0             Linear Regression  12.997198  444.140074  21.074631 -220.181386   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.392484         -0.816796  \n",
      "1        2.519215         -2.518675  \n",
      "7        2.537698         -0.193408  \n",
      "9        2.541997          0.037755  \n",
      "10       2.550651          0.018222  \n",
      "3        2.556213         -0.605348  \n",
      "6        2.575548         -0.312353  \n",
      "4        2.598342         -0.079635  \n",
      "11       2.602345         -0.028174  \n",
      "5        2.607505         -0.344936  \n",
      "13       2.678592         -0.130966  \n",
      "14       2.731999         -0.290640  \n",
      "8        2.767281         -0.613194  \n",
      "2        2.808110         -0.462941  \n",
      "12       3.381360         -0.602005  \n",
      "0      277.476733         -6.919442  \n",
      "ok\n",
      "Predictions for the next 12 periods (107-118) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[16.10479391 14.86639374 14.13700247 14.02321038 16.12750727 16.13774814\n",
      " 16.1342068  16.14050548 16.15767515 15.09241102 16.09554626 16.06579534]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.10687683 -0.28612667 -0.391701   -0.40817162 -0.10358923 -0.10210693\n",
      " -0.10261951 -0.10170782 -0.09922263 -0.25341223 -0.10821536 -0.1125216 ]\n",
      "This is the 8th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model        MAE         MSE       RMSE   R Squared  \\\n",
      "3       Decision Tree Regressor   1.171967    2.125307   1.457843   -0.058401   \n",
      "1              Ridge Regression   1.097593    2.184997   1.478174   -0.088127   \n",
      "7              BaggingRegressor   1.213046    2.446001   1.563970   -0.218107   \n",
      "10               XGBRFRegressor   1.203080    2.511542   1.584785   -0.250746   \n",
      "9                  XGBRegressor   1.254865    2.528518   1.590131   -0.259200   \n",
      "15                     stacking   1.182887    2.549285   1.596648   -0.269542   \n",
      "4       Random Forest Regressor   1.216728    2.593678   1.610490   -0.291649   \n",
      "14                     boosting   1.232291    2.620300   1.618734   -0.304907   \n",
      "13                      bagging   1.232410    2.639797   1.624745   -0.314617   \n",
      "11                     LightGBM   1.239354    2.658601   1.630522   -0.323981   \n",
      "5   Gradient Boosting Regressor   1.207770    2.696918   1.642229   -0.343063   \n",
      "6            Adaboost Regressor   1.238236    2.706398   1.645113   -0.347784   \n",
      "8           ExtraTreesRegressor   1.176074    2.894389   1.701290   -0.441403   \n",
      "2              Lasso Regression   1.202944    2.907041   1.705005   -0.447704   \n",
      "12                          SVM   1.375838    3.822101   1.955020   -0.903403   \n",
      "0             Linear Regression  13.981361  510.951940  22.604246 -253.453640   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "3        2.323001         -0.803792  \n",
      "1        2.360158         -3.266920  \n",
      "7        2.522633         -0.085271  \n",
      "10       2.563432         -0.119848  \n",
      "9        2.574000         -0.474982  \n",
      "15       2.586927         -0.957372  \n",
      "4        2.614562         -0.050147  \n",
      "14       2.631134         -0.605101  \n",
      "13       2.643271         -0.217702  \n",
      "11       2.654976         -0.135647  \n",
      "5        2.678828         -0.432349  \n",
      "6        2.684730         -0.380409  \n",
      "8        2.801754         -0.950954  \n",
      "2        2.809630         -0.436913  \n",
      "12       3.379254         -1.075818  \n",
      "0      319.067050         -6.631372  \n",
      "ok\n",
      "Predictions for the next 12 periods (108-119) using Decision Tree Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[19.8948667  15.92536248 15.15334785 15.15334785 19.8948667  20.13076411\n",
      " 20.13076411 20.13076411 20.13076411 15.15334785 20.13076411 20.13076411]\n",
      "Predictions for the next 12 periods:\n",
      "[ 0.44170995 -0.13284828 -0.24459205 -0.24459205  0.44170995  0.47585446\n",
      "  0.47585446  0.47585446  0.47585446 -0.24459205  0.47585446  0.47585446]\n",
      "This is the 9th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE         MSE       RMSE  R Squared  \\\n",
      "1              Ridge Regression  1.005900    1.852663   1.361126   0.077375   \n",
      "3       Decision Tree Regressor  1.088549    2.006941   1.416665   0.000545   \n",
      "15                     stacking  1.073945    2.257344   1.502446  -0.124156   \n",
      "10               XGBRFRegressor  1.155062    2.466875   1.570629  -0.228502   \n",
      "9                  XGBRegressor  1.167180    2.471001   1.571942  -0.230556   \n",
      "6            Adaboost Regressor  1.205396    2.528025   1.589976  -0.258954   \n",
      "4       Random Forest Regressor  1.196645    2.591875   1.609930  -0.290752   \n",
      "7              BaggingRegressor  1.236726    2.618031   1.618033  -0.303777   \n",
      "11                     LightGBM  1.212585    2.674629   1.635429  -0.331963   \n",
      "13                      bagging  1.216147    2.679595   1.636947  -0.334436   \n",
      "5   Gradient Boosting Regressor  1.180694    2.754382   1.659633  -0.371680   \n",
      "14                     boosting  1.197134    2.802779   1.674150  -0.395782   \n",
      "8           ExtraTreesRegressor  1.168428    2.849834   1.688145  -0.419215   \n",
      "2              Lasso Regression  1.202940    2.907376   1.705103  -0.447871   \n",
      "12                          SVM  1.375192    3.818940   1.954211  -0.901829   \n",
      "0             Linear Regression  6.988753  136.519073  11.684138 -66.986385   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        2.153281         -3.355651  \n",
      "3        2.249318         -1.094805  \n",
      "15       2.405194         -1.887172  \n",
      "10       2.535627         -0.081315  \n",
      "9        2.538195         -0.496620  \n",
      "6        2.573693         -0.506133  \n",
      "4        2.613439         -0.246698  \n",
      "7        2.629722         -0.247726  \n",
      "11       2.664954         -0.118007  \n",
      "13       2.668045         -0.245564  \n",
      "5        2.714600         -0.476288  \n",
      "14       2.744727         -0.219359  \n",
      "8        2.774019         -0.843116  \n",
      "2        2.809839         -0.429580  \n",
      "12       3.377286         -1.118667  \n",
      "0       85.982981         -5.361189  \n",
      "ok\n",
      "Predictions for the next 12 periods (109-120) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.56446418 13.43968733 13.30746863 13.35809282 13.24294736 13.3151346\n",
      " 13.5499229  13.3771921  13.08316958 13.06558007 12.940944   12.38872664]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.47457195 -0.49263254 -0.51177028 -0.50444278 -0.52110928 -0.51066068\n",
      " -0.4766767  -0.50167829 -0.54423601 -0.54678197 -0.56482218 -0.64475181]\n",
      "This is the 10th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE         MSE       RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.966017    1.709688   1.307550   0.148577   \n",
      "3       Decision Tree Regressor  1.087502    2.005624   1.416200   0.001201   \n",
      "10               XGBRFRegressor  1.156314    2.471023   1.571949  -0.230567   \n",
      "14                     boosting  1.182087    2.497962   1.580494  -0.243983   \n",
      "4       Random Forest Regressor  1.183500    2.579880   1.606200  -0.284778   \n",
      "9                  XGBRegressor  1.214249    2.593641   1.610479  -0.291631   \n",
      "13                      bagging  1.195432    2.654124   1.629148  -0.321751   \n",
      "5   Gradient Boosting Regressor  1.174484    2.718210   1.648700  -0.353666   \n",
      "11                     LightGBM  1.209924    2.720306   1.649335  -0.354710   \n",
      "7              BaggingRegressor  1.208217    2.753497   1.659367  -0.371239   \n",
      "6            Adaboost Regressor  1.241204    2.754328   1.659617  -0.371653   \n",
      "8           ExtraTreesRegressor  1.164619    2.858311   1.690654  -0.423436   \n",
      "2              Lasso Regression  1.202938    2.907597   1.705168  -0.447981   \n",
      "15                     stacking  1.251688    3.033697   1.741751  -0.510779   \n",
      "12                          SVM  1.374672    3.816503   1.953587  -0.900615   \n",
      "0             Linear Regression  6.333352  106.426183  10.316307 -52.000150   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        2.064279         -3.685536  \n",
      "3        2.248499         -1.006408  \n",
      "10       2.538209         -0.083256  \n",
      "14       2.554979         -0.422788  \n",
      "4        2.605973         -0.206052  \n",
      "9        2.614539         -0.851231  \n",
      "13       2.652189         -0.300494  \n",
      "5        2.692083         -0.515742  \n",
      "11       2.693388         -0.467047  \n",
      "7        2.714049         -0.333256  \n",
      "6        2.714566         -0.500177  \n",
      "8        2.779295         -1.296850  \n",
      "2        2.809976         -0.373731  \n",
      "15       2.888473         -1.244446  \n",
      "12       3.375769         -1.662726  \n",
      "0       67.250188         -2.871143  \n",
      "ok\n",
      "Predictions for the next 12 periods (110-121) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.72473653 13.50797985 13.55612274 13.40121401 13.45203196 13.67352407\n",
      " 13.52098835 13.22303121 13.27452835 13.1945946  12.82171388 11.55324802]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.45137364 -0.48274767 -0.47577932 -0.49820128 -0.49084574 -0.45878629\n",
      " -0.48086478 -0.52399201 -0.51653815 -0.52810801 -0.58207991 -0.76568156]\n",
      "This is the 11th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE         MSE       RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.997269    1.821649   1.349685   0.092820   \n",
      "3       Decision Tree Regressor  1.086366    2.049176   1.431494  -0.020488   \n",
      "10               XGBRFRegressor  1.132673    2.478505   1.574327  -0.234293   \n",
      "15                     stacking  1.149785    2.613922   1.616763  -0.301731   \n",
      "4       Random Forest Regressor  1.190894    2.628390   1.621231  -0.308936   \n",
      "9                  XGBRegressor  1.221738    2.637314   1.623981  -0.313380   \n",
      "14                     boosting  1.197530    2.647684   1.627171  -0.318545   \n",
      "13                      bagging  1.185927    2.681812   1.637624  -0.335540   \n",
      "5   Gradient Boosting Regressor  1.164767    2.734210   1.653545  -0.361634   \n",
      "7              BaggingRegressor  1.231257    2.771610   1.664815  -0.380259   \n",
      "6            Adaboost Regressor  1.211279    2.772489   1.665079  -0.380697   \n",
      "11                     LightGBM  1.199134    2.834833   1.683696  -0.411745   \n",
      "8           ExtraTreesRegressor  1.153751    2.901188   1.703287  -0.444789   \n",
      "2              Lasso Regression  1.202970    2.912717   1.706668  -0.450530   \n",
      "12                          SVM  1.392131    3.904819   1.976061  -0.944596   \n",
      "0             Linear Regression  6.807024  115.112957  10.729071 -56.326157   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        2.133975         -2.891010  \n",
      "3        2.275610         -0.890678  \n",
      "10       2.542867         -0.155936  \n",
      "15       2.627164         -1.196770  \n",
      "4        2.636170         -0.324052  \n",
      "9        2.641725         -0.719888  \n",
      "14       2.648181         -0.798781  \n",
      "13       2.669425         -0.429709  \n",
      "5        2.702043         -0.434489  \n",
      "7        2.725324         -0.181800  \n",
      "6        2.725872         -0.440772  \n",
      "11       2.764681         -0.875602  \n",
      "8        2.805987         -1.198217  \n",
      "2        2.813163         -0.364484  \n",
      "12       3.430746         -1.863564  \n",
      "0       72.657696         -7.010856  \n",
      "ok\n",
      "Predictions for the next 12 periods (111-122) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.28169634 13.39558174 13.24776632 13.33318395 13.57525294 13.43071957\n",
      " 13.10901439 13.17049976 13.03343337 12.61304202 11.2098532  10.58424143]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.51550064 -0.49901652 -0.52041177 -0.50804816 -0.47301035 -0.49393056\n",
      " -0.54049515 -0.53159557 -0.55143498 -0.61228372 -0.81538558 -0.90593855]\n",
      "This is the 12th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE         MSE       RMSE  R Squared  \\\n",
      "3       Decision Tree Regressor  1.086882    2.023086   1.422352  -0.007495   \n",
      "1              Ridge Regression  1.085984    2.182978   1.477490  -0.087121   \n",
      "10               XGBRFRegressor  1.136435    2.629038   1.621431  -0.309259   \n",
      "13                      bagging  1.184303    2.813786   1.677434  -0.401263   \n",
      "14                     boosting  1.172737    2.869308   1.693903  -0.428913   \n",
      "2              Lasso Regression  1.203095    2.924879   1.710228  -0.456587   \n",
      "11                     LightGBM  1.212336    2.977468   1.725534  -0.482777   \n",
      "4       Random Forest Regressor  1.199108    2.990558   1.729323  -0.489295   \n",
      "6            Adaboost Regressor  1.266039    3.002782   1.732854  -0.495383   \n",
      "7              BaggingRegressor  1.204363    3.080232   1.755059  -0.533953   \n",
      "5   Gradient Boosting Regressor  1.209628    3.138090   1.771465  -0.562766   \n",
      "15                     stacking  1.291252    3.293546   1.814813  -0.640183   \n",
      "9                  XGBRegressor  1.293492    3.346545   1.829356  -0.666576   \n",
      "8           ExtraTreesRegressor  1.330689    3.876415   1.968861  -0.930452   \n",
      "12                          SVM  1.404584    3.968164   1.992025  -0.976142   \n",
      "0             Linear Regression  8.030867  161.063550  12.691082 -79.209514   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "3        2.259369         -1.140988  \n",
      "1        2.358901         -2.113083  \n",
      "10       2.636574         -0.314813  \n",
      "13       2.751579         -0.533929  \n",
      "14       2.786141         -0.971752  \n",
      "2        2.820734         -0.412893  \n",
      "11       2.853471         -1.045523  \n",
      "4        2.861619         -0.501141  \n",
      "6        2.869228         -0.866650  \n",
      "7        2.917441         -0.641663  \n",
      "5        2.953458         -0.911315  \n",
      "15       3.050229         -1.060378  \n",
      "9        3.083221         -1.288048  \n",
      "8        3.413064         -1.376747  \n",
      "12       3.470178         -1.663891  \n",
      "0      101.261892         -4.623921  \n",
      "ok\n",
      "Predictions for the next 12 periods (112-123) using Decision Tree Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[20.68343092 20.68343092 14.78231916 14.78231916 14.78231916 17.80082332\n",
      " 20.68343092 20.68343092 20.68343092 20.68343092 20.68343092 20.68343092]\n",
      "Predictions for the next 12 periods:\n",
      "[ 0.55584916  0.55584916 -0.29829588 -0.29829588 -0.29829588  0.13861168\n",
      "  0.55584916  0.55584916  0.55584916  0.55584916  0.55584916  0.55584916]\n",
      "This is the 13th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE  R Squared  \\\n",
      "3       Decision Tree Regressor  1.077954   2.055284  1.433626  -0.023530   \n",
      "1              Ridge Regression  1.141768   2.416025  1.554357  -0.203178   \n",
      "2              Lasso Regression  1.203425   2.938181  1.714112  -0.463212   \n",
      "13                      bagging  1.206667   3.016690  1.736862  -0.502309   \n",
      "11                     LightGBM  1.224339   3.178880  1.782941  -0.583080   \n",
      "14                     boosting  1.210364   3.199981  1.788849  -0.593588   \n",
      "6            Adaboost Regressor  1.301436   3.216223  1.793383  -0.601676   \n",
      "4       Random Forest Regressor  1.226675   3.249857  1.802736  -0.618426   \n",
      "7              BaggingRegressor  1.279467   3.257801  1.804938  -0.622382   \n",
      "10               XGBRFRegressor  1.219640   3.307381  1.818621  -0.647073   \n",
      "5   Gradient Boosting Regressor  1.248586   3.430460  1.852150  -0.708366   \n",
      "9                  XGBRegressor  1.320890   3.581039  1.892363  -0.783354   \n",
      "15                     stacking  1.394415   3.765908  1.940595  -0.875419   \n",
      "8           ExtraTreesRegressor  1.330841   3.881295  1.970100  -0.932882   \n",
      "12                          SVM  1.445094   4.148901  2.036885  -1.066149   \n",
      "0             Linear Regression  5.999976  90.570932  9.516876 -44.104249   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "3        2.279412         -1.180960  \n",
      "1        2.503973         -1.808632  \n",
      "2        2.829014         -0.430138  \n",
      "13       2.877886         -0.817160  \n",
      "11       2.978850         -1.100156  \n",
      "14       2.991985         -1.109071  \n",
      "6        3.002095         -0.939397  \n",
      "4        3.023033         -0.789365  \n",
      "7        3.027978         -0.923037  \n",
      "10       3.058841         -0.649542  \n",
      "5        3.135458         -1.366233  \n",
      "9        3.229193         -1.541301  \n",
      "15       3.344274         -0.791381  \n",
      "8        3.416102         -1.466334  \n",
      "12       3.582687         -1.605920  \n",
      "0       57.380311         -4.893172  \n",
      "ok\n",
      "Predictions for the next 12 periods (113-124) using Decision Tree Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[20.13076411 12.77507851 14.74461575 14.74461575 17.80082332 20.68343092\n",
      " 20.68343092 20.68343092 20.68343092 20.68343092 20.68343092 20.68343092]\n",
      "Predictions for the next 12 periods:\n",
      "[ 0.47585446 -0.58883006 -0.30375319 -0.30375319  0.13861168  0.55584916\n",
      "  0.55584916  0.55584916  0.55584916  0.55584916  0.55584916  0.55584916]\n",
      "This is the 14th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  1.177518   2.569932  1.603101  -0.279824   \n",
      "15                     stacking  1.149765   2.653321  1.628902  -0.321352   \n",
      "2              Lasso Regression  1.204280   2.951246  1.717919  -0.469718   \n",
      "13                      bagging  1.217837   3.139215  1.771783  -0.563326   \n",
      "11                     LightGBM  1.241033   3.357615  1.832380  -0.672089   \n",
      "4       Random Forest Regressor  1.232708   3.373379  1.836676  -0.679940   \n",
      "7              BaggingRegressor  1.243377   3.433706  1.853026  -0.709982   \n",
      "5   Gradient Boosting Regressor  1.229129   3.434549  1.853254  -0.710402   \n",
      "6            Adaboost Regressor  1.279366   3.532494  1.879493  -0.759179   \n",
      "14                     boosting  1.290852   3.674935  1.917012  -0.830115   \n",
      "10               XGBRFRegressor  1.312172   3.693282  1.921791  -0.839251   \n",
      "8           ExtraTreesRegressor  1.326212   3.891133  1.972595  -0.937781   \n",
      "9                  XGBRegressor  1.376525   4.145588  2.036072  -1.064500   \n",
      "12                          SVM  1.502139   4.373076  2.091190  -1.177788   \n",
      "3       Decision Tree Regressor  1.451837   4.453927  2.110433  -1.218052   \n",
      "0             Linear Regression  4.015794  38.451156  6.200900 -18.148644   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        2.599780         -1.678378  \n",
      "15       2.651690         -1.511491  \n",
      "2        2.837148         -0.428545  \n",
      "13       2.954158         -0.659101  \n",
      "11       3.090112         -1.204085  \n",
      "4        3.099925         -0.753046  \n",
      "7        3.137478         -0.762748  \n",
      "5        3.138003         -1.446853  \n",
      "6        3.198974         -0.909671  \n",
      "14       3.287643         -1.001277  \n",
      "10       3.299064         -0.740256  \n",
      "8        3.422226         -1.418977  \n",
      "9        3.580624         -1.741551  \n",
      "12       3.722235         -1.556177  \n",
      "3        3.772565         -2.161430  \n",
      "0       24.935804         -4.238849  \n",
      "ok\n",
      "Predictions for the next 12 periods (114-125) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[11.91757506 12.51594832 12.55226111 12.3502659  12.35029085 12.17312196\n",
      " 11.42135782  9.74684623  8.41732961  8.17355327  8.64789083  9.28233606]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.71294774 -0.62633736 -0.62108133 -0.65031874 -0.65031513 -0.6759591\n",
      " -0.78477175 -1.0271457  -1.21958402 -1.25486895 -1.18621188 -1.09438033]\n",
      "This is the 15th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  1.185474   2.600677  1.612662  -0.295135   \n",
      "15                     stacking  1.202562   2.933523  1.712753  -0.460892   \n",
      "2              Lasso Regression  1.205196   2.961357  1.720859  -0.474753   \n",
      "13                      bagging  1.195497   3.114279  1.764732  -0.550908   \n",
      "11                     LightGBM  1.238925   3.430634  1.852197  -0.708453   \n",
      "4       Random Forest Regressor  1.258544   3.550329  1.884232  -0.768061   \n",
      "10               XGBRFRegressor  1.268593   3.551147  1.884449  -0.768468   \n",
      "7              BaggingRegressor  1.258807   3.554564  1.885355  -0.770170   \n",
      "14                     boosting  1.262583   3.587772  1.894142  -0.786708   \n",
      "5   Gradient Boosting Regressor  1.250730   3.593328  1.895608  -0.789474   \n",
      "6            Adaboost Regressor  1.281446   3.623650  1.903589  -0.804574   \n",
      "8           ExtraTreesRegressor  1.335956   3.891074  1.972581  -0.937752   \n",
      "3       Decision Tree Regressor  1.355150   4.002507  2.000627  -0.993245   \n",
      "9                  XGBRegressor  1.366240   4.189309  2.046780  -1.086272   \n",
      "12                          SVM  1.502140   4.372658  2.091090  -1.177580   \n",
      "0             Linear Regression  4.629205  48.889156  6.992078 -23.346759   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        2.618919         -1.558587  \n",
      "15       2.826115         -1.109301  \n",
      "2        2.843442         -0.543075  \n",
      "13       2.938635         -1.033405  \n",
      "11       3.135566         -1.270990  \n",
      "4        3.210076         -1.091411  \n",
      "10       3.210585         -1.095885  \n",
      "7        3.212713         -1.244851  \n",
      "14       3.233385         -1.084595  \n",
      "5        3.236843         -1.268163  \n",
      "6        3.255718         -1.175827  \n",
      "8        3.422190         -1.285581  \n",
      "3        3.491557         -2.398271  \n",
      "9        3.607840         -1.711863  \n",
      "12       3.721975         -1.650836  \n",
      "0       31.433449         -4.201493  \n",
      "ok\n",
      "Predictions for the next 12 periods (115-126) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[12.39506439 12.47281512 12.27751663 12.29710288 12.12333397 11.36286098\n",
      "  9.66585379  8.34092508  8.06975612  8.52940684  9.08697972  9.2031273 ]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.64383447 -0.63258059 -0.66084869 -0.65801372 -0.68316556 -0.79323876\n",
      " -1.03886879 -1.23064304 -1.26989287 -1.20336161 -1.1226568  -1.10584525]\n",
      "This is the 16th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE  R Squared  \\\n",
      "15                     stacking  1.093459   2.375488  1.541262  -0.182991   \n",
      "1              Ridge Regression  1.180946   2.585645  1.607994  -0.287649   \n",
      "2              Lasso Regression  1.205844   2.968540  1.722945  -0.478330   \n",
      "13                      bagging  1.188372   3.082501  1.755705  -0.535083   \n",
      "7              BaggingRegressor  1.171454   3.121633  1.766814  -0.554571   \n",
      "6            Adaboost Regressor  1.197490   3.207629  1.790985  -0.597397   \n",
      "4       Random Forest Regressor  1.235942   3.430371  1.852126  -0.708322   \n",
      "10               XGBRFRegressor  1.247036   3.497485  1.870156  -0.741745   \n",
      "11                     LightGBM  1.255749   3.503845  1.871856  -0.744912   \n",
      "5   Gradient Boosting Regressor  1.245597   3.518970  1.875892  -0.752444   \n",
      "14                     boosting  1.273137   3.629175  1.905039  -0.807326   \n",
      "9                  XGBRegressor  1.295689   3.739070  1.933667  -0.862054   \n",
      "8           ExtraTreesRegressor  1.304933   3.769701  1.941572  -0.877308   \n",
      "3       Decision Tree Regressor  1.331749   3.918311  1.979472  -0.951315   \n",
      "12                          SVM  1.486999   4.317905  2.077957  -1.150313   \n",
      "0             Linear Regression  5.966905  76.972734  8.773411 -37.332357   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.478739         -1.369940  \n",
      "1        2.609561         -1.873704  \n",
      "2        2.847913         -0.804771  \n",
      "13       2.918854         -1.543191  \n",
      "7        2.943213         -1.400090  \n",
      "6        2.996746         -1.815970  \n",
      "4        3.135403         -1.638850  \n",
      "10       3.177181         -1.671933  \n",
      "11       3.181140         -2.015796  \n",
      "5        3.190555         -1.862107  \n",
      "14       3.259157         -2.005830  \n",
      "9        3.327567         -2.497960  \n",
      "8        3.346635         -1.785051  \n",
      "3        3.439144         -2.689166  \n",
      "12       3.687891         -2.187134  \n",
      "0       48.915447         -5.622455  \n",
      "ok\n",
      "Predictions for the next 12 periods (116-127) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[15.10800202 15.08789756 15.08919533 15.07239375 15.00371824 14.50417221\n",
      " 14.38531594 14.36032413 14.40367972 14.4551379  14.47027993 14.49768005]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.25115555 -0.25406553 -0.25387768 -0.2563096  -0.2662499  -0.33855573\n",
      " -0.35575935 -0.35937674 -0.35310132 -0.3456531  -0.3434614  -0.33949542]\n",
      "This is the 17th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  1.168207   2.549470  1.596706  -0.269634   \n",
      "15                     stacking  1.201249   2.912102  1.706488  -0.450225   \n",
      "2              Lasso Regression  1.206148   2.971921  1.723926  -0.480014   \n",
      "13                      bagging  1.185529   3.045934  1.745260  -0.516872   \n",
      "5   Gradient Boosting Regressor  1.184912   3.185782  1.784876  -0.586517   \n",
      "14                     boosting  1.204651   3.255542  1.804312  -0.621257   \n",
      "3       Decision Tree Regressor  1.187710   3.315616  1.820883  -0.651174   \n",
      "4       Random Forest Regressor  1.231488   3.407904  1.846051  -0.697134   \n",
      "10               XGBRFRegressor  1.220835   3.412736  1.847359  -0.699539   \n",
      "6            Adaboost Regressor  1.250319   3.439319  1.854540  -0.712778   \n",
      "8           ExtraTreesRegressor  1.229616   3.487754  1.867553  -0.736899   \n",
      "7              BaggingRegressor  1.263201   3.574744  1.890699  -0.780220   \n",
      "11                     LightGBM  1.277644   3.608265  1.899543  -0.796913   \n",
      "9                  XGBRegressor  1.304301   3.747185  1.935765  -0.866095   \n",
      "12                          SVM  1.418234   4.049401  2.012312  -1.016599   \n",
      "0             Linear Regression  3.565205  27.621975  5.255661 -12.755720   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        2.587042         -2.293653  \n",
      "15       2.812781         -1.235944  \n",
      "2        2.850018         -1.189350  \n",
      "13       2.896090         -2.070255  \n",
      "5        2.983146         -2.756808  \n",
      "14       3.026572         -2.623573  \n",
      "3        3.063968         -4.254127  \n",
      "4        3.121417         -2.239455  \n",
      "10       3.124424         -2.412889  \n",
      "6        3.140972         -2.580614  \n",
      "8        3.171123         -2.638474  \n",
      "7        3.225275         -2.576516  \n",
      "11       3.246141         -2.804375  \n",
      "9        3.332619         -3.142240  \n",
      "12       3.520748         -2.639148  \n",
      "0       18.194650         -5.740889  \n",
      "ok\n",
      "Predictions for the next 12 periods (117-128) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[12.57511804 12.50001955 12.30275555 11.5186358   9.82713106  8.52650752\n",
      "  8.28635528  8.75788248  9.38550147  9.58566669 10.04197225 10.47285152]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.61777295 -0.62864294 -0.65719553 -0.77069143 -1.01552502 -1.20378127\n",
      " -1.23854164 -1.17029135 -1.07944785 -1.05047532 -0.98442825 -0.92206146]\n",
      "This is the 18th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE  R Squared  \\\n",
      "15                     stacking  1.099519   2.433386  1.559931  -0.211824   \n",
      "1              Ridge Regression  1.157197   2.522119  1.588118  -0.256013   \n",
      "2              Lasso Regression  1.206328   2.973928  1.724508  -0.481014   \n",
      "13                      bagging  1.195786   3.141422  1.772406  -0.564425   \n",
      "5   Gradient Boosting Regressor  1.177649   3.193018  1.786902  -0.590121   \n",
      "4       Random Forest Regressor  1.202693   3.252187  1.803382  -0.619586   \n",
      "7              BaggingRegressor  1.212347   3.254371  1.803988  -0.620674   \n",
      "10               XGBRFRegressor  1.206562   3.358126  1.832519  -0.672344   \n",
      "11                     LightGBM  1.227475   3.419330  1.849143  -0.702823   \n",
      "6            Adaboost Regressor  1.246627   3.421576  1.849750  -0.703942   \n",
      "14                     boosting  1.235632   3.445455  1.856194  -0.715834   \n",
      "9                  XGBRegressor  1.241065   3.485617  1.866981  -0.735834   \n",
      "8           ExtraTreesRegressor  1.259013   3.621052  1.902906  -0.803281   \n",
      "3       Decision Tree Regressor  1.281578   3.827782  1.956472  -0.906232   \n",
      "12                          SVM  1.394352   3.951478  1.987832  -0.967833   \n",
      "0             Linear Regression  3.922284  33.517111  5.789396 -15.691493   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.514780         -1.379556  \n",
      "1        2.570017         -2.841808  \n",
      "2        2.851267         -1.323544  \n",
      "13       2.955532         -2.653736  \n",
      "5        2.987651         -3.225636  \n",
      "4        3.024483         -2.707493  \n",
      "7        3.025843         -2.651081  \n",
      "10       3.090430         -2.767505  \n",
      "11       3.128529         -3.365224  \n",
      "6        3.129927         -2.876123  \n",
      "14       3.144792         -3.150545  \n",
      "9        3.169793         -3.372819  \n",
      "8        3.254101         -3.152377  \n",
      "3        3.382790         -3.994337  \n",
      "12       3.459791         -3.078002  \n",
      "0       21.864366        -13.016144  \n",
      "ok\n",
      "Predictions for the next 12 periods (118-129) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.60100112 14.57985563 14.52329004 14.64140378 14.54836109 14.53274328\n",
      " 14.56947824 14.61338099 14.63207452 14.21572042 14.25942748 14.80628609]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.32454041 -0.32760108 -0.33578855 -0.31869241 -0.33215969 -0.33442026\n",
      " -0.32910313 -0.32274851 -0.32004275 -0.38030712 -0.37398083 -0.29482684]\n",
      "This is the 19th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE  R Squared  \\\n",
      "15                     stacking  1.102215   2.440928  1.562347  -0.215580   \n",
      "1              Ridge Regression  1.152110   2.508421  1.583800  -0.249192   \n",
      "2              Lasso Regression  1.206629   2.977283  1.725480  -0.482684   \n",
      "5   Gradient Boosting Regressor  1.155306   3.041647  1.744032  -0.514738   \n",
      "13                      bagging  1.186831   3.097284  1.759910  -0.542445   \n",
      "7              BaggingRegressor  1.194537   3.232222  1.797838  -0.609644   \n",
      "4       Random Forest Regressor  1.207464   3.281118  1.811386  -0.633994   \n",
      "9                  XGBRegressor  1.206313   3.330577  1.824987  -0.658625   \n",
      "14                     boosting  1.208590   3.340066  1.827585  -0.663350   \n",
      "10               XGBRFRegressor  1.204849   3.347112  1.829511  -0.666859   \n",
      "6            Adaboost Regressor  1.254204   3.451846  1.857914  -0.719016   \n",
      "11                     LightGBM  1.242579   3.454533  1.858637  -0.720355   \n",
      "3       Decision Tree Regressor  1.256436   3.712463  1.926775  -0.848804   \n",
      "8           ExtraTreesRegressor  1.292312   3.762149  1.939626  -0.873547   \n",
      "12                          SVM  1.370266   3.858654  1.964346  -0.921607   \n",
      "0             Linear Regression  2.689937  15.697625  3.962023  -6.817404   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.519475         -0.832900  \n",
      "1        2.561489         -2.870790  \n",
      "2        2.853355         -1.328347  \n",
      "5        2.893422         -3.082045  \n",
      "13       2.928056         -2.615176  \n",
      "7        3.012055         -3.190954  \n",
      "4        3.042493         -3.062713  \n",
      "9        3.073281         -3.579395  \n",
      "14       3.079188         -3.581323  \n",
      "10       3.083574         -2.996800  \n",
      "6        3.148771         -2.945013  \n",
      "11       3.150443         -3.263589  \n",
      "3        3.311005         -5.125594  \n",
      "8        3.341934         -3.273587  \n",
      "12       3.402008         -3.100098  \n",
      "0       10.771755        -14.948021  \n",
      "ok\n",
      "Predictions for the next 12 periods (119-130) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.52045754 14.45612472 14.61634905 14.51491937 14.49817576 14.53889906\n",
      " 14.58756339 14.60688856 14.25847429 14.3062291  14.80354602 15.00995936]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.33619854 -0.34551027 -0.32231891 -0.33700015 -0.33942367 -0.33352926\n",
      " -0.32648543 -0.32368825 -0.3741188  -0.36720662 -0.29522344 -0.26534654]\n",
      "This is the 20th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "0             Linear Regression  1.019792  2.298339  1.516027  -0.144571   \n",
      "1              Ridge Regression  1.152873  2.510773  1.584542  -0.250363   \n",
      "15                     stacking  1.163416  2.647388  1.627080  -0.318397   \n",
      "5   Gradient Boosting Regressor  1.114406  2.849963  1.688183  -0.419279   \n",
      "2              Lasso Regression  1.207065  2.982147  1.726889  -0.485107   \n",
      "13                      bagging  1.211092  3.199819  1.788804  -0.593507   \n",
      "10               XGBRFRegressor  1.191865  3.278513  1.810666  -0.632697   \n",
      "9                  XGBRegressor  1.196249  3.291658  1.814293  -0.639243   \n",
      "6            Adaboost Regressor  1.247412  3.399741  1.843839  -0.693068   \n",
      "4       Random Forest Regressor  1.239486  3.450700  1.857606  -0.718446   \n",
      "14                     boosting  1.256144  3.582292  1.892694  -0.783978   \n",
      "7              BaggingRegressor  1.273636  3.582307  1.892698  -0.783986   \n",
      "8           ExtraTreesRegressor  1.259536  3.620381  1.902730  -0.802947   \n",
      "11                     LightGBM  1.289694  3.718585  1.928363  -0.851852   \n",
      "12                          SVM  1.370860  3.861561  1.965086  -0.923054   \n",
      "3       Decision Tree Regressor  1.349921  3.942113  1.985475  -0.963169   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "0        2.430714        -22.967612  \n",
      "1        2.562953         -3.341118  \n",
      "15       2.647997         -1.767251  \n",
      "5        2.774099         -3.976615  \n",
      "2        2.856384         -1.890015  \n",
      "13       2.991884         -3.778808  \n",
      "10       3.040871         -3.910339  \n",
      "9        3.049054         -4.995967  \n",
      "6        3.116335         -4.011832  \n",
      "4        3.148057         -3.521693  \n",
      "14       3.229973         -4.268193  \n",
      "7        3.229983         -4.117750  \n",
      "8        3.253684         -4.174925  \n",
      "11       3.314816         -4.375413  \n",
      "12       3.403818         -3.433418  \n",
      "3        3.453961         -6.917497  \n",
      "ok\n",
      "Predictions for the next 12 periods (120-131) using Linear Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[ 4.14978558  1.14271389 -0.47829527  3.80444918  8.61507039 11.42822121\n",
      " 10.47411424 12.17318767 14.29625944 19.71456137 24.35173124 30.01695435]\n",
      "Predictions for the next 12 periods:\n",
      "[-1.83728144 -2.27253423 -2.50716408 -1.88726649 -1.19096241 -0.78377832\n",
      " -0.92187869 -0.67594959 -0.36864966  0.415612    1.08681021  1.906812  ]\n",
      "This is the 21th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "0             Linear Regression  0.612790  0.879083  0.937594   0.562218   \n",
      "1              Ridge Regression  1.151136  2.505552  1.582894  -0.247763   \n",
      "15                     stacking  1.173254  2.617350  1.617823  -0.303438   \n",
      "5   Gradient Boosting Regressor  1.116325  2.874819  1.695529  -0.431657   \n",
      "2              Lasso Regression  1.207502  2.987043  1.728306  -0.487545   \n",
      "13                      bagging  1.199072  3.178707  1.782893  -0.582994   \n",
      "10               XGBRFRegressor  1.184349  3.256335  1.804532  -0.621652   \n",
      "9                  XGBRegressor  1.190905  3.265558  1.807085  -0.626245   \n",
      "7              BaggingRegressor  1.212663  3.265639  1.807108  -0.626285   \n",
      "4       Random Forest Regressor  1.247241  3.470258  1.862863  -0.728185   \n",
      "6            Adaboost Regressor  1.270062  3.508461  1.873089  -0.747211   \n",
      "14                     boosting  1.251722  3.553011  1.884943  -0.769396   \n",
      "11                     LightGBM  1.261671  3.653423  1.911393  -0.819401   \n",
      "8           ExtraTreesRegressor  1.268468  3.683605  1.919272  -0.834432   \n",
      "12                          SVM  1.371491  3.864684  1.965880  -0.924610   \n",
      "3       Decision Tree Regressor  1.328347  3.982486  1.995617  -0.983275   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "0        1.547228        -22.733960  \n",
      "1        2.559704         -3.236017  \n",
      "15       2.629298         -1.851150  \n",
      "5        2.789572         -4.616269  \n",
      "2        2.859431         -2.274952  \n",
      "13       2.978742         -4.530609  \n",
      "10       3.027065         -4.843911  \n",
      "9        3.032806         -5.570751  \n",
      "7        3.032857         -3.971488  \n",
      "4        3.160232         -4.173754  \n",
      "6        3.184013         -4.783313  \n",
      "14       3.211746         -5.707390  \n",
      "11       3.274252         -5.279832  \n",
      "8        3.293041         -5.467838  \n",
      "12       3.405762         -4.370721  \n",
      "3        3.479093         -7.402132  \n",
      "ok\n",
      "Predictions for the next 12 periods (121-132) using Linear Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[ 5.10488611  3.60925664  7.13734447 11.46261495 13.50516312 12.61612087\n",
      " 15.42500312 17.96961704 23.2534931  26.27954308 31.75650099 40.7243153 ]\n",
      "Predictions for the next 12 periods:\n",
      "[-1.69903726 -1.91551926 -1.404853   -0.77880006 -0.48315537 -0.61183808\n",
      " -0.20527183  0.1630434   0.92784785  1.36584761  2.15859932  3.4566283 ]\n",
      "This is the 22th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "15                     stacking  1.089520  2.366305  1.538280  -0.178418   \n",
      "1              Ridge Regression  1.152782  2.511514  1.584776  -0.250732   \n",
      "5   Gradient Boosting Regressor  1.119878  2.876853  1.696129  -0.432670   \n",
      "2              Lasso Regression  1.208204  2.994931  1.730587  -0.491473   \n",
      "9                  XGBRegressor  1.176074  3.188874  1.785742  -0.588056   \n",
      "7              BaggingRegressor  1.203227  3.211266  1.792001  -0.599208   \n",
      "10               XGBRFRegressor  1.209036  3.351414  1.830687  -0.669001   \n",
      "13                      bagging  1.245175  3.392978  1.842004  -0.689700   \n",
      "0             Linear Regression  1.093172  3.400490  1.844042  -0.693441   \n",
      "4       Random Forest Regressor  1.250476  3.509792  1.873444  -0.747874   \n",
      "14                     boosting  1.258180  3.573783  1.890445  -0.779741   \n",
      "11                     LightGBM  1.255897  3.575786  1.890975  -0.780738   \n",
      "6            Adaboost Regressor  1.283187  3.608326  1.899559  -0.796943   \n",
      "8           ExtraTreesRegressor  1.270695  3.690771  1.921138  -0.838001   \n",
      "3       Decision Tree Regressor  1.311026  3.825180  1.955807  -0.904936   \n",
      "12                          SVM  1.372541  3.869667  1.967147  -0.927091   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.473022         -1.508477  \n",
      "1        2.563415         -2.301995  \n",
      "5        2.790838         -4.562711  \n",
      "2        2.864342         -1.947053  \n",
      "9        2.985071         -5.299551  \n",
      "7        2.999010         -3.808402  \n",
      "10       3.086251         -4.085541  \n",
      "13       3.112126         -4.004437  \n",
      "0        3.116802        -23.257032  \n",
      "4        3.184842         -3.910864  \n",
      "14       3.224676         -4.429298  \n",
      "11       3.225923         -4.770935  \n",
      "6        3.246179         -4.762117  \n",
      "8        3.297501         -3.996999  \n",
      "3        3.381171         -7.089968  \n",
      "12       3.408864         -3.269388  \n",
      "ok\n",
      "Predictions for the next 12 periods (122-133) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.67455262 14.65669835 14.70299292 14.75917484 14.78129529 14.82604791\n",
      " 14.87987289 15.00844927 15.24467293 15.567937   16.22402034 16.49404942]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.31389434 -0.31647862 -0.30977781 -0.30164586 -0.29844408 -0.29196645\n",
      " -0.28417566 -0.26556512 -0.23137338 -0.18458314 -0.08961963 -0.05053479]\n",
      "This is the 23th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "15                     stacking  0.857325  1.540938  1.241345   0.232614   \n",
      "1              Ridge Regression  1.130912  2.434579  1.560314  -0.212418   \n",
      "5   Gradient Boosting Regressor  1.132575  2.955624  1.719193  -0.471898   \n",
      "2              Lasso Regression  1.208839  3.002094  1.732655  -0.495040   \n",
      "10               XGBRFRegressor  1.195857  3.251192  1.803106  -0.619091   \n",
      "6            Adaboost Regressor  1.232633  3.329072  1.824574  -0.657875   \n",
      "13                      bagging  1.240816  3.338651  1.827198  -0.662645   \n",
      "14                     boosting  1.236419  3.481563  1.865895  -0.733816   \n",
      "4       Random Forest Regressor  1.258946  3.529503  1.878697  -0.757689   \n",
      "9                  XGBRegressor  1.251019  3.556250  1.885802  -0.771010   \n",
      "7              BaggingRegressor  1.270825  3.570850  1.889669  -0.778280   \n",
      "11                     LightGBM  1.271513  3.635207  1.906622  -0.810330   \n",
      "8           ExtraTreesRegressor  1.272244  3.689868  1.920903  -0.837551   \n",
      "3       Decision Tree Regressor  1.316538  3.863946  1.965692  -0.924242   \n",
      "12                          SVM  1.373580  3.874866  1.968468  -0.929680   \n",
      "0             Linear Regression  1.181444  4.363302  2.088852  -1.172921   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       1.959233         -1.415333  \n",
      "1        2.515523         -1.184734  \n",
      "5        2.839873         -4.133176  \n",
      "2        2.868801         -1.606422  \n",
      "10       3.023863         -3.815126  \n",
      "6        3.072344         -4.150640  \n",
      "13       3.078307         -3.453455  \n",
      "14       3.167270         -4.240359  \n",
      "4        3.197112         -3.372302  \n",
      "9        3.213762         -4.533700  \n",
      "7        3.222850         -3.773218  \n",
      "11       3.262913         -4.366008  \n",
      "8        3.296939         -3.059918  \n",
      "3        3.405302         -6.939724  \n",
      "12       3.412100         -2.813078  \n",
      "0        3.716151       -100.593599  \n",
      "ok\n",
      "Predictions for the next 12 periods (123-134) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.39392958 13.50947902 13.69050805 13.76044926 14.01743324 14.17556361\n",
      " 14.55657455 15.21921944 16.1774124  17.71677718 18.83692623 19.95590159]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.49925565 -0.48253067 -0.45632798 -0.44620447 -0.40900782 -0.38611954\n",
      " -0.33097085 -0.2350576  -0.0963658   0.12644658  0.2885804   0.45054433]\n",
      "This is the 24th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   15.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "15                     stacking  0.957126  1.880038  1.371145   0.063743   \n",
      "1              Ridge Regression  1.090266  2.273989  1.507975  -0.132444   \n",
      "5   Gradient Boosting Regressor  1.073401  2.759611  1.661208  -0.374284   \n",
      "7              BaggingRegressor  1.120503  2.859213  1.690921  -0.423886   \n",
      "2              Lasso Regression  1.208917  3.002975  1.732909  -0.495479   \n",
      "10               XGBRFRegressor  1.151799  3.102278  1.761329  -0.544932   \n",
      "4       Random Forest Regressor  1.189916  3.235641  1.798789  -0.611347   \n",
      "9                  XGBRegressor  1.167862  3.280140  1.811116  -0.633507   \n",
      "14                     boosting  1.207615  3.377335  1.837753  -0.681910   \n",
      "6            Adaboost Regressor  1.256951  3.433530  1.852979  -0.709895   \n",
      "13                      bagging  1.253907  3.444607  1.855965  -0.715411   \n",
      "8           ExtraTreesRegressor  1.227833  3.552470  1.884800  -0.769127   \n",
      "3       Decision Tree Regressor  1.242916  3.592251  1.895323  -0.788938   \n",
      "11                     LightGBM  1.269472  3.679728  1.918262  -0.832502   \n",
      "12                          SVM  1.340008  3.712854  1.926877  -0.848998   \n",
      "0             Linear Regression  1.451479  6.697614  2.587975  -2.335406   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.170321         -1.828970  \n",
      "1        2.415556         -1.252889  \n",
      "5        2.717855         -4.127827  \n",
      "7        2.779857         -4.082792  \n",
      "2        2.869349         -1.579348  \n",
      "10       2.931165         -3.665565  \n",
      "4        3.014183         -3.225381  \n",
      "9        3.041884         -4.472552  \n",
      "14       3.102387         -3.664885  \n",
      "6        3.137369         -4.197930  \n",
      "13       3.144264         -3.158137  \n",
      "8        3.211409         -2.921365  \n",
      "3        3.236172         -6.544632  \n",
      "11       3.290627         -4.220765  \n",
      "12       3.311248         -2.843026  \n",
      "0        5.169258        -99.415451  \n",
      "ok\n",
      "Predictions for the next 12 periods (124-135) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.56752599 13.66015232 13.75611064 13.88696598 14.02369594 14.31351506\n",
      " 14.78730539 15.41565858 16.52611269 17.65821887 18.61697153 19.18502729]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.47412878 -0.46072176 -0.44683246 -0.42789205 -0.40810134 -0.36615203\n",
      " -0.29757416 -0.20662439 -0.04589385  0.11797067  0.25674348  0.33896561]\n",
      "This is the 25th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "15                     stacking  0.873946  1.617423  1.271779   0.194525   \n",
      "1              Ridge Regression  1.082829  2.263052  1.504344  -0.126998   \n",
      "5   Gradient Boosting Regressor  1.071326  2.793018  1.671232  -0.390921   \n",
      "9                  XGBRegressor  1.099957  2.953056  1.718446  -0.470620   \n",
      "2              Lasso Regression  1.208840  3.002104  1.732658  -0.495045   \n",
      "10               XGBRFRegressor  1.148429  3.135470  1.770726  -0.561461   \n",
      "13                      bagging  1.209236  3.217225  1.793662  -0.602175   \n",
      "7              BaggingRegressor  1.188141  3.229075  1.796963  -0.608077   \n",
      "4       Random Forest Regressor  1.191071  3.254387  1.803992  -0.620682   \n",
      "6            Adaboost Regressor  1.217139  3.267205  1.807541  -0.627065   \n",
      "14                     boosting  1.195254  3.374947  1.837103  -0.680721   \n",
      "8           ExtraTreesRegressor  1.179507  3.382758  1.839227  -0.684610   \n",
      "12                          SVM  1.298463  3.534723  1.880086  -0.760289   \n",
      "11                     LightGBM  1.253138  3.611122  1.900295  -0.798336   \n",
      "3       Decision Tree Regressor  1.316836  3.957739  1.989407  -0.970951   \n",
      "0             Linear Regression  1.301053  5.386465  2.320876  -1.682455   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.006844         -1.586735  \n",
      "1        2.408748         -0.852642  \n",
      "5        2.738651         -3.074436  \n",
      "9        2.838274         -3.856011  \n",
      "2        2.868806         -1.102194  \n",
      "10       2.951827         -2.945853  \n",
      "13       3.002719         -2.391161  \n",
      "7        3.010096         -2.744815  \n",
      "4        3.025852         -2.500432  \n",
      "6        3.033831         -3.290372  \n",
      "14       3.100901         -3.397015  \n",
      "8        3.105763         -1.583653  \n",
      "12       3.200362         -2.057394  \n",
      "11       3.247920         -2.925905  \n",
      "3        3.463689         -5.612505  \n",
      "0        4.353069        -44.913956  \n",
      "ok\n",
      "Predictions for the next 12 periods (125-136) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.73983918 13.84345494 14.0948678  14.31408872 14.71609574 15.31933725\n",
      " 16.08930468 17.38609652 18.81378639 20.05070376 20.88857191 21.48228146]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.44918764 -0.43418997 -0.3977997  -0.366069   -0.30788126 -0.22056624\n",
      " -0.10911878  0.07858285  0.28523106  0.46426628  0.58554189  0.67147723]\n",
      "This is the 26th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "15                     stacking  0.905117  1.695519  1.302121   0.155633   \n",
      "1              Ridge Regression  1.086819  2.314851  1.521463  -0.152794   \n",
      "9                  XGBRegressor  1.001997  2.491655  1.578498  -0.240842   \n",
      "5   Gradient Boosting Regressor  1.059329  2.722731  1.650070  -0.355918   \n",
      "0             Linear Regression  0.950336  2.804238  1.674586  -0.396508   \n",
      "2              Lasso Regression  1.208793  3.001576  1.732506  -0.494783   \n",
      "14                     boosting  1.135169  3.087407  1.757102  -0.537526   \n",
      "6            Adaboost Regressor  1.176763  3.111887  1.764054  -0.549717   \n",
      "10               XGBRFRegressor  1.143814  3.125124  1.767802  -0.556309   \n",
      "13                      bagging  1.187883  3.137699  1.771355  -0.562571   \n",
      "4       Random Forest Regressor  1.168745  3.174518  1.781718  -0.580907   \n",
      "12                          SVM  1.219679  3.217405  1.793713  -0.602265   \n",
      "8           ExtraTreesRegressor  1.157110  3.278336  1.810617  -0.632608   \n",
      "11                     LightGBM  1.203157  3.351648  1.830751  -0.669118   \n",
      "7              BaggingRegressor  1.237124  3.510238  1.873563  -0.748096   \n",
      "3       Decision Tree Regressor  1.233320  3.557194  1.886052  -0.771480   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.055459         -1.578997  \n",
      "1        2.440992         -0.934410  \n",
      "9        2.551052         -3.883079  \n",
      "5        2.694897         -2.530820  \n",
      "0        2.745635        -28.035050  \n",
      "2        2.868478         -0.858832  \n",
      "14       2.921908         -2.374208  \n",
      "6        2.937147         -2.986922  \n",
      "10       2.945387         -2.724501  \n",
      "13       2.953214         -2.032474  \n",
      "4        2.976134         -2.201660  \n",
      "12       3.002831         -1.483275  \n",
      "8        3.040761         -1.013908  \n",
      "11       3.086397         -2.587246  \n",
      "7        3.185120         -2.338753  \n",
      "3        3.214350         -4.938191  \n",
      "ok\n",
      "Predictions for the next 12 periods (126-137) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.24527906 14.48608295 14.73501238 15.07815662 15.62224529 16.28307209\n",
      " 17.34835945 18.56855391 19.65744288 20.40287217 20.96433755 21.45445969]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.37602872 -0.34117402 -0.30514321 -0.25547546 -0.1767224  -0.0810723\n",
      "  0.07312067  0.24973536  0.4073445   0.51524022  0.59650844  0.66745023]\n",
      "This is the 27th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "15                     stacking  0.989262  1.967734  1.402759   0.020070   \n",
      "1              Ridge Regression  1.097056  2.437588  1.561278  -0.213917   \n",
      "9                  XGBRegressor  0.997402  2.514363  1.585674  -0.252151   \n",
      "5   Gradient Boosting Regressor  1.078103  2.872427  1.694824  -0.430466   \n",
      "8           ExtraTreesRegressor  1.084761  2.909973  1.705864  -0.449164   \n",
      "3       Decision Tree Regressor  1.073860  2.967971  1.722780  -0.478047   \n",
      "10               XGBRFRegressor  1.111066  2.987174  1.728344  -0.487610   \n",
      "7              BaggingRegressor  1.115859  2.991425  1.729574  -0.489727   \n",
      "4       Random Forest Regressor  1.126818  2.992131  1.729778  -0.490079   \n",
      "2              Lasso Regression  1.208386  2.996980  1.731179  -0.492494   \n",
      "6            Adaboost Regressor  1.164827  3.057134  1.748466  -0.522450   \n",
      "13                      bagging  1.165676  3.067652  1.751471  -0.527688   \n",
      "0             Linear Regression  0.993491  3.100602  1.760853  -0.544097   \n",
      "12                          SVM  1.195487  3.105289  1.762183  -0.546431   \n",
      "14                     boosting  1.153438  3.241374  1.800382  -0.614202   \n",
      "11                     LightGBM  1.203821  3.413579  1.847587  -0.699959   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.224912         -1.709252  \n",
      "1        2.517396         -1.131050  \n",
      "9        2.565189         -3.001020  \n",
      "5        2.788083         -2.249734  \n",
      "8        2.811455         -0.774920  \n",
      "3        2.847559         -5.291140  \n",
      "10       2.859513         -2.542032  \n",
      "7        2.862159         -1.876752  \n",
      "4        2.862598         -1.885039  \n",
      "2        2.865617         -0.678797  \n",
      "6        2.903062         -2.411646  \n",
      "13       2.909610         -1.510017  \n",
      "0        2.930122        -92.004826  \n",
      "12       2.933039         -1.510892  \n",
      "14       3.017752         -2.951903  \n",
      "11       3.124949         -2.194709  \n",
      "ok\n",
      "Predictions for the next 12 periods (127-138) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.53895856 15.09165129 15.40361877 15.72373718 16.18714828 16.8815562\n",
      " 17.69575887 18.14930934 18.66938223 19.34553956 19.7155022  20.13743941]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.33352064 -0.2535222  -0.20836707 -0.16203215 -0.0949566   0.00555413\n",
      "  0.12340433  0.18905262  0.26432956  0.36219865  0.41574818  0.47682067]\n",
      "This is the 28th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "15                     stacking  1.070298  2.281884  1.510590  -0.136376   \n",
      "8           ExtraTreesRegressor  1.037425  2.660512  1.631108  -0.324933   \n",
      "14                     boosting  1.034896  2.668526  1.633562  -0.328924   \n",
      "1              Ridge Regression  1.130551  2.698234  1.642630  -0.343718   \n",
      "12                          SVM  1.119905  2.800061  1.673338  -0.394428   \n",
      "4       Random Forest Regressor  1.087101  2.802695  1.674125  -0.395740   \n",
      "10               XGBRFRegressor  1.069330  2.814132  1.677538  -0.401436   \n",
      "7              BaggingRegressor  1.088749  2.832813  1.683096  -0.410738   \n",
      "5   Gradient Boosting Regressor  1.074537  2.874987  1.695579  -0.431741   \n",
      "9                  XGBRegressor  1.079441  2.967024  1.722505  -0.477576   \n",
      "6            Adaboost Regressor  1.140693  2.970782  1.723596  -0.479447   \n",
      "2              Lasso Regression  1.207630  2.988480  1.728722  -0.488261   \n",
      "13                      bagging  1.160440  2.997145  1.731227  -0.492576   \n",
      "3       Decision Tree Regressor  1.126826  3.163633  1.778661  -0.575487   \n",
      "11                     LightGBM  1.158760  3.222729  1.795196  -0.604916   \n",
      "0             Linear Regression  1.126973  4.163733  2.040523  -1.073535   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "15       2.420470         -0.849187  \n",
      "8        2.656166         -0.639175  \n",
      "14       2.661155         -2.199804  \n",
      "1        2.679648         -1.199857  \n",
      "12       2.743035         -1.557482  \n",
      "4        2.744675         -1.694322  \n",
      "10       2.751794         -2.025016  \n",
      "7        2.763423         -1.663393  \n",
      "5        2.789677         -1.935500  \n",
      "9        2.846969         -2.449921  \n",
      "6        2.849309         -1.731879  \n",
      "2        2.860326         -0.541704  \n",
      "13       2.865720         -1.162411  \n",
      "3        2.969358         -4.170568  \n",
      "11       3.006145         -1.816695  \n",
      "0        3.591919       -120.248228  \n",
      "ok\n",
      "Predictions for the next 12 periods (128-139) using stacking:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[15.29337315 15.48557979 15.73275367 16.00971771 16.40132104 16.87018795\n",
      " 17.30876242 17.59241841 17.80028786 17.37864472 17.68095822 17.78639238]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.22432436 -0.19650378 -0.16072707 -0.12063845 -0.06395658  0.00390866\n",
      "  0.06738927  0.10844651  0.13853417  0.07750425  0.12126204  0.1365229 ]\n",
      "This is the 29th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "3       Decision Tree Regressor  0.716254  1.291446  1.136418   0.356861   \n",
      "5   Gradient Boosting Regressor  0.864781  1.925167  1.387504   0.041269   \n",
      "7              BaggingRegressor  0.907134  2.022085  1.422000  -0.006997   \n",
      "8           ExtraTreesRegressor  0.909375  2.155346  1.468110  -0.073360   \n",
      "15                     stacking  1.033488  2.176431  1.475273  -0.083861   \n",
      "14                     boosting  0.937434  2.288911  1.512915  -0.139876   \n",
      "4       Random Forest Regressor  0.977060  2.321857  1.523764  -0.156283   \n",
      "12                          SVM  1.067737  2.590547  1.609518  -0.290090   \n",
      "10               XGBRFRegressor  1.029006  2.648239  1.627341  -0.318821   \n",
      "13                      bagging  1.083901  2.664724  1.632398  -0.327031   \n",
      "9                  XGBRegressor  1.007348  2.680324  1.637170  -0.334799   \n",
      "6            Adaboost Regressor  1.082677  2.708921  1.645880  -0.349041   \n",
      "11                     LightGBM  1.057575  2.748876  1.657974  -0.368938   \n",
      "2              Lasso Regression  1.205895  2.969108  1.723110  -0.478614   \n",
      "1              Ridge Regression  1.202675  3.284072  1.812201  -0.635465   \n",
      "0             Linear Regression  1.145108  4.326896  2.080119  -1.154790   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "3        1.803924         -2.888975  \n",
      "5        2.198414         -1.398143  \n",
      "7        2.258746         -1.353929  \n",
      "8        2.341700         -0.481944  \n",
      "15       2.354826         -0.737607  \n",
      "14       2.424845         -1.299275  \n",
      "4        2.445354         -0.940913  \n",
      "12       2.612613         -1.572774  \n",
      "10       2.648526         -1.261939  \n",
      "13       2.658788         -0.720624  \n",
      "9        2.668499         -1.671952  \n",
      "6        2.686301         -1.054933  \n",
      "11       2.711173         -1.272687  \n",
      "2        2.848267         -0.433742  \n",
      "1        3.044331         -1.281930  \n",
      "0        3.693488       -112.481686  \n",
      "ok\n",
      "Predictions for the next 12 periods (129-140) using Decision Tree Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[22.38108216 22.38108216 22.38108216 22.38108216 22.38108216 22.38108216\n",
      " 22.38108216 22.38108216 22.38108216 22.38108216 22.38108216 22.38108216]\n",
      "Predictions for the next 12 periods:\n",
      "[0.80157241 0.80157241 0.80157241 0.80157241 0.80157241 0.80157241\n",
      " 0.80157241 0.80157241 0.80157241 0.80157241 0.80157241 0.80157241]\n",
      "This is the 30th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "3       Decision Tree Regressor  0.417076  0.510865  0.714748   0.745590   \n",
      "14                     boosting  0.514830  0.726768  0.852507   0.638070   \n",
      "7              BaggingRegressor  0.610764  0.919103  0.958699   0.542287   \n",
      "5   Gradient Boosting Regressor  0.618616  1.006212  1.003101   0.498907   \n",
      "8           ExtraTreesRegressor  0.652837  1.156886  1.075586   0.423872   \n",
      "4       Random Forest Regressor  0.725467  1.267042  1.125630   0.369014   \n",
      "13                      bagging  0.837333  1.595886  1.263284   0.205250   \n",
      "6            Adaboost Regressor  0.823087  1.642945  1.281774   0.181815   \n",
      "11                     LightGBM  0.884795  1.927662  1.388403   0.040026   \n",
      "12                          SVM  1.009099  2.345739  1.531581  -0.168176   \n",
      "10               XGBRFRegressor  0.957527  2.444037  1.563342  -0.217128   \n",
      "9                  XGBRegressor  0.957268  2.609474  1.615387  -0.299516   \n",
      "2              Lasso Regression  1.203398  2.937317  1.713860  -0.462781   \n",
      "15                     stacking  1.240097  3.067370  1.751391  -0.527548   \n",
      "1              Ridge Regression  1.329003  4.265326  2.065267  -1.124129   \n",
      "0             Linear Regression  1.242075  5.059872  2.249416  -1.519812   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "3        1.318013         -3.025210  \n",
      "14       1.452412         -1.143224  \n",
      "7        1.572141         -0.866817  \n",
      "5        1.626366         -1.420802  \n",
      "8        1.720160         -0.560422  \n",
      "4        1.788732         -0.808124  \n",
      "13       1.993437         -0.571077  \n",
      "6        2.022731         -0.774930  \n",
      "11       2.199968         -0.880438  \n",
      "12       2.460220         -1.710738  \n",
      "10       2.521411         -1.048696  \n",
      "9        2.624395         -1.114008  \n",
      "2        2.828477         -0.347447  \n",
      "15       2.909435         -0.700888  \n",
      "1        3.655161         -1.527904  \n",
      "0        4.149765      -2604.737851  \n",
      "ok\n",
      "Predictions for the next 12 periods (130-141) using Decision Tree Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[27.74224957 27.74224957 27.74224957 27.74224957 27.74224957 27.74224957\n",
      " 27.74224957 27.74224957 27.74224957 27.74224957 27.74224957 27.74224957]\n",
      "Predictions for the next 12 periods:\n",
      "[1.57756424 1.57756424 1.57756424 1.57756424 1.57756424 1.57756424\n",
      " 1.57756424 1.57756424 1.57756424 1.57756424 1.57756424 1.57756424]\n",
      "This is the 31th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "8           ExtraTreesRegressor  0.304674  0.338237  0.581581   0.831558   \n",
      "5   Gradient Boosting Regressor  0.296438  0.348714  0.590520   0.826341   \n",
      "6            Adaboost Regressor  0.403306  0.374920  0.612307   0.813290   \n",
      "7              BaggingRegressor  0.372113  0.389711  0.624268   0.805924   \n",
      "4       Random Forest Regressor  0.410335  0.409997  0.640310   0.795822   \n",
      "14                     boosting  0.359264  0.425836  0.652561   0.787934   \n",
      "3       Decision Tree Regressor  0.426642  0.840011  0.916521   0.581675   \n",
      "11                     LightGBM  0.681853  1.129695  1.062871   0.437413   \n",
      "13                      bagging  0.759459  1.263386  1.124005   0.370835   \n",
      "15                     stacking  0.806259  1.274646  1.129002   0.365227   \n",
      "12                          SVM  0.879551  1.849994  1.360145   0.078705   \n",
      "10               XGBRFRegressor  0.900054  2.239532  1.496507  -0.115285   \n",
      "9                  XGBRegressor  0.938950  2.609231  1.615311  -0.299395   \n",
      "2              Lasso Regression  1.203192  2.883201  1.697999  -0.435832   \n",
      "1              Ridge Regression  1.586277  6.369241  2.523735  -2.171876   \n",
      "0             Linear Regression  1.576163  7.703188  2.775462  -2.836181   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "8        1.210552         -0.428457  \n",
      "5        1.217074         -1.213588  \n",
      "6        1.233387         -0.851320  \n",
      "7        1.242595         -1.221249  \n",
      "4        1.255223         -0.629819  \n",
      "14       1.265082         -0.727969  \n",
      "3        1.522906         -2.088565  \n",
      "11       1.703234         -0.869113  \n",
      "13       1.786457         -0.300144  \n",
      "15       1.793466         -0.612506  \n",
      "12       2.151619         -1.558048  \n",
      "10       2.394106         -0.745135  \n",
      "9        2.624243         -0.636008  \n",
      "2        2.794790         -0.319441  \n",
      "1        4.964846         -1.741673  \n",
      "0        5.795226        -28.779936  \n",
      "ok\n",
      "Predictions for the next 12 periods (131-142) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[33.27347131 32.02226476 31.3993771  30.83694723 30.58542761 29.73124388\n",
      " 28.26818618 26.86743076 26.72425147 28.70128734 29.33635317 27.59642752]\n",
      "Predictions for the next 12 periods:\n",
      "[2.37817026 2.19706679 2.10690811 2.02550029 1.98909456 1.86545739\n",
      " 1.65368992 1.45094028 1.43021607 1.71637831 1.80829969 1.55645751]\n",
      "This is the 32th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "5   Gradient Boosting Regressor  0.270967  0.257837  0.507776   0.871598   \n",
      "4       Random Forest Regressor  0.347884  0.323865  0.569091   0.838716   \n",
      "7              BaggingRegressor  0.358802  0.330040  0.574491   0.835641   \n",
      "14                     boosting  0.323921  0.364633  0.603849   0.818413   \n",
      "6            Adaboost Regressor  0.377844  0.426807  0.653305   0.787450   \n",
      "8           ExtraTreesRegressor  0.335432  0.427971  0.654195   0.786871   \n",
      "13                      bagging  0.508279  0.525792  0.725115   0.738156   \n",
      "3       Decision Tree Regressor  0.373520  0.701102  0.837318   0.650852   \n",
      "15                     stacking  0.620903  0.739965  0.860212   0.631498   \n",
      "11                     LightGBM  0.567818  0.775390  0.880562   0.613857   \n",
      "12                          SVM  0.787041  1.507058  1.227623   0.249487   \n",
      "10               XGBRFRegressor  0.858041  2.093383  1.446853  -0.042503   \n",
      "9                  XGBRegressor  0.833832  2.242640  1.497545  -0.116833   \n",
      "2              Lasso Regression  1.203688  2.836519  1.684197  -0.412584   \n",
      "1              Ridge Regression  1.546927  6.060047  2.461716  -2.017898   \n",
      "0             Linear Regression  1.516923  7.207306  2.684643  -2.589232   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "5        1.160503         -0.975155  \n",
      "4        1.201605         -0.455162  \n",
      "7        1.205449         -1.014745  \n",
      "14       1.226984         -0.540245  \n",
      "6        1.265687         -0.568653  \n",
      "8        1.266411         -0.299506  \n",
      "13       1.327305         -0.260967  \n",
      "3        1.436435         -1.510754  \n",
      "15       1.460627         -0.689142  \n",
      "11       1.482679         -0.701347  \n",
      "12       1.938142         -1.553405  \n",
      "10       2.303129         -0.583252  \n",
      "9        2.396041         -0.655785  \n",
      "2        2.765730         -0.324196  \n",
      "1        4.772373         -1.598136  \n",
      "0        5.486541        -51.051437  \n",
      "ok\n",
      "Predictions for the next 12 periods (132-143) using Gradient Boosting Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[32.14502001 32.03605186 31.56727509 31.77803812 31.7710228  31.53254314\n",
      " 28.85698217 28.13025397 30.41606819 31.61690653 31.01343572 28.8932625 ]\n",
      "Predictions for the next 12 periods:\n",
      "[2.21483476 2.19906237 2.13121018 2.16171667 2.16070125 2.12618297\n",
      " 1.73891406 1.63372519 1.96458096 2.13839399 2.05104577 1.74416539]\n",
      "This is the 33th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "14                     boosting  0.209730  0.214246  0.462867   0.893306   \n",
      "6            Adaboost Regressor  0.315568  0.224888  0.474223   0.888006   \n",
      "3       Decision Tree Regressor  0.217621  0.225273  0.474629   0.887814   \n",
      "7              BaggingRegressor  0.291894  0.232986  0.482687   0.883973   \n",
      "5   Gradient Boosting Regressor  0.291487  0.303312  0.550738   0.848951   \n",
      "4       Random Forest Regressor  0.323758  0.337174  0.580667   0.832088   \n",
      "13                      bagging  0.433962  0.423855  0.651041   0.788921   \n",
      "8           ExtraTreesRegressor  0.370113  0.503469  0.709555   0.749273   \n",
      "15                     stacking  0.548232  0.584609  0.764597   0.708865   \n",
      "11                     LightGBM  0.500371  0.611206  0.781797   0.695620   \n",
      "12                          SVM  0.688604  1.185006  1.088580   0.409868   \n",
      "10               XGBRFRegressor  0.733004  1.522492  1.233893   0.241800   \n",
      "9                  XGBRegressor  0.833045  2.235442  1.495140  -0.113248   \n",
      "2              Lasso Regression  1.204135  2.795546  1.671988  -0.392179   \n",
      "1              Ridge Regression  1.352052  4.624707  2.150513  -1.303100   \n",
      "0             Linear Regression  1.321216  5.669544  2.381081  -1.823428   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "14       1.133368         -0.753746  \n",
      "6        1.139992         -0.575797  \n",
      "3        1.140232         -1.312259  \n",
      "7        1.145034         -0.598282  \n",
      "5        1.188811         -0.863315  \n",
      "4        1.209890         -0.485336  \n",
      "13       1.263849         -0.290958  \n",
      "8        1.313409         -0.525651  \n",
      "15       1.363919         -0.709727  \n",
      "11       1.380475         -1.682255  \n",
      "12       1.737665         -1.584392  \n",
      "10       1.947750         -0.650056  \n",
      "9        2.391560         -0.572835  \n",
      "2        2.740224         -0.386968  \n",
      "1        3.878875         -1.479936  \n",
      "0        4.529286        -31.434819  \n",
      "ok\n",
      "Predictions for the next 12 periods (133-144) using boosting:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.56713616 33.86213776 33.86213776 33.86213776 33.86213776 33.86213776\n",
      " 33.86213776 33.86213776 33.86213776 33.86213776 33.86213776 33.86213776]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71016236 2.46337565 2.46337565 2.46337565 2.46337565 2.46337565\n",
      " 2.46337565 2.46337565 2.46337565 2.46337565 2.46337565 2.46337565]\n",
      "This is the 34th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "14                     boosting  0.183210  0.134937  0.367337   0.932802   \n",
      "7              BaggingRegressor  0.290800  0.221145  0.470260   0.889870   \n",
      "6            Adaboost Regressor  0.338462  0.267829  0.517522   0.866622   \n",
      "5   Gradient Boosting Regressor  0.268677  0.309979  0.556758   0.845631   \n",
      "13                      bagging  0.360655  0.330611  0.574988   0.835356   \n",
      "4       Random Forest Regressor  0.301614  0.334938  0.578738   0.833201   \n",
      "15                     stacking  0.374151  0.358597  0.598830   0.821419   \n",
      "10               XGBRFRegressor  0.350566  0.373746  0.611347   0.813875   \n",
      "8           ExtraTreesRegressor  0.319585  0.409368  0.639819   0.796135   \n",
      "9                  XGBRegressor  0.280237  0.441407  0.664384   0.780180   \n",
      "3       Decision Tree Regressor  0.288076  0.482257  0.694447   0.759836   \n",
      "11                     LightGBM  0.441623  0.489287  0.699491   0.756335   \n",
      "12                          SVM  0.580755  0.903450  0.950500   0.550083   \n",
      "0             Linear Regression  0.827980  2.558673  1.599585  -0.274217   \n",
      "2              Lasso Regression  1.204625  2.751765  1.658845  -0.370377   \n",
      "1              Ridge Regression  1.176196  3.514682  1.874748  -0.750309   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "14       1.083998         -0.826408  \n",
      "7        1.137662         -0.553374  \n",
      "6        1.166723         -0.679506  \n",
      "5        1.192962         -0.910524  \n",
      "13       1.205805         -0.323616  \n",
      "4        1.208499         -0.387402  \n",
      "15       1.223226         -2.330010  \n",
      "10       1.232656         -0.570723  \n",
      "8        1.254831         -0.324531  \n",
      "9        1.274775         -0.527764  \n",
      "3        1.300205         -1.710024  \n",
      "11       1.304581         -1.420352  \n",
      "12       1.562397         -1.628161  \n",
      "0        2.592771        -18.343236  \n",
      "2        2.712971         -0.485140  \n",
      "1        3.187886         -1.523322  \n",
      "ok\n",
      "Predictions for the next 12 periods (134-145) using boosting:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.56713616 35.56713616 35.56713616 35.56713616 33.86213776 33.86213776\n",
      " 33.86213776 33.86213776 33.86213776 33.86213776 27.74224957 27.74224957]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71016236 2.71016236 2.71016236 2.71016236 2.46337565 2.46337565\n",
      " 2.46337565 2.46337565 2.46337565 2.46337565 1.57756424 1.57756424]\n",
      "This is the 35th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "14                     boosting  0.249971  0.284126  0.533035   0.858505   \n",
      "4       Random Forest Regressor  0.290172  0.308603  0.555521   0.846316   \n",
      "15                     stacking  0.351872  0.313894  0.560262   0.843681   \n",
      "5   Gradient Boosting Regressor  0.289977  0.317291  0.563286   0.841989   \n",
      "13                      bagging  0.347286  0.340645  0.583648   0.830359   \n",
      "11                     LightGBM  0.374324  0.379973  0.616419   0.810774   \n",
      "8           ExtraTreesRegressor  0.292928  0.392837  0.626767   0.804368   \n",
      "7              BaggingRegressor  0.368634  0.407085  0.638032   0.797272   \n",
      "10               XGBRFRegressor  0.323597  0.468556  0.684512   0.766659   \n",
      "9                  XGBRegressor  0.293836  0.526475  0.725586   0.737816   \n",
      "6            Adaboost Regressor  0.404081  0.534901  0.731369   0.733620   \n",
      "3       Decision Tree Regressor  0.334450  0.664230  0.815003   0.669214   \n",
      "0             Linear Regression  0.413395  0.684347  0.827253   0.659196   \n",
      "12                          SVM  0.500908  0.726266  0.852212   0.638320   \n",
      "1              Ridge Regression  0.940802  2.249510  1.499837  -0.120254   \n",
      "2              Lasso Regression  1.205138  2.707370  1.645409  -0.348268   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "14       1.176868         -0.358153  \n",
      "4        1.192105         -0.439830  \n",
      "15       1.195399         -2.501019  \n",
      "5        1.197513         -1.076715  \n",
      "13       1.212051         -0.174559  \n",
      "11       1.236533         -1.117734  \n",
      "8        1.244541         -0.285750  \n",
      "7        1.253410         -0.472560  \n",
      "10       1.291676         -0.748428  \n",
      "9        1.327730         -0.617683  \n",
      "6        1.332975         -0.499430  \n",
      "3        1.413482         -1.783983  \n",
      "0        1.426006        -15.548797  \n",
      "12       1.452100         -1.308308  \n",
      "1        2.400318         -1.572807  \n",
      "2        2.685335         -0.623076  \n",
      "ok\n",
      "Predictions for the next 12 periods (135-146) using boosting:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[37.30144888 37.30144888 33.86213776 33.86213776 33.86213776 27.74224957\n",
      " 33.86213776 33.86213776 33.86213776 27.74224957 27.74224957 27.74224957]\n",
      "Predictions for the next 12 periods:\n",
      "[2.96119211 2.96119211 2.46337565 2.46337565 2.46337565 1.57756424\n",
      " 2.46337565 2.46337565 2.46337565 1.57756424 1.57756424 1.57756424]\n",
      "This is the 36th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "14                     boosting  0.201077  0.219619  0.468635   0.890630   \n",
      "6            Adaboost Regressor  0.320429  0.277148  0.526448   0.861981   \n",
      "8           ExtraTreesRegressor  0.266834  0.311824  0.558412   0.844712   \n",
      "7              BaggingRegressor  0.310751  0.326066  0.571022   0.837620   \n",
      "3       Decision Tree Regressor  0.280642  0.342080  0.584876   0.829644   \n",
      "11                     LightGBM  0.328688  0.345898  0.588131   0.827743   \n",
      "13                      bagging  0.362372  0.361388  0.601155   0.820029   \n",
      "4       Random Forest Regressor  0.316091  0.362002  0.601666   0.819723   \n",
      "10               XGBRFRegressor  0.304822  0.377594  0.614487   0.811959   \n",
      "9                  XGBRegressor  0.259098  0.420137  0.648180   0.790772   \n",
      "5   Gradient Boosting Regressor  0.327993  0.432899  0.657951   0.784416   \n",
      "0             Linear Regression  0.382730  0.594287  0.770900   0.704046   \n",
      "12                          SVM  0.460610  0.632172  0.795092   0.685179   \n",
      "15                     stacking  0.579169  0.712117  0.843870   0.645366   \n",
      "1              Ridge Regression  0.653813  1.056368  1.027798   0.473930   \n",
      "2              Lasso Regression  1.205611  2.667579  1.633273  -0.328452   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "14       1.136712         -0.245785  \n",
      "6        1.172524         -0.184561  \n",
      "8        1.194110         -0.115956  \n",
      "7        1.202975         -0.354204  \n",
      "3        1.212944         -0.811730  \n",
      "11       1.215321         -1.008465  \n",
      "13       1.224964          0.000355  \n",
      "4        1.225346         -0.164512  \n",
      "10       1.235052         -0.276781  \n",
      "9        1.261535         -0.509105  \n",
      "5        1.269479         -0.479679  \n",
      "0        1.369943         -6.965049  \n",
      "12       1.393526         -0.912543  \n",
      "15       1.443292         -7.620394  \n",
      "1        1.657588         -1.596734  \n",
      "2        2.660565         -0.696299  \n",
      "ok\n",
      "Predictions for the next 12 periods (136-147) using boosting:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.97986676 35.97986676 35.97986676 35.56713616 33.86213776 33.86213776\n",
      " 33.86213776 33.86213776 33.86213776 27.74224957 27.74224957 27.74224957]\n",
      "Predictions for the next 12 periods:\n",
      "[2.76990225 2.76990225 2.76990225 2.71016236 2.46337565 2.46337565\n",
      " 2.46337565 2.46337565 2.46337565 1.57756424 1.57756424 1.57756424]\n",
      "This is the 37th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "6            Adaboost Regressor  0.299770  0.237519  0.487359   0.881716   \n",
      "8           ExtraTreesRegressor  0.243666  0.264021  0.513829   0.868518   \n",
      "4       Random Forest Regressor  0.269242  0.276028  0.525384   0.862538   \n",
      "5   Gradient Boosting Regressor  0.255646  0.283385  0.532339   0.858874   \n",
      "7              BaggingRegressor  0.291092  0.322388  0.567792   0.839451   \n",
      "3       Decision Tree Regressor  0.259124  0.322500  0.567890   0.839395   \n",
      "13                      bagging  0.329777  0.340096  0.583177   0.830633   \n",
      "11                     LightGBM  0.310054  0.340486  0.583512   0.830438   \n",
      "1              Ridge Regression  0.384060  0.347137  0.589183   0.827126   \n",
      "14                     boosting  0.247377  0.354110  0.595072   0.823653   \n",
      "9                  XGBRegressor  0.262159  0.426503  0.653072   0.787602   \n",
      "10               XGBRFRegressor  0.301876  0.428255  0.654412   0.786729   \n",
      "12                          SVM  0.460174  0.629145  0.793187   0.686686   \n",
      "15                     stacking  0.593956  0.741598  0.861161   0.630685   \n",
      "0             Linear Regression  0.494754  1.070654  1.034724   0.466815   \n",
      "2              Lasso Regression  1.206733  2.634488  1.623111  -0.311973   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "6        1.147855         -0.124540  \n",
      "8        1.164353         -0.126688  \n",
      "4        1.171827         -0.164776  \n",
      "5        1.176407         -0.422963  \n",
      "7        1.200686         -0.022149  \n",
      "3        1.200756         -0.721437  \n",
      "13       1.211709         -0.011514  \n",
      "11       1.211952         -1.583488  \n",
      "1        1.216092         -1.802295  \n",
      "14       1.220433         -0.080157  \n",
      "9        1.265498         -0.421541  \n",
      "10       1.266588         -0.316629  \n",
      "12       1.391642         -0.750553  \n",
      "15       1.461644         -4.577484  \n",
      "0        1.666481         -7.548792  \n",
      "2        2.639966         -0.813788  \n",
      "ok\n",
      "Predictions for the next 12 periods (137-148) using Adaboost Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[33.86213776 33.5990227  33.5990227  33.5990227  33.5990227  33.5990227\n",
      " 33.5990227  33.33590765 33.33590765 27.74224957 27.74224957 27.74224957]\n",
      "Predictions for the next 12 periods:\n",
      "[2.46337565 2.42529157 2.42529157 2.42529157 2.42529157 2.42529157\n",
      " 2.42529157 2.38720749 2.38720749 1.57756424 1.57756424 1.57756424]\n",
      "This is the 38th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.192868  0.080770  0.284201   0.959777   \n",
      "14                     boosting  0.231317  0.281701  0.530755   0.859713   \n",
      "4       Random Forest Regressor  0.278206  0.297272  0.545227   0.851959   \n",
      "5   Gradient Boosting Regressor  0.257649  0.303683  0.551074   0.848766   \n",
      "9                  XGBRegressor  0.250401  0.316256  0.562367   0.842505   \n",
      "3       Decision Tree Regressor  0.242273  0.316535  0.562615   0.842366   \n",
      "10               XGBRFRegressor  0.282191  0.322334  0.567744   0.839478   \n",
      "11                     LightGBM  0.309537  0.330860  0.575205   0.835232   \n",
      "13                      bagging  0.339692  0.335543  0.579260   0.832900   \n",
      "6            Adaboost Regressor  0.349141  0.342295  0.585060   0.829537   \n",
      "8           ExtraTreesRegressor  0.289232  0.378119  0.614914   0.811697   \n",
      "7              BaggingRegressor  0.325207  0.385280  0.620709   0.808131   \n",
      "12                          SVM  0.472810  0.671150  0.819238   0.665768   \n",
      "0             Linear Regression  0.455003  0.915285  0.956705   0.544189   \n",
      "2              Lasso Regression  1.207619  2.610880  1.615822  -0.300216   \n",
      "15                     stacking  1.301167  3.124193  1.767539  -0.555846   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.050279         -2.129682  \n",
      "14       1.175359         -0.164342  \n",
      "4        1.185052         -0.202457  \n",
      "5        1.189042         -0.439483  \n",
      "9        1.196869         -0.542319  \n",
      "3        1.197043         -0.994987  \n",
      "10       1.200652         -0.465977  \n",
      "11       1.205960         -1.448899  \n",
      "13       1.208875         -0.086957  \n",
      "6        1.213078         -0.370713  \n",
      "8        1.235379         -0.125331  \n",
      "7        1.239836         -0.803556  \n",
      "12       1.417790         -0.775250  \n",
      "0        1.569764        -12.454763  \n",
      "2        2.625270         -0.941453  \n",
      "15       2.944807         -5.252287  \n",
      "ok\n",
      "Predictions for the next 12 periods (138-149) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[37.35997105 40.76561496 39.22253349 36.63809417 33.838554   34.57188301\n",
      " 35.74850692 33.61177652 27.60415543 20.19183491 15.97548533 14.88374104]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.96966278  3.46260614  3.23925579  2.86517611  2.45996207  2.56610636\n",
      "  2.73641452  2.4271376   1.55757607  0.48469404 -0.12559335 -0.28361577]\n",
      "This is the 39th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.188849  0.075777  0.275276   0.962263   \n",
      "14                     boosting  0.161457  0.149819  0.387065   0.925390   \n",
      "8           ExtraTreesRegressor  0.210827  0.216863  0.465686   0.892002   \n",
      "7              BaggingRegressor  0.268271  0.227225  0.476681   0.886842   \n",
      "6            Adaboost Regressor  0.279785  0.241537  0.491464   0.879715   \n",
      "4       Random Forest Regressor  0.270064  0.282952  0.531933   0.859090   \n",
      "5   Gradient Boosting Regressor  0.234797  0.301237  0.548851   0.849984   \n",
      "11                     LightGBM  0.295846  0.342111  0.584903   0.829629   \n",
      "13                      bagging  0.350290  0.356776  0.597307   0.822326   \n",
      "10               XGBRFRegressor  0.288016  0.366479  0.605375   0.817494   \n",
      "9                  XGBRegressor  0.240435  0.380487  0.616836   0.810518   \n",
      "3       Decision Tree Regressor  0.256662  0.444631  0.666807   0.778574   \n",
      "12                          SVM  0.428386  0.527963  0.726611   0.737075   \n",
      "0             Linear Regression  0.467833  0.984012  0.991974   0.509963   \n",
      "2              Lasso Regression  1.208733  2.581815  1.606803  -0.285742   \n",
      "15                     stacking  1.510601  4.108545  2.026955  -1.046052   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.047171         -2.042525  \n",
      "14       1.093262         -0.139399  \n",
      "8        1.134997         -0.070946  \n",
      "7        1.141447         -0.359685  \n",
      "6        1.150356         -0.130008  \n",
      "4        1.176138         -0.216796  \n",
      "5        1.187520         -0.419256  \n",
      "11       1.212964         -1.327842  \n",
      "13       1.222093         -0.080507  \n",
      "10       1.228133         -0.411994  \n",
      "9        1.236853         -0.551102  \n",
      "3        1.276783         -0.982904  \n",
      "12       1.328657         -0.792813  \n",
      "0        1.612547        -18.205036  \n",
      "2        2.607177         -1.081027  \n",
      "15       3.557565         -3.569559  \n",
      "ok\n",
      "Predictions for the next 12 periods (139-150) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[40.35487339 38.93220146 36.31701519 33.48139843 34.18415218 35.41564988\n",
      " 33.32634703 27.35349918 19.946593   15.71865195 14.58423604 15.53071462]\n",
      "Predictions for the next 12 periods:\n",
      "[ 3.40315415  3.19723224  2.81870215  2.40826627  2.50998501  2.68823577\n",
      "  2.38582366  1.52129532  0.44919697 -0.1627682  -0.32696704 -0.18997083]\n",
      "This is the 40th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.189025  0.077802  0.278930   0.961255   \n",
      "8           ExtraTreesRegressor  0.137972  0.122049  0.349355   0.939220   \n",
      "14                     boosting  0.137587  0.147502  0.384060   0.926544   \n",
      "5   Gradient Boosting Regressor  0.177048  0.194906  0.441482   0.902937   \n",
      "6            Adaboost Regressor  0.286200  0.273567  0.523036   0.863764   \n",
      "4       Random Forest Regressor  0.253549  0.274902  0.524311   0.863099   \n",
      "13                      bagging  0.331327  0.312694  0.559191   0.844279   \n",
      "12                          SVM  0.362171  0.340115  0.583193   0.830623   \n",
      "7              BaggingRegressor  0.287327  0.349591  0.591262   0.825904   \n",
      "11                     LightGBM  0.304778  0.412156  0.641994   0.794747   \n",
      "10               XGBRFRegressor  0.330343  0.583124  0.763626   0.709605   \n",
      "9                  XGBRegressor  0.283752  0.624544  0.790281   0.688977   \n",
      "3       Decision Tree Regressor  0.304241  0.697305  0.835048   0.652743   \n",
      "0             Linear Regression  0.498724  1.139954  1.067686   0.432304   \n",
      "2              Lasso Regression  1.210257  2.545810  1.595560  -0.267811   \n",
      "15                     stacking  1.725337  5.380268  2.319540  -1.679369   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.048432         -1.786505  \n",
      "8        1.075975         -0.108148  \n",
      "14       1.091820         -0.472607  \n",
      "5        1.121329         -0.560395  \n",
      "6        1.170295         -0.447734  \n",
      "4        1.171126         -0.227598  \n",
      "13       1.194652         -0.250168  \n",
      "12       1.211721         -0.555492  \n",
      "7        1.217620         -0.548865  \n",
      "11       1.256567         -1.666701  \n",
      "10       1.362994         -0.302142  \n",
      "9        1.388778         -0.407378  \n",
      "3        1.434071         -0.797374  \n",
      "0        1.709620        -10.291272  \n",
      "2        2.584764         -1.213383  \n",
      "15       4.349211         -4.078868  \n",
      "ok\n",
      "Predictions for the next 12 periods (140-151) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[39.1201868  36.43981292 33.62657855 34.35125105 35.5989165  33.48102949\n",
      " 27.48466526 20.06165554 15.83972591 14.7136977  15.69023058 13.51742441]\n",
      "Predictions for the next 12 periods:\n",
      "[ 3.22444182  2.83647627  2.42928009  2.53417141  2.71476234  2.40821287\n",
      "  1.5402807   0.46585148 -0.14524358 -0.30822836 -0.166882   -0.48138063]\n",
      "This is the 41th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.184760  0.065272  0.255484   0.967495   \n",
      "8           ExtraTreesRegressor  0.139222  0.138907  0.372703   0.930824   \n",
      "7              BaggingRegressor  0.217607  0.142372  0.377322   0.929099   \n",
      "4       Random Forest Regressor  0.222838  0.199193  0.446310   0.900802   \n",
      "12                          SVM  0.293542  0.212405  0.460875   0.894222   \n",
      "14                     boosting  0.197192  0.286244  0.535018   0.857451   \n",
      "6            Adaboost Regressor  0.287207  0.295391  0.543499   0.852896   \n",
      "13                      bagging  0.315995  0.299415  0.547189   0.850891   \n",
      "5   Gradient Boosting Regressor  0.200971  0.303488  0.550898   0.848863   \n",
      "3       Decision Tree Regressor  0.215267  0.398461  0.631238   0.801567   \n",
      "11                     LightGBM  0.335463  0.535305  0.731645   0.733419   \n",
      "10               XGBRFRegressor  0.319717  0.559548  0.748029   0.721346   \n",
      "9                  XGBRegressor  0.286979  0.632217  0.795121   0.685157   \n",
      "0             Linear Regression  0.363205  0.647996  0.804982   0.677298   \n",
      "2              Lasso Regression  1.212588  2.511503  1.584772  -0.250726   \n",
      "15                     stacking  1.955594  6.946747  2.635668  -2.459474   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.040632         -1.812597  \n",
      "8        1.086470         -0.260308  \n",
      "7        1.088626         -0.695063  \n",
      "4        1.123997         -0.544399  \n",
      "12       1.132222         -0.586663  \n",
      "14       1.178187         -0.606102  \n",
      "6        1.183881         -0.754865  \n",
      "13       1.186386         -0.388246  \n",
      "5        1.188921         -1.046086  \n",
      "3        1.248042         -1.125445  \n",
      "11       1.333227         -1.837910  \n",
      "10       1.348318         -0.542498  \n",
      "9        1.393554         -0.798657  \n",
      "0        1.403377         -5.632091  \n",
      "2        2.563408         -1.531086  \n",
      "15       5.324343         -3.409889  \n",
      "fine\n",
      "Predictions for the next 12 periods (141-152) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[36.63076399 34.34862364 32.22991932 32.68814985 33.71555176 31.44344907\n",
      " 25.74872566 18.74724387 14.64096091 13.38993977 14.2040368  11.73629905]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.86411512  2.53379111  2.22712334  2.29344904  2.44215835  2.11328722\n",
      "  1.28901547  0.2755995  -0.31875651 -0.49983315 -0.38199825 -0.73918619]\n",
      "This is the 42th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.185133  0.067202  0.259234   0.966533   \n",
      "14                     boosting  0.124547  0.100886  0.317626   0.949759   \n",
      "8           ExtraTreesRegressor  0.134087  0.127594  0.357202   0.936459   \n",
      "5   Gradient Boosting Regressor  0.152302  0.149028  0.386042   0.925784   \n",
      "12                          SVM  0.254563  0.160860  0.401073   0.919892   \n",
      "7              BaggingRegressor  0.210734  0.176257  0.419830   0.912224   \n",
      "4       Random Forest Regressor  0.231316  0.242915  0.492864   0.879028   \n",
      "13                      bagging  0.310387  0.305552  0.552768   0.847835   \n",
      "6            Adaboost Regressor  0.285107  0.305946  0.553124   0.847639   \n",
      "0             Linear Regression  0.287275  0.468199  0.684251   0.766837   \n",
      "10               XGBRFRegressor  0.315449  0.550199  0.741754   0.726001   \n",
      "9                  XGBRegressor  0.261054  0.575361  0.758526   0.713470   \n",
      "11                     LightGBM  0.343234  0.600295  0.774787   0.701054   \n",
      "3       Decision Tree Regressor  0.293905  0.603928  0.777128   0.699245   \n",
      "2              Lasso Regression  1.214705  2.481329  1.575224  -0.235700   \n",
      "15                     stacking  1.880499  6.420246  2.533821  -2.197277   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.041833         -1.792461  \n",
      "14       1.062802         -0.779804  \n",
      "8        1.079427         -0.543185  \n",
      "5        1.092770         -1.318330  \n",
      "12       1.100135         -0.620161  \n",
      "7        1.109720         -0.785226  \n",
      "4        1.151215         -0.622684  \n",
      "13       1.190206         -0.597247  \n",
      "6        1.190451         -0.940041  \n",
      "0        1.291453         -6.302062  \n",
      "10       1.342499         -0.796002  \n",
      "9        1.358162         -0.884493  \n",
      "11       1.373683         -2.388089  \n",
      "3        1.375944         -0.951122  \n",
      "2        2.544625         -1.805653  \n",
      "15       4.996597         -2.514221  \n",
      "fine\n",
      "Predictions for the next 12 periods (142-153) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.87191741 33.57236525 31.58967156 32.27126496 33.24438601 30.87788003\n",
      " 25.12738089 18.25727958 14.28840159 13.06550844 13.81631622 11.29096774]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.75427733  2.42143309  2.13445192  2.23310784  2.37396037  2.03142502\n",
      "  1.19908012  0.20468056 -0.36978703 -0.54679234 -0.43811811 -0.80364481]\n",
      "This is the 43th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.210547  0.099018  0.314671   0.950689   \n",
      "14                     boosting  0.108977  0.105120  0.324223   0.947650   \n",
      "6            Adaboost Regressor  0.215341  0.108507  0.329404   0.945964   \n",
      "8           ExtraTreesRegressor  0.127009  0.116184  0.340857   0.942141   \n",
      "5   Gradient Boosting Regressor  0.140558  0.141462  0.376115   0.929552   \n",
      "12                          SVM  0.273917  0.185148  0.430288   0.907797   \n",
      "4       Random Forest Regressor  0.216177  0.209964  0.458218   0.895438   \n",
      "3       Decision Tree Regressor  0.160107  0.242499  0.492442   0.879236   \n",
      "9                  XGBRegressor  0.168647  0.270414  0.520013   0.865334   \n",
      "13                      bagging  0.311093  0.288429  0.537056   0.856362   \n",
      "10               XGBRFRegressor  0.231472  0.291388  0.539803   0.854889   \n",
      "0             Linear Regression  0.215312  0.309991  0.556768   0.845625   \n",
      "11                     LightGBM  0.286280  0.407507  0.638363   0.797062   \n",
      "7              BaggingRegressor  0.340140  0.422799  0.650230   0.789446   \n",
      "2              Lasso Regression  1.216139  2.461407  1.568887  -0.225779   \n",
      "15                     stacking  1.960467  6.962571  2.638668  -2.467355   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.061639         -1.858304  \n",
      "14       1.065437         -1.016022  \n",
      "6        1.067545         -1.094628  \n",
      "8        1.072324         -0.658181  \n",
      "5        1.088060         -1.551566  \n",
      "12       1.115254         -0.625567  \n",
      "4        1.130702         -0.661100  \n",
      "3        1.150955         -0.942032  \n",
      "9        1.168332         -0.964836  \n",
      "13       1.179547         -0.630940  \n",
      "10       1.181388         -0.817719  \n",
      "0        1.192969         -6.145486  \n",
      "11       1.253673         -2.405144  \n",
      "7        1.263192         -0.781758  \n",
      "2        2.532223         -1.991044  \n",
      "15       5.334193         -2.466255  \n",
      "fine\n",
      "Predictions for the next 12 periods (143-154) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.11841672 30.69940047 28.67046542 29.92082151 31.7973763  29.21902319\n",
      " 23.08098239 16.07796339 12.60722396 11.90055989 12.71323278  9.83226082]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.64521333  2.00559135  1.71191706  1.89289744  2.16451574  1.79131699\n",
      "  0.90287812 -0.11076036 -0.61312584 -0.71541057 -0.5977818  -1.01478253]\n",
      "This is the 44th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.197668  0.086109  0.293443   0.957118   \n",
      "14                     boosting  0.112432  0.107951  0.328559   0.946240   \n",
      "8           ExtraTreesRegressor  0.118307  0.110435  0.332318   0.945003   \n",
      "5   Gradient Boosting Regressor  0.140024  0.141471  0.376126   0.929548   \n",
      "4       Random Forest Regressor  0.184059  0.156322  0.395376   0.922152   \n",
      "7              BaggingRegressor  0.229758  0.168639  0.410657   0.916018   \n",
      "12                          SVM  0.267986  0.173422  0.416440   0.913636   \n",
      "3       Decision Tree Regressor  0.155702  0.211006  0.459354   0.894919   \n",
      "10               XGBRFRegressor  0.221067  0.256794  0.506749   0.872117   \n",
      "9                  XGBRegressor  0.166007  0.263024  0.512859   0.869014   \n",
      "0             Linear Regression  0.195196  0.269560  0.519192   0.865759   \n",
      "6            Adaboost Regressor  0.274624  0.269704  0.519330   0.865688   \n",
      "13                      bagging  0.323545  0.320953  0.566527   0.840166   \n",
      "11                     LightGBM  0.266594  0.348264  0.590139   0.826565   \n",
      "2              Lasso Regression  1.217549  2.442254  1.562771  -0.216241   \n",
      "15                     stacking  1.455140  3.836945  1.958812  -0.910795   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.053603         -1.719168  \n",
      "14       1.067199         -0.672492  \n",
      "8        1.068746         -0.716775  \n",
      "5        1.088065         -1.416052  \n",
      "4        1.097311         -0.658958  \n",
      "7        1.104977         -0.778962  \n",
      "12       1.107955         -0.640239  \n",
      "3        1.131351         -0.974700  \n",
      "10       1.159854         -0.844917  \n",
      "9        1.163732         -0.993582  \n",
      "0        1.167801         -7.051248  \n",
      "6        1.167890         -0.979870  \n",
      "13       1.199793         -0.691557  \n",
      "11       1.216794         -2.137036  \n",
      "2        2.520301         -2.134767  \n",
      "15       3.388494         -2.741537  \n",
      "fine\n",
      "Predictions for the next 12 periods (144-155) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.13245375 30.89776851 29.40777409 30.66065838 32.36648845 29.59493424\n",
      " 23.50900785 16.58312883 13.13678192 12.30552812 13.0281776  10.10304181]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.64724509  2.03430374  1.81863738  1.9999837   2.24689078  1.84572751\n",
      "  0.96483184 -0.03764116 -0.536476   -0.65679422 -0.55219572 -0.97558886]\n",
      "This is the 45th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.168604  0.060852  0.246683   0.969696   \n",
      "8           ExtraTreesRegressor  0.106272  0.113267  0.336551   0.943593   \n",
      "0             Linear Regression  0.148182  0.127525  0.357107   0.936493   \n",
      "12                          SVM  0.258189  0.159309  0.399136   0.920664   \n",
      "4       Random Forest Regressor  0.195246  0.169397  0.411579   0.915640   \n",
      "7              BaggingRegressor  0.218069  0.193401  0.439774   0.903687   \n",
      "5   Gradient Boosting Regressor  0.155552  0.207557  0.455584   0.896637   \n",
      "6            Adaboost Regressor  0.268651  0.262796  0.512636   0.869128   \n",
      "13                      bagging  0.303181  0.277036  0.526342   0.862036   \n",
      "14                     boosting  0.174045  0.294481  0.542661   0.853349   \n",
      "10               XGBRFRegressor  0.245525  0.370627  0.608791   0.815428   \n",
      "11                     LightGBM  0.285895  0.386817  0.621946   0.807366   \n",
      "9                  XGBRegressor  0.197694  0.399712  0.632228   0.800944   \n",
      "3       Decision Tree Regressor  0.203398  0.418341  0.646793   0.791667   \n",
      "2              Lasso Regression  1.219344  2.418456  1.555139  -0.204389   \n",
      "15                     stacking  1.739715  5.340423  2.310935  -1.659526   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.037880         -1.722513  \n",
      "8        1.070508         -0.892995  \n",
      "0        1.079384         -5.385815  \n",
      "12       1.099170         -0.587637  \n",
      "4        1.105449         -0.821219  \n",
      "7        1.120392         -0.813552  \n",
      "5        1.129204         -1.736479  \n",
      "6        1.163590         -1.054158  \n",
      "13       1.172454         -0.733261  \n",
      "14       1.183314         -0.952815  \n",
      "10       1.230715         -0.980483  \n",
      "11       1.240793         -2.423667  \n",
      "9        1.248821         -1.480701  \n",
      "3        1.260417         -1.540227  \n",
      "2        2.505486         -2.506635  \n",
      "15       4.324408         -3.451969  \n",
      "fine\n",
      "Predictions for the next 12 periods (145-156) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.06410191 30.93435795 29.95482714 32.6925496  34.33110009 31.136256\n",
      " 24.49998091 17.6988348  14.45236348 13.70535154 14.14276903 10.93252156]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.63735164  2.03959981  1.89781951  2.29408587  2.5312547   2.06882316\n",
      "  1.10826832  0.12384955 -0.34605468 -0.45417948 -0.39086633 -0.85552741]\n",
      "This is the 46th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.158126  0.053866  0.232090   0.973175   \n",
      "0             Linear Regression  0.119115  0.066747  0.258354   0.966760   \n",
      "8           ExtraTreesRegressor  0.133034  0.195420  0.442064   0.902681   \n",
      "12                          SVM  0.265398  0.202108  0.449564   0.899350   \n",
      "14                     boosting  0.150149  0.212978  0.461496   0.893937   \n",
      "4       Random Forest Regressor  0.220700  0.227067  0.476515   0.886921   \n",
      "5   Gradient Boosting Regressor  0.164463  0.236528  0.486342   0.882209   \n",
      "6            Adaboost Regressor  0.274176  0.246028  0.496012   0.877478   \n",
      "7              BaggingRegressor  0.248288  0.258589  0.508517   0.871223   \n",
      "13                      bagging  0.325438  0.325884  0.570863   0.837710   \n",
      "10               XGBRFRegressor  0.251221  0.396536  0.629711   0.802525   \n",
      "11                     LightGBM  0.287927  0.433396  0.658329   0.784169   \n",
      "3       Decision Tree Regressor  0.211220  0.449389  0.670365   0.776204   \n",
      "9                  XGBRegressor  0.219145  0.484039  0.695729   0.758949   \n",
      "2              Lasso Regression  1.221357  2.392569  1.546793  -0.191498   \n",
      "15                     stacking  1.624439  4.784263  2.187296  -1.382559   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.033531         -1.753234  \n",
      "0        1.041550         -4.498085  \n",
      "8        1.121649         -1.306050  \n",
      "12       1.125812         -0.797788  \n",
      "14       1.132579         -1.130394  \n",
      "4        1.141349         -1.046756  \n",
      "5        1.147239         -1.732497  \n",
      "6        1.153152         -1.077183  \n",
      "7        1.160971         -1.610246  \n",
      "13       1.202863         -1.028401  \n",
      "10       1.246844         -1.200016  \n",
      "11       1.269789         -2.231809  \n",
      "3        1.279744         -1.428724  \n",
      "9        1.301314         -1.325979  \n",
      "2        2.489372         -3.069042  \n",
      "15       3.978199         -3.582820  \n",
      "fine\n",
      "Predictions for the next 12 periods (146-157) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.14316983 30.90055425 29.97155293 32.95796584 35.33570872 32.12702379\n",
      " 25.26801984 18.15783061 14.97414817 14.34143473 14.83070758 11.48794068]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.64879617  2.03470696  1.90024046  2.33250303  2.67666484  2.21222993\n",
      "  1.21943663  0.19028601 -0.27052996 -0.36211085 -0.29129199 -0.77513434]\n",
      "This is the 47th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "14                     boosting  0.037714  0.018717  0.136809   0.990679   \n",
      "1              Ridge Regression  0.165991  0.062280  0.249559   0.968985   \n",
      "0             Linear Regression  0.137905  0.097021  0.311482   0.951684   \n",
      "7              BaggingRegressor  0.195967  0.143193  0.378408   0.928690   \n",
      "3       Decision Tree Regressor  0.115698  0.171130  0.413679   0.914777   \n",
      "5   Gradient Boosting Regressor  0.138767  0.192230  0.438440   0.904270   \n",
      "8           ExtraTreesRegressor  0.125424  0.197003  0.443850   0.901893   \n",
      "12                          SVM  0.267509  0.203803  0.451445   0.898506   \n",
      "4       Random Forest Regressor  0.215054  0.237922  0.487772   0.881515   \n",
      "6            Adaboost Regressor  0.249809  0.239768  0.489662   0.880596   \n",
      "9                  XGBRegressor  0.145997  0.271877  0.521418   0.864606   \n",
      "13                      bagging  0.314962  0.304020  0.551380   0.848598   \n",
      "10               XGBRFRegressor  0.230032  0.331294  0.575582   0.835016   \n",
      "11                     LightGBM  0.271785  0.375885  0.613095   0.812809   \n",
      "2              Lasso Regression  1.222784  2.374731  1.541016  -0.182614   \n",
      "15                     stacking  2.081928  7.815238  2.795575  -2.891982   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "14       1.011651         -1.418620  \n",
      "1        1.038769         -1.775921  \n",
      "0        1.060396         -4.000815  \n",
      "7        1.089137         -1.918376  \n",
      "3        1.106528         -2.933826  \n",
      "5        1.119663         -1.806434  \n",
      "8        1.122634         -1.453585  \n",
      "12       1.126867         -0.924124  \n",
      "4        1.148106         -1.187093  \n",
      "6        1.149256         -1.352561  \n",
      "9        1.169243         -2.043182  \n",
      "13       1.189252         -1.282994  \n",
      "10       1.206230         -1.304642  \n",
      "11       1.233988         -1.582163  \n",
      "2        2.478267         -3.450814  \n",
      "15       5.864977         -3.698028  \n",
      "fine\n",
      "Predictions for the next 12 periods (147-158) using boosting:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 33.43224095 35.71014558 30.50069868\n",
      " 27.74224957 17.91403977 17.91403977 17.91403977 17.91403977 17.91403977]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 1.86111556 1.85671248 2.40115107 2.73086198 1.97683064\n",
      " 1.57756424 0.15499898 0.15499898 0.15499898 0.15499898 0.15499898]\n",
      "This is the 48th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "1              Ridge Regression  0.144073  0.041820  0.204500   0.979173   \n",
      "6            Adaboost Regressor  0.155248  0.043037  0.207452   0.978568   \n",
      "0             Linear Regression  0.100610  0.051229  0.226338   0.974488   \n",
      "14                     boosting  0.065971  0.055028  0.234581   0.972596   \n",
      "5   Gradient Boosting Regressor  0.103539  0.107273  0.327525   0.946578   \n",
      "8           ExtraTreesRegressor  0.102263  0.150583  0.388050   0.925010   \n",
      "7              BaggingRegressor  0.200778  0.150791  0.388318   0.924906   \n",
      "4       Random Forest Regressor  0.194063  0.190878  0.436896   0.904943   \n",
      "12                          SVM  0.264294  0.195973  0.442688   0.902406   \n",
      "9                  XGBRegressor  0.118699  0.201597  0.448996   0.899605   \n",
      "10               XGBRFRegressor  0.180509  0.207948  0.456013   0.896442   \n",
      "11                     LightGBM  0.221407  0.242131  0.492068   0.879419   \n",
      "3       Decision Tree Regressor  0.126501  0.242317  0.492257   0.879327   \n",
      "13                      bagging  0.293693  0.261314  0.511189   0.869866   \n",
      "2              Lasso Regression  1.223921  2.360824  1.536497  -0.175688   \n",
      "15                     stacking  1.698547  5.229912  2.286900  -1.604492   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "1        1.026033         -1.914448  \n",
      "6        1.026790         -1.583246  \n",
      "0        1.031890         -3.798734  \n",
      "14       1.034255         -1.618039  \n",
      "5        1.066777         -1.972335  \n",
      "8        1.093738         -1.495093  \n",
      "7        1.093867         -1.645319  \n",
      "4        1.118821         -1.364686  \n",
      "12       1.121993         -1.358046  \n",
      "9        1.125494         -1.467075  \n",
      "10       1.129447         -1.383088  \n",
      "11       1.150726         -1.692132  \n",
      "3        1.150842         -1.674443  \n",
      "13       1.162668         -1.489450  \n",
      "2        2.469610         -3.818043  \n",
      "15       4.255615         -2.739461  \n",
      "fine\n",
      "Predictions for the next 12 periods (148-159) using Ridge Regression:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.11944358 30.93968147 30.21456029 32.85626842 35.05602759 31.7695971\n",
      " 26.8262934  19.89484368 16.25207158 14.84547078 15.56901963 12.57009403]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.64536196  2.04037035  1.93541409  2.31778304  2.63618293  2.16049489\n",
      "  1.44498593  0.44170662 -0.0855594  -0.28915512 -0.18442644 -0.61850014]\n",
      "This is the 49th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "6            Adaboost Regressor  0.135732  0.030702  0.175219   0.984710   \n",
      "1              Ridge Regression  0.139661  0.037242  0.192981   0.981454   \n",
      "0             Linear Regression  0.090342  0.043225  0.207906   0.978474   \n",
      "3       Decision Tree Regressor  0.058651  0.062271  0.249542   0.968989   \n",
      "14                     boosting  0.061462  0.062395  0.249790   0.968927   \n",
      "9                  XGBRegressor  0.062101  0.069510  0.263647   0.965384   \n",
      "11                     LightGBM  0.148088  0.078749  0.280623   0.960783   \n",
      "5   Gradient Boosting Regressor  0.086123  0.081274  0.285086   0.959526   \n",
      "7              BaggingRegressor  0.168365  0.083670  0.289258   0.958332   \n",
      "10               XGBRFRegressor  0.127654  0.087742  0.296214   0.956304   \n",
      "8           ExtraTreesRegressor  0.070111  0.089204  0.298671   0.955576   \n",
      "4       Random Forest Regressor  0.155504  0.091975  0.303273   0.954197   \n",
      "12                          SVM  0.243325  0.147699  0.384317   0.926446   \n",
      "13                      bagging  0.251761  0.185680  0.430906   0.907531   \n",
      "2              Lasso Regression  1.224556  2.353167  1.534004  -0.171875   \n",
      "15                     stacking  1.657943  5.209633  2.282462  -1.594393   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "6        1.019112         -1.489952  \n",
      "1        1.023183         -1.769162  \n",
      "0        1.026908         -2.768192  \n",
      "3        1.038764         -1.647826  \n",
      "14       1.038841         -1.651193  \n",
      "9        1.043270         -1.259138  \n",
      "11       1.049021         -1.558317  \n",
      "5        1.050593         -1.728347  \n",
      "7        1.052085         -1.314907  \n",
      "10       1.054620         -1.241454  \n",
      "8        1.055530         -1.620498  \n",
      "4        1.057254         -1.398453  \n",
      "12       1.091943         -1.321733  \n",
      "13       1.115586         -1.522147  \n",
      "2        2.464844         -3.881454  \n",
      "15       4.242991         -1.913492  \n",
      "fine\n",
      "Predictions for the next 12 periods (149-160) using Adaboost Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.64553649 31.02729159 30.58423926 32.46254002 35.49716763 30.50069868\n",
      " 28.34693242 22.96368278 19.09886492 18.23351571 18.23351571 17.67491161]\n",
      "Predictions for the next 12 periods:\n",
      "[2.72151026 2.05305131 1.98892256 2.26079358 2.7000349  1.97683064\n",
      " 1.66508789 0.88589981 0.32649421 0.2012409  0.2012409  0.12038683]\n",
      "This is the 50th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "9                  XGBRegressor  0.017578  0.007765  0.088117   0.996133   \n",
      "3       Decision Tree Regressor  0.020414  0.010876  0.104290   0.994584   \n",
      "14                     boosting  0.023887  0.011047  0.105102   0.994499   \n",
      "5   Gradient Boosting Regressor  0.042255  0.015686  0.125246   0.992188   \n",
      "8           ExtraTreesRegressor  0.031122  0.024710  0.157193   0.987695   \n",
      "0             Linear Regression  0.073621  0.026689  0.163369   0.986709   \n",
      "10               XGBRFRegressor  0.090023  0.027533  0.165930   0.986289   \n",
      "6            Adaboost Regressor  0.143902  0.031845  0.178452   0.984141   \n",
      "11                     LightGBM  0.110190  0.031942  0.178725   0.984093   \n",
      "1              Ridge Regression  0.140258  0.037888  0.194648   0.981132   \n",
      "4       Random Forest Regressor  0.129301  0.047645  0.218277   0.976273   \n",
      "7              BaggingRegressor  0.153331  0.075307  0.274420   0.962497   \n",
      "13                      bagging  0.210805  0.093122  0.305159   0.953625   \n",
      "12                          SVM  0.228375  0.121154  0.348072   0.939665   \n",
      "2              Lasso Regression  1.224713  2.351283  1.533389  -0.170937   \n",
      "15                     stacking  1.373184  3.694136  1.922014  -0.839677   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "9        1.004833         -2.102699  \n",
      "3        1.006771         -2.224042  \n",
      "14       1.006876         -1.896429  \n",
      "5        1.009765         -2.234207  \n",
      "8        1.015382         -1.902418  \n",
      "0        1.016614         -2.726404  \n",
      "10       1.017139         -1.651276  \n",
      "6        1.019824         -1.683803  \n",
      "11       1.019884         -1.718093  \n",
      "1        1.023585         -1.990825  \n",
      "4        1.029659         -1.802713  \n",
      "7        1.046878         -1.801933  \n",
      "13       1.057968         -2.034585  \n",
      "12       1.075418         -1.660117  \n",
      "2        2.463671         -4.118644  \n",
      "15       3.299596         -0.895528  \n",
      "fine\n",
      "Predictions for the next 12 periods (150-161) using XGBRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60237  29.703594 29.672794 33.43111  35.702286 30.500938 27.958538\n",
      " 23.352741 18.866426 18.286385 18.292698 18.19778 ]\n",
      "Predictions for the next 12 periods:\n",
      "[2.715263   1.8614556  1.8569974  2.4009876  2.7297244  1.9768655\n",
      " 1.6088707  0.9422135  0.29285046 0.2088933  0.20980723 0.19606845]\n",
      "This is the 51th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE  R Squared  \\\n",
      "9                  XGBRegressor  0.003539  0.000495  0.022253   0.999753   \n",
      "3       Decision Tree Regressor  0.003132  0.000500  0.022369   0.999751   \n",
      "14                     boosting  0.003917  0.000512  0.022635   0.999745   \n",
      "8           ExtraTreesRegressor  0.003547  0.000642  0.025334   0.999680   \n",
      "5   Gradient Boosting Regressor  0.022498  0.000886  0.029768   0.999559   \n",
      "10               XGBRFRegressor  0.068545  0.008131  0.090171   0.995951   \n",
      "0             Linear Regression  0.058253  0.013015  0.114085   0.993518   \n",
      "4       Random Forest Regressor  0.105157  0.019584  0.139942   0.990247   \n",
      "6            Adaboost Regressor  0.113467  0.020447  0.142993   0.989817   \n",
      "11                     LightGBM  0.110055  0.025852  0.160785   0.987126   \n",
      "7              BaggingRegressor  0.123681  0.034459  0.185632   0.982839   \n",
      "1              Ridge Regression  0.132651  0.035423  0.188209   0.982360   \n",
      "13                      bagging  0.205941  0.082959  0.288026   0.958686   \n",
      "12                          SVM  0.204516  0.089692  0.299485   0.955334   \n",
      "2              Lasso Regression  1.224439  2.354572  1.534462  -0.172575   \n",
      "15                     stacking  1.570825  4.859278  2.204377  -1.419916   \n",
      "\n",
      "    adj R Squared  Cross Validation  \n",
      "9        1.000308         -1.998878  \n",
      "3        1.000311         -2.394048  \n",
      "14       1.000319         -2.013014  \n",
      "8        1.000400         -2.019653  \n",
      "5        1.000552         -2.215362  \n",
      "10       1.005061         -1.792726  \n",
      "0        1.008102         -3.292862  \n",
      "4        1.012191         -1.979994  \n",
      "6        1.012728         -2.023688  \n",
      "11       1.016093         -2.374210  \n",
      "7        1.021451         -1.971178  \n",
      "1        1.022051         -2.239593  \n",
      "13       1.051642         -2.037003  \n",
      "12       1.055833         -2.512971  \n",
      "2        2.465719         -4.365595  \n",
      "15       4.024895         -1.824574  \n",
      "fine\n",
      "Predictions for the next 12 periods (151-162) using XGBRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60359  29.702835 29.673122 33.4309   35.70299  30.501904 27.964304\n",
      " 23.349009 18.8606   14.720691 14.718992 14.718992]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.7154386   1.8613456   1.8570447   2.4009573   2.7298265   1.977005\n",
      "  1.6097052   0.94167304  0.29200703 -0.3072161  -0.307462   -0.307462  ]\n",
      "This is the 52th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model           MAE           MSE          RMSE  \\\n",
      "3       Decision Tree Regressor  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "8           ExtraTreesRegressor  1.557850e-15  5.945357e-30  2.438310e-15   \n",
      "9                  XGBRegressor  4.567047e-04  3.463002e-07  5.884728e-04   \n",
      "14                     boosting  1.567174e-03  3.570204e-05  5.975119e-03   \n",
      "5   Gradient Boosting Regressor  2.155008e-02  6.226369e-04  2.495269e-02   \n",
      "0             Linear Regression  4.423444e-02  3.257695e-03  5.707622e-02   \n",
      "10               XGBRFRegressor  6.256867e-02  6.307780e-03  7.942153e-02   \n",
      "4       Random Forest Regressor  9.144202e-02  1.638289e-02  1.279957e-01   \n",
      "11                     LightGBM  1.071069e-01  2.430478e-02  1.558999e-01   \n",
      "7              BaggingRegressor  1.066953e-01  2.611541e-02  1.616026e-01   \n",
      "6            Adaboost Regressor  1.376848e-01  3.143669e-02  1.773039e-01   \n",
      "1              Ridge Regression  1.321864e-01  3.539212e-02  1.881279e-01   \n",
      "13                      bagging  1.741370e-01  5.345565e-02  2.312048e-01   \n",
      "12                          SVM  1.955592e-01  8.365646e-02  2.892343e-01   \n",
      "2              Lasso Regression  1.224282e+00  2.356461e+00  1.535077e+00   \n",
      "15                     stacking  1.690744e+00  5.730663e+00  2.393880e+00   \n",
      "\n",
      "    R Squared  adj R Squared  Cross Validation  \n",
      "3    1.000000       1.000000         -2.941536  \n",
      "8    1.000000       1.000000         -2.418334  \n",
      "9    1.000000       1.000000         -2.425402  \n",
      "14   0.999982       1.000022         -2.304126  \n",
      "5    0.999690       1.000388         -2.539979  \n",
      "0    0.998378       1.002028         -3.990745  \n",
      "10   0.996859       1.003927         -2.253317  \n",
      "4    0.991841       1.010198         -2.600927  \n",
      "11   0.987896       1.015130         -2.427091  \n",
      "7    0.986995       1.016257         -2.200088  \n",
      "6    0.984345       1.019569         -2.444080  \n",
      "1    0.982375       1.022032         -2.655228  \n",
      "13   0.973379       1.033276         -3.374088  \n",
      "12   0.958339       1.052076         -3.517401  \n",
      "2   -0.173516       2.466895         -4.807818  \n",
      "15  -1.853866       4.567332         -1.115473  \n",
      "fine\n",
      "Predictions for the next 12 periods (152-163) using Decision Tree Regressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 33.43224095 35.71014558 30.50069868\n",
      " 27.96098937 23.35208319 18.86110472 14.71293448 15.81659505 14.71293448]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.71527578  1.86111556  1.85671248  2.40115107  2.73086198  1.97683064\n",
      "  1.60922531  0.94211808  0.29208006 -0.30833884 -0.14859161 -0.30833884]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 创建基础模型对象\n",
    "base_model_b = RandomForestRegressor()\n",
    "# 创建基础模型对象\n",
    "base_model_o = DecisionTreeRegressor()\n",
    "# 创建基础模型对象\n",
    "base_models = [\n",
    "    ('model1', DecisionTreeRegressor()),\n",
    "    ('model2', Ridge())\n",
    "]\n",
    "\n",
    "# 创建Bagging模型对象\n",
    "bagging_model = BaggingRegressor(estimator=base_model_b)\n",
    "# 创建Boosting模型对象\n",
    "boosting_model = AdaBoostRegressor(estimator=base_model_o)\n",
    "# 创建Stacking模型对象\n",
    "stacking_model = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "names = [\"Linear Regression\", \"Ridge Regression\", \"Lasso Regression\",\n",
    "         \"Decision Tree Regressor\", \"Random Forest Regressor\", \"Gradient Boosting Regressor\",\n",
    "         \"Adaboost Regressor\", \"BaggingRegressor\", \"ExtraTreesRegressor\",\n",
    "         \"XGBRegressor\", \"XGBRFRegressor\", \"LightGBM\", \"SVM\",\"bagging\", 'boosting', 'stacking']\n",
    "\n",
    "models = [LinearRegression(), Ridge(), Lasso(), DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(), GradientBoostingRegressor(),\n",
    "          AdaBoostRegressor(), BaggingRegressor(), ExtraTreesRegressor(),\n",
    "          XGBRegressor(), XGBRFRegressor(), LGBMRegressor(), SVR(),bagging_model, boosting_model, stacking_model]\n",
    "\n",
    "\n",
    "# 指定训练集和测试集的范围\n",
    "train_num = 1\n",
    "train_start = 12\n",
    "train_end = 100\n",
    "test_start = 101\n",
    "test_end = 151\n",
    "current_train_end = train_end\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "# 划分训练集和测试集\n",
    "# 获取 'num' 列对应数字为 train_start:current_train_end 范围内的行索引\n",
    "num_indices_te = X_final_data_feature_lag12.loc[(X_final_data_feature_lag12['num'] >= test_start) & (X_final_data_feature_lag12['num'] <= test_end)].index\n",
    "\n",
    "# 使用相同的行索引选择测试集特征和目标变量\n",
    "X_test = X_final_data_feature_lag12.loc[num_indices_te, X_final_data_feature_lag12.columns != 'num']\n",
    "y_test = y_final_data_feature_lag12.loc[num_indices_te, 'Hog prices']\n",
    "\n",
    "\n",
    "\n",
    "while train_end <= test_end:\n",
    "    # 打印循环次数\n",
    "    print(\"This is the {}th loop.\".format(train_num))\n",
    "    \n",
    "    # 清空评估结果列表\n",
    "    evaluation_results.clear()\n",
    "\n",
    "     # 划分训练集和测试集\n",
    "    # 获取 'num' 列对应数字为 train_start:current_train_end 范围内的行索引\n",
    "    num_indices_tr = (X_final_data_feature_lag12['num'] >= train_start-1) & (X_final_data_feature_lag12['num'] <= current_train_end-1)\n",
    "    # 获取 'num' 列对应数字为 test_start:test_end 范围内的行索引\n",
    "    num_indices_te = (X_final_data_feature_lag12['num'] >= test_start-1) & (X_final_data_feature_lag12['num'] <= test_end-1)\n",
    "    # 选择对应行索引的其他列数据作为训练集特征，同时移除 'num' 列\n",
    "    X_train_features = X_final_data_feature_lag12.drop('num', axis=1)\n",
    "    X_train_features = X_train_features.loc[num_indices_tr]\n",
    "    # 选择对应行索引的其他列数据作为测试集特征，同时移除 'num' 列\n",
    "    X_test_features = X_final_data_feature_lag12.drop('num', axis=1)\n",
    "    X_test_features = X_test_features.loc[num_indices_te]\n",
    "    y_test = y_final_data_feature_lag12.loc[num_indices_te].drop('num', axis=1)['Hog prices']\n",
    "    y_train = y_final_data_feature_lag12.loc[num_indices_tr].drop('num', axis=1)['Hog prices']\n",
    "    \n",
    "    \n",
    "    # 初始化评估指标列表\n",
    "    MAE = []\n",
    "    MSE = []\n",
    "    RMSE = []\n",
    "    R_Square = []\n",
    "    adj_rsquared = []\n",
    "    CV = []\n",
    "\n",
    "    def evaluate(true, predicted, variable_of_model):\n",
    "        MAE.append(mean_absolute_error(true, predicted))\n",
    "        MSE.append(mean_squared_error(true, predicted))\n",
    "        RMSE.append(np.sqrt(mean_squared_error(true, predicted)))\n",
    "        R_Square.append(variable_of_model.score(X_test_features, y_test))  # 修改此行\n",
    "        n = X_test_features.shape[0]\n",
    "        p = X_test_features.shape[1] - 1\n",
    "        adj_rsquared.append(1 - (1 - R_Square[-1]) * ((n - 1) / (n - p - 1)))\n",
    "        cv_accuracies = cross_val_score(estimator=variable_of_model, X=X_train_features, y=y_train.ravel(), cv=5, verbose=1)\n",
    "        CV.append(cv_accuracies.mean())\n",
    "\n",
    "    def print_evaluate(true, predicted):\n",
    "        mae = mean_absolute_error(true, predicted)\n",
    "        mse = mean_squared_error(true, predicted)\n",
    "        rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "        r2_square = r2_score(true, predicted)\n",
    "        n = X_test_features.shape[0]\n",
    "        p = X_test_features.shape[1] - 1\n",
    "        adj_rsquared = 1 - (1 - r2_square) * ((n - 1) / (n - p - 1))\n",
    "        print(\"MAE:\", mae)\n",
    "        print(\"MSE:\", mse)\n",
    "        print(\"RMSE:\", rmse)\n",
    "        print(\"R2 Square\", r2_square)\n",
    "        print(\"adj R Square\", adj_rsquared)\n",
    "\n",
    "    def fit_and_predict(name, model):\n",
    "        variable_of_model = model\n",
    "        variable_of_model.fit(X_train_features, y_train.ravel())\n",
    "        pred = variable_of_model.predict(X_test_features)\n",
    "        evaluate(y_test, pred, variable_of_model)\n",
    "\n",
    "        evaluation_results.append({\n",
    "            \"Model\": name,\n",
    "            \"MAE\": MAE[-1],\n",
    "            \"MSE\": MSE[-1],\n",
    "            \"RMSE\": RMSE[-1],\n",
    "            \"R Squared\": R_Square[-1],\n",
    "            \"adj R Squared\": adj_rsquared[-1],\n",
    "            \"Cross Validation\": CV[-1]\n",
    "        })\n",
    "\n",
    "    # 声明变量存储最小RMSE(CV)和对应的算法\n",
    "    min_rmse_cv = float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    for name, model in zip(names, models):\n",
    "        fit_and_predict(name, model)\n",
    "\n",
    "    # 创建评估结果DataFrame\n",
    "    evaluation_dataframe = pd.DataFrame(evaluation_results)\n",
    "    evaluation_dataframe = evaluation_dataframe.sort_values(\"RMSE\")\n",
    "\n",
    "    # 打印评估结果DataFrame\n",
    "    print(evaluation_dataframe)\n",
    "    \n",
    "    \n",
    "    # 使用最小RMSE的模型进行未来12期的预测\n",
    "    # 找到评估结果DataFrame中最小RMSE对应的算法\n",
    "    best_row = evaluation_dataframe.loc[evaluation_dataframe['RMSE'].idxmin()]\n",
    "    best_model_name = best_row['Model']\n",
    "    best_model = models[names.index(best_model_name)]\n",
    "\n",
    "\n",
    "    # 使用最小RMSE的模型进行未来12期的预测\n",
    "    num_indices_p = (X_final_data_feature_lag12['num'] >= current_train_end + 1) & (X_final_data_feature_lag12['num'] <= current_train_end + 12)\n",
    "\n",
    "    if num_indices_p.sum() == 12:\n",
    "        print('ok')\n",
    "        future_X_features = X_final_data_feature_lag12.drop('num', axis=1)\n",
    "        future_X_features = future_X_features.loc[num_indices_p]\n",
    "        future_predictions = best_model.predict(future_X_features)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        future_predictions = []\n",
    "        current_input_sequence = X_final_data_feature_lag12_cnn[-12:].values\n",
    "        print('fine')\n",
    "\n",
    "        for _ in range(12):\n",
    "            current_input_sequence = current_input_sequence.reshape((12, 91))\n",
    "#             print(\"current_input_sequence shape:\", current_input_sequence.shape)\n",
    "            prediction = best_model.predict(current_input_sequence)\n",
    "            future_predictions.append(prediction)\n",
    "            current_input_sequence = np.roll(current_input_sequence, -1, axis=0)\n",
    "            current_input_sequence[-1] = np.squeeze(prediction)[-1]\n",
    "            prediction = np.squeeze(prediction)\n",
    "            \n",
    "\n",
    "    # 打印预测结果\n",
    "    future_predictions = np.array(best_model.predict(future_X_features))\n",
    "    mean = raw_data[\"Hog prices\"].mean()\n",
    "    std = raw_data[\"Hog prices\"].std()\n",
    "\n",
    "    # Reverse standardization and print the predictions\n",
    "    print(\"Predictions for the next 12 periods ({}-{}) using {}:\".format(current_train_end+1, current_train_end+12, best_model_name))\n",
    "    future_predictions_reversed = future_predictions * std + mean\n",
    "    print(\"Reversed Predictions for the next 12 periods:\")\n",
    "    print(future_predictions_reversed)\n",
    "    print(\"Predictions for the next 12 periods:\")\n",
    "    print(future_predictions)\n",
    "\n",
    "    # 更新下一个训练集和测试集的起始和结束行数\n",
    "    current_train_end += 1\n",
    "    train_end += 1\n",
    "    train_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845c7c6b",
   "metadata": {},
   "source": [
    "## RMSE_Traditional_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "73341d21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T06:20:14.654606Z",
     "start_time": "2023-07-02T04:37:42.573429Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 1th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.263980   2.780113  1.667367  -0.387941   \n",
      "9                  XGBRegressor  1.260347   2.418308  1.555091  -0.207314   \n",
      "14                     boosting  1.264940   2.646458  1.626794  -0.321216   \n",
      "5   Gradient Boosting Regressor  1.279248   2.583339  1.607277  -0.289704   \n",
      "6            Adaboost Regressor  1.282832   2.611551  1.616029  -0.303789   \n",
      "10               XGBRFRegressor  1.266668   2.621881  1.619222  -0.308946   \n",
      "4       Random Forest Regressor  1.269716   2.691272  1.640510  -0.343588   \n",
      "0             Linear Regression  4.139964  29.690929  5.448938 -13.822873   \n",
      "11                     LightGBM  1.310361   2.640015  1.624812  -0.317999   \n",
      "12                          SVM  1.379946   3.587656  1.894111  -0.791098   \n",
      "13                      bagging  1.256056   2.625268  1.620268  -0.310637   \n",
      "1              Ridge Regression  1.160562   2.285580  1.511813  -0.141051   \n",
      "7              BaggingRegressor  1.283690   2.671417  1.634447  -0.333676   \n",
      "15                     stacking  0.923780   1.654985  1.286462   0.173767   \n",
      "3       Decision Tree Regressor  1.239294   2.373742  1.540695  -0.185065   \n",
      "2              Lasso Regression  1.200746   2.887727  1.699331  -0.441666   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    2.734927           0.117344          0.090082          0.015093  \n",
      "9    2.509142           0.165807          0.123231          0.028865  \n",
      "14   2.651519           0.177261          0.131595          0.035390  \n",
      "5    2.612130           0.187709          0.136362          0.035890  \n",
      "6    2.629736           0.187882          0.149847          0.037244  \n",
      "10   2.636182           0.191984          0.144124          0.037849  \n",
      "4    2.679486           0.192477          0.148553          0.038549  \n",
      "0   19.528591           0.194052          0.157682          0.038621  \n",
      "11   2.647498           0.198150          0.153388          0.041461  \n",
      "12   3.238873           0.198504          0.155051          0.042188  \n",
      "13   2.638296           0.200962          0.158774          0.042091  \n",
      "1    2.426313           0.205877          0.162685          0.044909  \n",
      "7    2.667095           0.207615          0.154967          0.044600  \n",
      "15   2.032791           0.270855          0.217558          0.081428  \n",
      "3    2.481331           0.282231          0.199233          0.083085  \n",
      "2    2.802083           0.361887          0.307070          0.139392  \n",
      "Predictions for the next 12 periods (101-112) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[15.25989824 15.84658962 15.80849958 15.85929815 15.95446581 16.26878468\n",
      " 16.7341718  16.55930725 16.33871951 15.9769325  15.8135153  16.14879346]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.22916962 -0.14425011 -0.14976338 -0.14241064 -0.12863578 -0.0831403\n",
      " -0.01577874 -0.04108917 -0.07301772 -0.12538388 -0.14903739 -0.1005082 ]\n",
      "This is the 2th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.238650  2.809085  1.676033 -0.402405   \n",
      "14                     boosting  1.258001  2.632188  1.622402 -0.314091   \n",
      "10               XGBRFRegressor  1.243552  2.617977  1.618016 -0.306996   \n",
      "9                  XGBRegressor  1.264933  2.512455  1.585073 -0.254316   \n",
      "4       Random Forest Regressor  1.255882  2.656402  1.629847 -0.326180   \n",
      "5   Gradient Boosting Regressor  1.249327  2.663872  1.632137 -0.329909   \n",
      "6            Adaboost Regressor  1.243996  2.542855  1.594633 -0.269493   \n",
      "13                      bagging  1.251007  2.668793  1.633644 -0.332366   \n",
      "7              BaggingRegressor  1.249574  2.753731  1.659437 -0.374770   \n",
      "12                          SVM  1.370744  3.670073  1.915743 -0.832244   \n",
      "11                     LightGBM  1.257769  2.553794  1.598060 -0.274954   \n",
      "1              Ridge Regression  1.173041  2.425266  1.557326 -0.210787   \n",
      "0             Linear Regression  1.879107  7.358081  2.712578 -2.673442   \n",
      "3       Decision Tree Regressor  1.263716  2.463174  1.569450 -0.229713   \n",
      "15                     stacking  0.973357  1.815272  1.347320  0.093745   \n",
      "2              Lasso Regression  1.200691  2.893019  1.700888 -0.444308   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   2.753007           0.131971          0.104853          0.026931  \n",
      "14  2.642614           0.165157          0.125851          0.029368  \n",
      "10  2.633745           0.181039          0.143812          0.036448  \n",
      "9   2.567895           0.183146          0.141476          0.039529  \n",
      "4   2.657725           0.189527          0.148886          0.039867  \n",
      "5   2.662386           0.191945          0.144299          0.041163  \n",
      "6   2.586866           0.192274          0.156596          0.039616  \n",
      "13  2.665457           0.204624          0.162531          0.044613  \n",
      "7   2.718463           0.206512          0.161987          0.045829  \n",
      "12  3.290305           0.211591          0.161938          0.049825  \n",
      "11  2.593692           0.215478          0.167179          0.050000  \n",
      "1   2.513484           0.225387          0.171199          0.062252  \n",
      "0   5.591802           0.261745          0.201808          0.070797  \n",
      "3   2.537141           0.287769          0.211565          0.089008  \n",
      "15  2.132818           0.298146          0.224742          0.091730  \n",
      "2   2.805385           0.363351          0.305219          0.138159  \n",
      "Predictions for the next 12 periods (102-113) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.35783238 14.97742257 15.22201968 15.67352857 15.75019217 15.91891475\n",
      " 15.83880016 15.77243934 15.32345696 15.09769971 15.09695856 15.31803036]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.3597374  -0.27005602 -0.23465228 -0.1692995  -0.15820297 -0.13378155\n",
      " -0.14537758 -0.15498285 -0.21996994 -0.25264673 -0.25275401 -0.2207554 ]\n",
      "This is the 3th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.207033  2.792672  1.671129 -0.394211   \n",
      "14                     boosting  1.273533  2.600308  1.612547 -0.298176   \n",
      "9                  XGBRegressor  1.236400  2.314006  1.521186 -0.155242   \n",
      "5   Gradient Boosting Regressor  1.230840  2.597552  1.611692 -0.296799   \n",
      "10               XGBRFRegressor  1.234272  2.554847  1.598389 -0.275479   \n",
      "6            Adaboost Regressor  1.275224  2.658300  1.630429 -0.327127   \n",
      "4       Random Forest Regressor  1.254528  2.681540  1.637541 -0.338729   \n",
      "7              BaggingRegressor  1.284185  2.754597  1.659698 -0.375202   \n",
      "12                          SVM  1.374589  3.798255  1.948911 -0.896237   \n",
      "13                      bagging  1.256544  2.749450  1.658146 -0.372633   \n",
      "1              Ridge Regression  1.241370  2.671395  1.634440 -0.333665   \n",
      "11                     LightGBM  1.250527  2.593955  1.610576 -0.295004   \n",
      "3       Decision Tree Regressor  1.234055  2.225613  1.491849 -0.111113   \n",
      "15                     stacking  1.091192  2.170572  1.473286 -0.083634   \n",
      "0             Linear Regression  2.212570  8.286746  2.878671 -3.137068   \n",
      "2              Lasso Regression  1.200648  2.897101  1.702087 -0.446346   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   2.742764           0.112128          0.090648          0.013709  \n",
      "14  2.622719           0.157892          0.122488          0.025842  \n",
      "9   2.444053           0.161835          0.128887          0.028021  \n",
      "5   2.620999           0.172513          0.129669          0.030903  \n",
      "10  2.594349           0.176412          0.132946          0.033134  \n",
      "6   2.658909           0.180368          0.144403          0.035092  \n",
      "4   2.673412           0.185567          0.145409          0.036090  \n",
      "7   2.719003           0.191005          0.145354          0.038079  \n",
      "12  3.370297           0.198905          0.157672          0.043992  \n",
      "13  2.715791           0.204758          0.163504          0.044253  \n",
      "1   2.667081           0.207641          0.160715          0.047240  \n",
      "11  2.618755           0.219036          0.170023          0.049943  \n",
      "3   2.388892           0.259139          0.192169          0.070272  \n",
      "15  2.354543           0.263560          0.208668          0.072283  \n",
      "0   6.171335           0.281657          0.217466          0.086558  \n",
      "2   2.807932           0.366317          0.304325          0.137889  \n",
      "Predictions for the next 12 periods (103-114) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.27880061 14.6956443  15.0032683  15.39231667 15.63093024 15.64453924\n",
      " 15.54240754 15.58492493 15.21022959 15.19783275 15.22309076 15.17818732]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.3711767  -0.31084147 -0.26631503 -0.21000297 -0.17546531 -0.1734955\n",
      " -0.18827836 -0.18212426 -0.23635881 -0.23815317 -0.23449725 -0.24099671]\n",
      "This is the 4th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model        MAE         MSE       RMSE         R^2  \\\n",
      "8           ExtraTreesRegressor   1.204860    2.798384   1.672837   -0.397063   \n",
      "14                     boosting   1.252371    2.764428   1.662657   -0.380110   \n",
      "4       Random Forest Regressor   1.240274    2.638162   1.624242   -0.317074   \n",
      "10               XGBRFRegressor   1.235691    2.535459   1.592313   -0.265800   \n",
      "9                  XGBRegressor   1.229619    2.385130   1.544386   -0.190750   \n",
      "5   Gradient Boosting Regressor   1.239448    2.657914   1.630311   -0.326935   \n",
      "6            Adaboost Regressor   1.249112    2.628773   1.621349   -0.312386   \n",
      "7              BaggingRegressor   1.221316    2.606402   1.614435   -0.301218   \n",
      "12                          SVM   1.381267    3.835198   1.958366   -0.914681   \n",
      "13                      bagging   1.229141    2.678113   1.636494   -0.337019   \n",
      "1              Ridge Regression   1.278717    2.804586   1.674690   -0.400159   \n",
      "11                     LightGBM   1.263096    2.621330   1.619052   -0.308670   \n",
      "3       Decision Tree Regressor   1.201483    2.179344   1.476260   -0.088014   \n",
      "0             Linear Regression  17.955427  805.157532  28.375298 -400.966123   \n",
      "15                     stacking   1.028658    1.925709   1.387699    0.038611   \n",
      "2              Lasso Regression   1.200625    2.899388   1.702759   -0.447488   \n",
      "\n",
      "       Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8     2.746328           0.098545          0.075194          0.010298  \n",
      "14    2.725138           0.173442          0.129913          0.033748  \n",
      "4     2.646342           0.180153          0.140479          0.035038  \n",
      "10    2.582251           0.183225          0.140221          0.035457  \n",
      "9     2.488437           0.185237          0.147255          0.035884  \n",
      "5     2.658668           0.186328          0.141203          0.036458  \n",
      "6     2.640483           0.187211          0.147641          0.037872  \n",
      "7     2.626522           0.187868          0.147038          0.036763  \n",
      "12    3.393351           0.193498          0.151327          0.040134  \n",
      "13    2.671273           0.200149          0.156634          0.041702  \n",
      "1     2.750199           0.201884          0.156217          0.042232  \n",
      "11    2.635838           0.208729          0.162521          0.045427  \n",
      "3     2.360017           0.247690          0.185733          0.069084  \n",
      "0   503.457653           0.248361          0.203411          0.064678  \n",
      "15    2.201736           0.266260          0.206650          0.074116  \n",
      "2     2.809360           0.364486          0.302728          0.136690  \n",
      "Predictions for the next 12 periods (104-115) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.61773957 15.092284   15.21049431 15.47168105 15.48553687 15.41160908\n",
      " 15.29501193 15.41664997 15.30002268 15.3516629  15.23548853 15.33559799]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.32211764 -0.25343062 -0.2363205  -0.19851553 -0.19650999 -0.20721053\n",
      " -0.22408716 -0.20648089 -0.22336189 -0.21588732 -0.23270276 -0.21821261]\n",
      "This is the 5th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model        MAE          MSE       RMSE  \\\n",
      "8           ExtraTreesRegressor   1.195128     2.774902   1.665804   \n",
      "9                  XGBRegressor   1.269246     2.534079   1.591879   \n",
      "14                     boosting   1.261552     2.770879   1.664596   \n",
      "10               XGBRFRegressor   1.228868     2.510738   1.584531   \n",
      "4       Random Forest Regressor   1.220504     2.567551   1.602358   \n",
      "6            Adaboost Regressor   1.245874     2.525387   1.589147   \n",
      "5   Gradient Boosting Regressor   1.252124     2.635596   1.623452   \n",
      "7              BaggingRegressor   1.199396     2.633369   1.622766   \n",
      "12                          SVM   1.380269     3.830355   1.957129   \n",
      "13                      bagging   1.236805     2.627000   1.620802   \n",
      "11                     LightGBM   1.255560     2.592883   1.610243   \n",
      "1              Ridge Regression   1.260160     2.735898   1.654055   \n",
      "3       Decision Tree Regressor   1.186550     2.091838   1.446319   \n",
      "15                     stacking   1.114571     2.302826   1.517507   \n",
      "0             Linear Regression  25.575538  1603.762425  40.047003   \n",
      "2              Lasso Regression   1.200605     2.901262   1.703309   \n",
      "\n",
      "           R^2      Adj R^2  Average RMSE (CV)  Average MAE (CV)  \\\n",
      "8    -0.385340     2.731675           0.103942          0.084244   \n",
      "9    -0.265111     2.581389           0.163696          0.132787   \n",
      "14   -0.383331     2.729164           0.165846          0.120797   \n",
      "10   -0.253458     2.566823           0.173861          0.133846   \n",
      "4    -0.281822     2.602277           0.175376          0.138366   \n",
      "6    -0.260772     2.575965           0.176006          0.142251   \n",
      "5    -0.315793     2.644741           0.179562          0.137170   \n",
      "7    -0.314681     2.643351           0.180618          0.135607   \n",
      "12   -0.912263     3.390329           0.191371          0.150643   \n",
      "13   -0.311501     2.639376           0.191968          0.155317   \n",
      "11   -0.294469     2.618086           0.192610          0.153885   \n",
      "1    -0.365867     2.707334           0.199089          0.153991   \n",
      "3    -0.044327     2.305409           0.278918          0.197065   \n",
      "15   -0.149661     2.437076           0.284526          0.222329   \n",
      "0  -799.660912  1001.826139           0.336138          0.275387   \n",
      "2    -0.448424     2.810530           0.359825          0.299494   \n",
      "\n",
      "    Average MSE (CV)  \n",
      "8           0.011758  \n",
      "9           0.028326  \n",
      "14          0.029730  \n",
      "10          0.034308  \n",
      "4           0.033964  \n",
      "6           0.033427  \n",
      "5           0.035341  \n",
      "7           0.036821  \n",
      "12          0.039980  \n",
      "13          0.040304  \n",
      "11          0.038982  \n",
      "1           0.041410  \n",
      "3           0.085919  \n",
      "15          0.084268  \n",
      "0           0.116451  \n",
      "2           0.134216  \n",
      "Predictions for the next 12 periods (105-116) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.81778273 15.20272869 15.45135781 15.2492965  15.25611309 14.98875253\n",
      " 14.85084843 15.0184355  15.24866737 15.26588911 15.26444564 15.36843454]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.29316278 -0.23744452 -0.20145717 -0.23070415 -0.22971749 -0.26841608\n",
      " -0.28837675 -0.26411968 -0.23079521 -0.22830248 -0.22851142 -0.21345974]\n",
      "This is the 6th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model        MAE         MSE       RMSE         R^2  \\\n",
      "8           ExtraTreesRegressor   1.169704    2.822907   1.680151   -0.409305   \n",
      "14                     boosting   1.220072    2.633252   1.622730   -0.314622   \n",
      "6            Adaboost Regressor   1.234136    2.498641   1.580709   -0.247419   \n",
      "10               XGBRFRegressor   1.208268    2.492528   1.578774   -0.244367   \n",
      "4       Random Forest Regressor   1.238158    2.622145   1.619304   -0.309077   \n",
      "5   Gradient Boosting Regressor   1.238918    2.623840   1.619827   -0.309924   \n",
      "9                  XGBRegressor   1.260423    2.477517   1.574013   -0.236873   \n",
      "11                     LightGBM   1.237495    2.574105   1.604402   -0.285094   \n",
      "12                          SVM   1.379542    3.827051   1.956285   -0.910613   \n",
      "1              Ridge Regression   1.201337    2.517593   1.586692   -0.256881   \n",
      "13                      bagging   1.239778    2.603508   1.613539   -0.299773   \n",
      "7              BaggingRegressor   1.227229    2.651980   1.628490   -0.323972   \n",
      "3       Decision Tree Regressor   1.178991    2.081266   1.442660   -0.039050   \n",
      "15                     stacking   1.084902    2.150583   1.466487   -0.073655   \n",
      "2              Lasso Regression   1.200576    2.904151   1.704157   -0.449866   \n",
      "0             Linear Regression  13.848083  481.074725  21.933416 -239.171313   \n",
      "\n",
      "       Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8     2.761632           0.101593          0.083141          0.011514  \n",
      "14    2.643278           0.157733          0.119909          0.026875  \n",
      "6     2.559274           0.172130          0.141892          0.032488  \n",
      "10    2.555459           0.173571          0.133663          0.033622  \n",
      "4     2.636347           0.178245          0.142485          0.035078  \n",
      "5     2.637405           0.178437          0.137908          0.033621  \n",
      "9     2.546092           0.180530          0.144595          0.035204  \n",
      "11    2.606367           0.193079          0.154840          0.039057  \n",
      "12    3.388267           0.193534          0.150824          0.040649  \n",
      "1     2.571101           0.199993          0.155127          0.041746  \n",
      "13    2.624716           0.200124          0.161127          0.042899  \n",
      "7     2.654965           0.205688          0.159712          0.048351  \n",
      "3     2.298812           0.252673          0.183470          0.074574  \n",
      "15    2.342069           0.275959          0.210314          0.080652  \n",
      "2     2.812332           0.359142          0.297077          0.132538  \n",
      "0   301.214141           0.365440          0.297005          0.139467  \n",
      "Predictions for the next 12 periods (106-117) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.32155682 15.00195321 15.02982473 14.9503726  14.82226572 14.8763252\n",
      " 15.27277503 15.4329406  15.22983289 15.29661194 15.05302346 15.20162911]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.36498804 -0.26650538 -0.26247117 -0.27397131 -0.2925139  -0.28468916\n",
      " -0.22730579 -0.20412294 -0.23352137 -0.22385557 -0.25911331 -0.23760367]\n",
      "This is the 7th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model        MAE         MSE       RMSE         R^2  \\\n",
      "8           ExtraTreesRegressor   1.179036    2.903746   1.704038   -0.449663   \n",
      "14                     boosting   1.223492    2.658508   1.630493   -0.327231   \n",
      "6            Adaboost Regressor   1.205770    2.466125   1.570390   -0.231186   \n",
      "4       Random Forest Regressor   1.205122    2.588155   1.608774   -0.292108   \n",
      "10               XGBRFRegressor   1.207215    2.512462   1.585075   -0.254319   \n",
      "9                  XGBRegressor   1.255369    2.528531   1.590135   -0.262341   \n",
      "5   Gradient Boosting Regressor   1.201351    2.678342   1.636564   -0.337133   \n",
      "12                          SVM   1.378839    3.823651   1.955416   -0.908916   \n",
      "7              BaggingRegressor   1.225924    2.588152   1.608774   -0.292107   \n",
      "13                      bagging   1.204406    2.679265   1.636846   -0.337594   \n",
      "1              Ridge Regression   1.129055    2.254403   1.501467   -0.125486   \n",
      "11                     LightGBM   1.238253    2.658505   1.630492   -0.327229   \n",
      "15                     stacking   1.020747    1.969932   1.403542    0.016533   \n",
      "3       Decision Tree Regressor   1.168505    2.113839   1.453905   -0.055311   \n",
      "0             Linear Regression  14.886859  552.771525  23.511094 -274.965159   \n",
      "2              Lasso Regression   1.200550    2.906598   1.704875   -0.451087   \n",
      "\n",
      "       Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8     2.812079           0.102174          0.080697          0.011284  \n",
      "14    2.659039           0.163431          0.122050          0.030027  \n",
      "6     2.538983           0.169099          0.135928          0.032004  \n",
      "4     2.615135           0.184176          0.141319          0.037443  \n",
      "10    2.567899           0.187903          0.140714          0.038545  \n",
      "9     2.577927           0.190560          0.150432          0.038695  \n",
      "5     2.671416           0.190600          0.140826          0.039422  \n",
      "12    3.386145           0.191187          0.151714          0.040362  \n",
      "7     2.615134           0.195837          0.149112          0.042876  \n",
      "13    2.671992           0.196491          0.160061          0.041524  \n",
      "1     2.406858           0.202823          0.155397          0.042715  \n",
      "11    2.659037           0.205847          0.165944          0.044120  \n",
      "15    2.229334           0.266696          0.201764          0.075905  \n",
      "3     2.319139           0.268843          0.190729          0.080644  \n",
      "0   345.956449           0.349898          0.296674          0.124542  \n",
      "2     2.813859           0.356288          0.296145          0.132098  \n",
      "Predictions for the next 12 periods (107-118) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[15.0795113  15.22696553 15.18325606 14.97098594 14.84794196 15.2390686\n",
      " 15.44856538 15.48701469 15.4645437  15.39257877 15.55404612 15.44395169]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.25527938 -0.2339364  -0.24026304 -0.27098767 -0.28879744 -0.23218457\n",
      " -0.20186136 -0.19629609 -0.19954861 -0.20996503 -0.18659375 -0.20252916]\n",
      "This is the 8th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE         MSE       RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.166865    2.820449   1.679419  -0.408079   \n",
      "14                     boosting  1.229486    2.843489   1.686265  -0.419581   \n",
      "7              BaggingRegressor  1.167497    2.425751   1.557482  -0.211030   \n",
      "5   Gradient Boosting Regressor  1.176994    2.721585   1.649723  -0.358722   \n",
      "10               XGBRFRegressor  1.160719    2.468542   1.571159  -0.232393   \n",
      "12                          SVM  1.378171    3.820474   1.954603  -0.907330   \n",
      "4       Random Forest Regressor  1.198100    2.610412   1.615677  -0.303220   \n",
      "6            Adaboost Regressor  1.229786    2.608281   1.615017  -0.302156   \n",
      "9                  XGBRegressor  1.170251    2.471484   1.572095  -0.233861   \n",
      "13                      bagging  1.177255    2.572062   1.603765  -0.284074   \n",
      "1              Ridge Regression  1.033849    1.909803   1.381956   0.046551   \n",
      "11                     LightGBM  1.212484    2.674615   1.635425  -0.335272   \n",
      "3       Decision Tree Regressor  1.100964    2.049703   1.431678  -0.023292   \n",
      "15                     stacking  1.158289    2.589152   1.609084  -0.292606   \n",
      "0             Linear Regression  7.490901  149.385553  12.222338 -73.579109   \n",
      "2              Lasso Regression  1.200547    2.906934   1.704973  -0.451255   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    2.760098           0.110318          0.088973          0.013326  \n",
      "14   2.774476           0.170504          0.130927          0.032726  \n",
      "7    2.513787           0.183133          0.146238          0.036237  \n",
      "5    2.698402           0.187053          0.146157          0.038818  \n",
      "10   2.540491           0.191650          0.148051          0.041473  \n",
      "12   3.384162           0.194338          0.150557          0.040167  \n",
      "4    2.629025           0.194600          0.150851          0.041702  \n",
      "6    2.627695           0.195670          0.154964          0.041589  \n",
      "9    2.542327           0.198125          0.157303          0.044598  \n",
      "13   2.605092           0.208346          0.165050          0.045378  \n",
      "1    2.191811           0.210103          0.161164          0.046241  \n",
      "11   2.669090           0.216757          0.173960          0.049374  \n",
      "3    2.279115           0.272485          0.198805          0.086573  \n",
      "15   2.615757           0.282570          0.218827          0.084500  \n",
      "0   94.223886           0.308565          0.261943          0.097216  \n",
      "2    2.814069           0.355795          0.292718          0.129937  \n",
      "Predictions for the next 12 periods (108-119) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[15.1502075  15.27295838 15.039992   14.88726762 14.85041969 15.36835714\n",
      " 15.27370061 15.34226444 15.23912393 15.45987413 15.27020303 15.49439541]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.2450466  -0.22727926 -0.26099952 -0.28310532 -0.2884388  -0.21347095\n",
      " -0.22717182 -0.21724768 -0.23217656 -0.2002245  -0.22767807 -0.19522778]\n",
      "This is the 9th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE         MSE       RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.176825    2.881364   1.697458  -0.438490   \n",
      "14                     boosting  1.189666    2.605997   1.614310  -0.301016   \n",
      "5   Gradient Boosting Regressor  1.159452    2.631300   1.622128  -0.313648   \n",
      "9                  XGBRegressor  1.215364    2.593705   1.610498  -0.294879   \n",
      "10               XGBRFRegressor  1.160647    2.471980   1.572253  -0.234109   \n",
      "4       Random Forest Regressor  1.191861    2.632181   1.622400  -0.314088   \n",
      "6            Adaboost Regressor  1.199719    2.549624   1.596754  -0.272872   \n",
      "12                          SVM  1.377637    3.818027   1.953977  -0.906108   \n",
      "1              Ridge Regression  0.991978    1.760374   1.326791   0.121152   \n",
      "11                     LightGBM  1.210972    2.720459   1.649381  -0.358160   \n",
      "13                      bagging  1.205228    2.690925   1.640404  -0.343415   \n",
      "7              BaggingRegressor  1.151719    2.518176   1.586876  -0.257172   \n",
      "3       Decision Tree Regressor  1.102525    2.046863   1.430686  -0.021874   \n",
      "15                     stacking  1.191283    2.755003   1.659820  -0.375405   \n",
      "0             Linear Regression  6.763701  115.886508  10.765060 -56.855076   \n",
      "2              Lasso Regression  1.200545    2.907155   1.705038  -0.451365   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    2.798112           0.100680          0.079142          0.011664  \n",
      "14   2.626269           0.169615          0.125331          0.030908  \n",
      "5    2.642060           0.173291          0.129733          0.032600  \n",
      "9    2.618599           0.175458          0.146118          0.034995  \n",
      "10   2.542637           0.182707          0.137594          0.037591  \n",
      "4    2.642610           0.187677          0.145385          0.039359  \n",
      "6    2.591090           0.189016          0.148530          0.040554  \n",
      "12   3.382636           0.189344          0.146974          0.038049  \n",
      "1    2.098560           0.202006          0.156976          0.041958  \n",
      "11   2.697699           0.202116          0.156297          0.044258  \n",
      "13   2.679269           0.204394          0.162003          0.044139  \n",
      "7    2.571465           0.204510          0.163454          0.044599  \n",
      "3    2.277343           0.246412          0.173808          0.067132  \n",
      "15   2.719256           0.292042          0.230796          0.089228  \n",
      "0   73.318845           0.308421          0.253627          0.104229  \n",
      "2    2.814207           0.352576          0.289229          0.128377  \n",
      "Predictions for the next 12 periods (109-120) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[14.91810235 14.84042047 14.81550947 14.91503637 14.89623645 14.89009926\n",
      " 14.9082049  14.77362673 14.81806392 14.92199986 14.99091295 14.99706297]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.27864221 -0.28988612 -0.29349182 -0.27908599 -0.28180714 -0.28269546\n",
      " -0.28007479 -0.29955405 -0.29312208 -0.27807807 -0.26810338 -0.2672132 ]\n",
      "This is the 10th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE         MSE       RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.158758    2.909821   1.705820  -0.452696   \n",
      "14                     boosting  1.207361    2.861039   1.691461  -0.428343   \n",
      "5   Gradient Boosting Regressor  1.160321    2.702447   1.643912  -0.349167   \n",
      "6            Adaboost Regressor  1.182292    2.458142   1.567846  -0.227200   \n",
      "9                  XGBRegressor  1.222190    2.637325   1.623984  -0.316656   \n",
      "10               XGBRFRegressor  1.137923    2.479915   1.574774  -0.238070   \n",
      "4       Random Forest Regressor  1.170209    2.621697   1.619166  -0.308854   \n",
      "11                     LightGBM  1.199266    2.834850   1.683701  -0.415268   \n",
      "12                          SVM  1.395753    3.906705   1.976539  -0.950380   \n",
      "1              Ridge Regression  1.025070    1.878471   1.370573   0.062194   \n",
      "13                      bagging  1.190590    2.767089   1.663457  -0.381439   \n",
      "7              BaggingRegressor  1.211652    2.776367   1.666243  -0.386071   \n",
      "3       Decision Tree Regressor  1.089211    2.021440   1.421773  -0.009182   \n",
      "15                     stacking  1.288779    3.224037   1.795560  -0.609566   \n",
      "2              Lasso Regression  1.200577    2.912288   1.706543  -0.453928   \n",
      "0             Linear Regression  7.241038  124.734552  11.168462 -61.272366   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    2.815870           0.103691          0.085120          0.011926  \n",
      "14   2.785428           0.164943          0.125620          0.031297  \n",
      "5    2.686459           0.171105          0.125924          0.030666  \n",
      "6    2.534001           0.176182          0.143582          0.034569  \n",
      "9    2.645820           0.177739          0.140088          0.033778  \n",
      "10   2.547588           0.177813          0.133961          0.035147  \n",
      "4    2.636067           0.184052          0.142583          0.037453  \n",
      "11   2.769085           0.186778          0.147315          0.036867  \n",
      "12   3.437975           0.189722          0.148402          0.038400  \n",
      "1    2.172257           0.194768          0.152743          0.041176  \n",
      "13   2.726798           0.201700          0.159649          0.042855  \n",
      "7    2.732588           0.205659          0.160744          0.044685  \n",
      "3    2.261477           0.224472          0.157693          0.058707  \n",
      "15   3.011957           0.282225          0.228418          0.084787  \n",
      "2    2.817410           0.349971          0.288061          0.127342  \n",
      "0   78.840457           0.380482          0.321877          0.157298  \n",
      "Predictions for the next 12 periods (110-121) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.41618624 13.7693652  14.19489752 14.40087929 14.39809325 14.45084498\n",
      " 14.36178244 14.27538458 14.38123025 14.42444679 14.49854081 14.39453895]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.49603416 -0.44491395 -0.3833211  -0.35350666 -0.35390992 -0.34627447\n",
      " -0.35916566 -0.37167115 -0.35635072 -0.35009543 -0.33937083 -0.35442438]\n",
      "This is the 11th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE         MSE       RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.310682    3.788588   1.946430  -0.891411   \n",
      "5   Gradient Boosting Regressor  1.187366    3.000155   1.732096  -0.497795   \n",
      "14                     boosting  1.179262    2.635193   1.623328  -0.315591   \n",
      "9                  XGBRegressor  1.297366    3.347311   1.829566  -0.671108   \n",
      "10               XGBRFRegressor  1.140602    2.629971   1.621719  -0.312984   \n",
      "4       Random Forest Regressor  1.180572    2.858293   1.690649  -0.426972   \n",
      "12                          SVM  1.409300    3.970493   1.992610  -0.982225   \n",
      "1              Ridge Regression  1.120115    2.262367   1.504117  -0.129462   \n",
      "6            Adaboost Regressor  1.222332    2.932369   1.712416  -0.463953   \n",
      "11                     LightGBM  1.214335    2.977725   1.725609  -0.486597   \n",
      "13                      bagging  1.187540    2.794985   1.671821  -0.395366   \n",
      "7              BaggingRegressor  1.260548    3.416535   1.848387  -0.705668   \n",
      "3       Decision Tree Regressor  1.084408    2.040456   1.428445  -0.018675   \n",
      "15                     stacking  1.339132    3.521556   1.876581  -0.758099   \n",
      "2              Lasso Regression  1.200702    2.924481   1.710111  -0.460015   \n",
      "0             Linear Regression  8.542680  174.441646  13.207636 -86.088091   \n",
      "\n",
      "       Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8     3.364264           0.109748          0.086680          0.013888  \n",
      "5     2.872243           0.173485          0.131338          0.031885  \n",
      "14    2.644489           0.180353          0.132170          0.036387  \n",
      "9     3.088885           0.180519          0.134129          0.035319  \n",
      "10    2.641230           0.184401          0.137607          0.036991  \n",
      "4     2.783715           0.188145          0.141047          0.038443  \n",
      "12    3.477782           0.194427          0.151882          0.040440  \n",
      "1     2.411828           0.199915          0.155402          0.043092  \n",
      "6     2.829942           0.200247          0.159869          0.043658  \n",
      "11    2.858246           0.202809          0.157869          0.043218  \n",
      "13    2.744207           0.211328          0.163843          0.047454  \n",
      "7     3.132085           0.218395          0.166869          0.050115  \n",
      "3     2.273344           0.255758          0.178385          0.071694  \n",
      "15    3.197623           0.320411          0.259751          0.107544  \n",
      "2     2.825019           0.354621          0.291532          0.130756  \n",
      "0   109.860113           0.400292          0.321394          0.177782  \n",
      "Predictions for the next 12 periods (111-122) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[11.09196786 11.76462526 11.73020808 12.10287363 12.11413945 12.18518362\n",
      " 12.33012251 11.81175805 11.59784295 11.59868687 11.47739435 11.26586916]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.83244866 -0.73508617 -0.74006781 -0.68612706 -0.68449641 -0.67421326\n",
      " -0.65323436 -0.72826402 -0.75922675 -0.7591046  -0.77666085 -0.80727765]\n",
      "This is the 12th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.349688   3.973616  1.993393  -0.983785   \n",
      "14                     boosting  1.260544   3.352654  1.831025  -0.673776   \n",
      "5   Gradient Boosting Regressor  1.255612   3.428385  1.851590  -0.711584   \n",
      "12                          SVM  1.451024   4.151876  2.037615  -1.072779   \n",
      "1              Ridge Regression  1.179432   2.509123  1.584021  -0.252653   \n",
      "10               XGBRFRegressor  1.219728   3.307384  1.818621  -0.651175   \n",
      "4       Random Forest Regressor  1.243797   3.394771  1.842490  -0.694802   \n",
      "9                  XGBRegressor  1.328360   3.583886  1.893115  -0.789216   \n",
      "6            Adaboost Regressor  1.259273   3.150513  1.774968  -0.572859   \n",
      "11                     LightGBM  1.227588   3.179443  1.783099  -0.587302   \n",
      "13                      bagging  1.191393   2.817373  1.678503  -0.406543   \n",
      "7              BaggingRegressor  1.217378   3.202362  1.789515  -0.598744   \n",
      "3       Decision Tree Regressor  1.082759   2.054778  1.433450  -0.025825   \n",
      "2              Lasso Regression  1.201031   2.937816  1.714006  -0.466672   \n",
      "15                     stacking  1.421323   3.873005  1.967995  -0.933556   \n",
      "0             Linear Regression  6.390874  98.379575  9.918648 -48.114931   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    3.479731           0.111832          0.088662          0.013429  \n",
      "14   3.092220           0.162403          0.117925          0.029540  \n",
      "5    3.139480           0.184896          0.130631          0.035166  \n",
      "12   3.590974           0.195894          0.149939          0.039789  \n",
      "1    2.565816           0.197355          0.150950          0.040745  \n",
      "10   3.063969           0.198146          0.144608          0.044423  \n",
      "4    3.118503           0.201258          0.149227          0.045708  \n",
      "9    3.236520           0.205789          0.151900          0.046528  \n",
      "6    2.966074           0.208585          0.160002          0.048376  \n",
      "11   2.984128           0.210662          0.159368          0.047791  \n",
      "13   2.758178           0.215985          0.167389          0.050311  \n",
      "7    2.998431           0.216667          0.166559          0.053086  \n",
      "3    2.282282           0.302033          0.210769          0.110659  \n",
      "2    2.833341           0.360363          0.292940          0.132945  \n",
      "15   3.416944           0.361651          0.288058          0.137638  \n",
      "0   62.393663           0.420643          0.341825          0.194347  \n",
      "Predictions for the next 12 periods (112-123) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[10.95548806 12.05804974 12.16094144 12.58308068 12.59346608 12.56293076\n",
      " 12.34586047 11.83535071 12.0032926  11.87739953 11.05946284 11.36772447]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.85220317 -0.692615   -0.67772214 -0.61662041 -0.6151172  -0.61953698\n",
      " -0.6509564  -0.72484915 -0.70054072 -0.71876287 -0.83715354 -0.7925348 ]\n",
      "This is the 13th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.346760   3.952064  1.987980  -0.973025   \n",
      "5   Gradient Boosting Regressor  1.264021   3.578686  1.891742  -0.786620   \n",
      "10               XGBRFRegressor  1.312770   3.693367  1.921814  -0.843873   \n",
      "9                  XGBRegressor  1.382775   4.147582  2.036561  -1.070635   \n",
      "12                          SVM  1.508877   4.376686  2.092053  -1.185013   \n",
      "4       Random Forest Regressor  1.262096   3.532786  1.879571  -0.763705   \n",
      "1              Ridge Regression  1.218061   2.673244  1.635006  -0.334588   \n",
      "14                     boosting  1.160744   2.964861  1.721877  -0.480175   \n",
      "6            Adaboost Regressor  1.317187   3.351836  1.830802  -0.673368   \n",
      "7              BaggingRegressor  1.238306   3.392943  1.841994  -0.693890   \n",
      "13                      bagging  1.216816   3.200529  1.789002  -0.597829   \n",
      "11                     LightGBM  1.245529   3.358747  1.832688  -0.676818   \n",
      "3       Decision Tree Regressor  1.369285   3.974614  1.993643  -0.984283   \n",
      "2              Lasso Regression  1.201887   2.950914  1.717822  -0.473211   \n",
      "15                     stacking  0.990545   1.901494  1.378947   0.050700   \n",
      "0             Linear Regression  4.275251  41.900209  6.473037 -19.918222   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    3.466281           0.107576          0.087708          0.012398  \n",
      "5    3.233275           0.191157          0.138422          0.037557  \n",
      "10   3.304842           0.191484          0.140359          0.039901  \n",
      "9    3.588294           0.194930          0.144107          0.040197  \n",
      "12   3.731266           0.197195          0.153478          0.041019  \n",
      "4    3.204631           0.197422          0.150585          0.042214  \n",
      "1    2.668235           0.201148          0.153941          0.041656  \n",
      "14   2.850218           0.206258          0.142182          0.047545  \n",
      "6    3.091709           0.212476          0.163158          0.048011  \n",
      "7    3.117362           0.214285          0.162988          0.051182  \n",
      "13   2.997286           0.221501          0.174311          0.053643  \n",
      "11   3.096022           0.232039          0.178645          0.057155  \n",
      "3    3.480354           0.282471          0.194747          0.097358  \n",
      "2    2.841514           0.363778          0.295210          0.137035  \n",
      "15   2.186625           0.387999          0.311101          0.160267  \n",
      "0   27.147778           0.498640          0.387232          0.265304  \n",
      "Predictions for the next 12 periods (113-124) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[11.8549891  11.91594865 12.25151954 12.33035966 12.23197627 12.0502737\n",
      " 12.14847975 12.05865726 11.989554   11.34938074 11.2254109  11.22988173]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.72200663 -0.71318315 -0.66461159 -0.65320003 -0.66744035 -0.69374053\n",
      " -0.67952589 -0.69252707 -0.70252929 -0.79518993 -0.81313371 -0.81248659]\n",
      "This is the 14th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.339284   3.892130  1.972848  -0.943104   \n",
      "10               XGBRFRegressor  1.269045   3.551171  1.884455  -0.772883   \n",
      "5   Gradient Boosting Regressor  1.257018   3.596547  1.896456  -0.795537   \n",
      "1              Ridge Regression  1.226438   2.705966  1.644982  -0.350924   \n",
      "12                          SVM  1.508883   4.376267  2.091953  -1.184804   \n",
      "4       Random Forest Regressor  1.238464   3.446315  1.856425  -0.720535   \n",
      "9                  XGBRegressor  1.371954   4.190976  2.047187  -1.092299   \n",
      "14                     boosting  1.239326   3.453185  1.858275  -0.723965   \n",
      "6            Adaboost Regressor  1.245926   3.465586  1.861608  -0.730156   \n",
      "11                     LightGBM  1.241746   3.431041  1.852307  -0.712910   \n",
      "13                      bagging  1.190192   3.055228  1.747921  -0.525289   \n",
      "7              BaggingRegressor  1.215672   3.235420  1.798727  -0.615248   \n",
      "3       Decision Tree Regressor  1.227313   3.289885  1.813804  -0.642439   \n",
      "2              Lasso Regression  1.202803   2.961049  1.720770  -0.478271   \n",
      "15                     stacking  1.258246   3.221574  1.794874  -0.608336   \n",
      "0             Linear Regression  4.905813  52.812246  7.267203 -25.365938   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    3.428880           0.106940          0.087166          0.012531  \n",
      "10   3.216104           0.182007          0.140045          0.034621  \n",
      "5    3.244421           0.184696          0.135844          0.035414  \n",
      "1    2.688655           0.196548          0.149823          0.039521  \n",
      "12   3.731004           0.197426          0.152406          0.040106  \n",
      "4    3.150669           0.201944          0.154051          0.043300  \n",
      "9    3.615374           0.206754          0.153632          0.049482  \n",
      "14   3.154956           0.208477          0.142445          0.046806  \n",
      "6    3.162695           0.219000          0.164337          0.053073  \n",
      "11   3.141137           0.220938          0.165204          0.049949  \n",
      "13   2.906612           0.224073          0.172764          0.053071  \n",
      "7    3.019060           0.225220          0.163397          0.055615  \n",
      "3    3.053049           0.276228          0.188894          0.086484  \n",
      "2    2.847839           0.367270          0.297831          0.138320  \n",
      "15   3.010420           0.395054          0.322428          0.160856  \n",
      "0   33.957423           0.754335          0.601392          0.730429  \n",
      "Predictions for the next 12 periods (114-125) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[11.38872602 11.54010617 11.54515951 11.92581819 11.65951215 11.51129881\n",
      " 11.22216967 11.14979909 11.1014765  11.13649084 11.20470511 11.20560549]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.78949498 -0.76758375 -0.76685231 -0.71175461 -0.75030056 -0.77175341\n",
      " -0.81360285 -0.82407799 -0.83107235 -0.82600427 -0.81613073 -0.8160004 ]\n",
      "This is the 15th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.283158   3.712529  1.926792  -0.853440   \n",
      "5   Gradient Boosting Regressor  1.263850   3.581315  1.892436  -0.787932   \n",
      "14                     boosting  1.178772   3.158489  1.777214  -0.576841   \n",
      "9                  XGBRegressor  1.298263   3.739410  1.933755  -0.866859   \n",
      "10               XGBRFRegressor  1.247690   3.497544  1.870172  -0.746111   \n",
      "12                          SVM  1.493552   4.321353  2.078786  -1.157388   \n",
      "1              Ridge Regression  1.221742   2.690099  1.640152  -0.343003   \n",
      "4       Random Forest Regressor  1.220155   3.352205  1.830903  -0.673552   \n",
      "11                     LightGBM  1.258848   3.504380  1.871999  -0.749524   \n",
      "6            Adaboost Regressor  1.274433   3.602863  1.898121  -0.798690   \n",
      "13                      bagging  1.197259   3.105443  1.762227  -0.550359   \n",
      "7              BaggingRegressor  1.285973   3.662725  1.913825  -0.828575   \n",
      "3       Decision Tree Regressor  1.267661   3.642131  1.908437  -0.818294   \n",
      "2              Lasso Regression  1.203465   2.968250  1.722861  -0.481866   \n",
      "15                     stacking  1.126365   2.531788  1.591159  -0.263967   \n",
      "0             Linear Regression  6.302038  82.744430  9.096397 -40.309255   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    3.316800           0.101275          0.079386          0.010982  \n",
      "5    3.234916           0.181641          0.137182          0.034378  \n",
      "14   2.971052           0.182101          0.124474          0.039174  \n",
      "9    3.333574           0.182373          0.131085          0.037028  \n",
      "10   3.182639           0.193653          0.143370          0.039555  \n",
      "12   3.696735           0.193966          0.146246          0.038334  \n",
      "1    2.678753           0.195682          0.148881          0.039267  \n",
      "4    3.091940           0.197298          0.147146          0.041554  \n",
      "11   3.186904           0.213878          0.167488          0.047320  \n",
      "6    3.248363           0.218147          0.165892          0.050102  \n",
      "13   2.937948           0.220914          0.169351          0.050739  \n",
      "7    3.285719           0.241786          0.177903          0.061894  \n",
      "3    3.272868           0.290697          0.210909          0.091652  \n",
      "2    2.852333           0.370802          0.299061          0.138529  \n",
      "15   2.579959           0.403460          0.331474          0.165648  \n",
      "0   52.636569           3.544615          2.990809         51.896624  \n",
      "Predictions for the next 12 periods (115-126) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[12.20059446 12.29688027 12.3116344  11.91243702 11.81437378 11.57815408\n",
      " 11.50046331 11.47983061 11.47744655 11.47742065 11.70260475 11.71246997]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.67198264 -0.65804594 -0.65591038 -0.71369144 -0.72788541 -0.76207658\n",
      " -0.77332178 -0.77630822 -0.77665329 -0.77665704 -0.7440632  -0.74263528]\n",
      "This is the 16th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.265931   3.611605  1.900422  -0.803055   \n",
      "5   Gradient Boosting Regressor  1.216125   3.337062  1.826763  -0.665992   \n",
      "10               XGBRFRegressor  1.221639   3.412852  1.847391  -0.703829   \n",
      "14                     boosting  1.318107   3.810203  1.951974  -0.902202   \n",
      "9                  XGBRegressor  1.308262   3.747987  1.935972  -0.871141   \n",
      "4       Random Forest Regressor  1.264347   3.563989  1.887853  -0.779283   \n",
      "12                          SVM  1.424130   4.052163  2.012999  -1.022998   \n",
      "1              Ridge Regression  1.208843   2.652840  1.628754  -0.324401   \n",
      "11                     LightGBM  1.282850   3.609980  1.899995  -0.802243   \n",
      "13                      bagging  1.215787   3.230665  1.797405  -0.612874   \n",
      "6            Adaboost Regressor  1.246549   3.422583  1.850022  -0.708687   \n",
      "7              BaggingRegressor  1.274661   3.558951  1.886518  -0.776767   \n",
      "3       Decision Tree Regressor  1.329970   3.871484  1.967609  -0.932796   \n",
      "2              Lasso Regression  1.203836   2.971639  1.723844  -0.483558   \n",
      "15                     stacking  1.094667   2.411405  1.552870  -0.203868   \n",
      "0             Linear Regression  3.773323  29.861112  5.464532 -13.907835   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    3.253818           0.104279          0.083071          0.011903  \n",
      "5    3.082490           0.185886          0.135055          0.036274  \n",
      "10   3.129787           0.185985          0.137840          0.036184  \n",
      "14   3.377753           0.192054          0.129808          0.041022  \n",
      "9    3.338927           0.193759          0.142140          0.044146  \n",
      "4    3.224103           0.195269          0.147699          0.039997  \n",
      "12   3.528748           0.196763          0.149577          0.039614  \n",
      "1    2.655502           0.197015          0.151078          0.039976  \n",
      "11   3.252804           0.207274          0.159796          0.044721  \n",
      "13   3.016093           0.222199          0.169026          0.051101  \n",
      "6    3.135859           0.222554          0.174709          0.051204  \n",
      "7    3.220959           0.224351          0.165341          0.052600  \n",
      "3    3.415995           0.322653          0.232291          0.109461  \n",
      "2    2.854448           0.369286          0.297765          0.137477  \n",
      "15   2.504834           0.429992          0.357864          0.187283  \n",
      "0   19.634793           0.774633          0.628930          0.814815  \n",
      "Predictions for the next 12 periods (116-127) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[11.98908174 12.0540007  11.86068824 11.98483549 11.71836454 11.61580357\n",
      " 11.67190634 11.56984387 11.6301009  11.70107364 11.70866059 11.75295919]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.70259765 -0.69320108 -0.72118171 -0.70321226 -0.74178208 -0.75662707\n",
      " -0.74850659 -0.76327942 -0.75455763 -0.74428482 -0.74318666 -0.73677475]\n",
      "This is the 17th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE        R^2  \\\n",
      "8           ExtraTreesRegressor  1.271363   3.658319  1.912673  -0.826376   \n",
      "5   Gradient Boosting Regressor  1.181940   3.204778  1.790189  -0.599951   \n",
      "14                     boosting  1.311890   3.760698  1.939252  -0.877488   \n",
      "10               XGBRFRegressor  1.207928   3.358294  1.832565  -0.676592   \n",
      "4       Random Forest Regressor  1.233808   3.404704  1.845184  -0.699761   \n",
      "1              Ridge Regression  1.197291   2.623160  1.619617  -0.309584   \n",
      "11                     LightGBM  1.229186   3.419503  1.849190  -0.707150   \n",
      "12                          SVM  1.399712   3.953937  1.988451  -0.973960   \n",
      "9                  XGBRegressor  1.243084   3.485826  1.867037  -0.740261   \n",
      "6            Adaboost Regressor  1.258944   3.441613  1.855159  -0.718188   \n",
      "7              BaggingRegressor  1.210667   3.311299  1.819698  -0.653130   \n",
      "13                      bagging  1.159104   2.959353  1.720277  -0.477425   \n",
      "3       Decision Tree Regressor  1.201453   3.191861  1.786578  -0.593502   \n",
      "2              Lasso Regression  1.204057   2.973651  1.724428  -0.484563   \n",
      "15                     stacking  1.071222   2.314745  1.521429  -0.155611   \n",
      "0             Linear Regression  4.149800  36.190276  6.015835 -17.067601   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    3.282970           0.107299          0.086186          0.012759  \n",
      "5    2.999938           0.186218          0.132138          0.036256  \n",
      "14   3.346860           0.187251          0.128330          0.038689  \n",
      "10   3.095740           0.187369          0.140947          0.037226  \n",
      "4    3.124702           0.193496          0.144768          0.040295  \n",
      "1    2.636980           0.193833          0.149032          0.038734  \n",
      "11   3.133937           0.195562          0.154470          0.040049  \n",
      "12   3.467450           0.197771          0.151365          0.039939  \n",
      "9    3.175326           0.200387          0.135677          0.045589  \n",
      "6    3.147735           0.221309          0.170830          0.050971  \n",
      "7    3.066412           0.222083          0.164964          0.051653  \n",
      "13   2.846781           0.229029          0.176034          0.055826  \n",
      "3    2.991877           0.254185          0.170946          0.068677  \n",
      "2    2.855703           0.370622          0.298697          0.138438  \n",
      "15   2.444514           0.426834          0.351914          0.184778  \n",
      "0   23.584501           0.508165          0.423118          0.281672  \n",
      "Predictions for the next 12 periods (117-128) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.42119213 12.93387011 12.54104874 12.2276007  12.06897682 11.84123817\n",
      " 11.85380517 11.84401719 11.94053197 12.08488926 12.26296817 12.31334032]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.49530959 -0.56584607 -0.62270425 -0.66807368 -0.69103339 -0.72399698\n",
      " -0.72217799 -0.72359473 -0.70962489 -0.68873017 -0.66295448 -0.65566346]\n",
      "This is the 18th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE        MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.288571   3.742193  1.934475 -0.868249   \n",
      "10               XGBRFRegressor  1.205646   3.347169  1.829527 -0.671037   \n",
      "5   Gradient Boosting Regressor  1.150172   3.005366  1.733599 -0.500396   \n",
      "1              Ridge Regression  1.191954   2.608380  1.615048 -0.302205   \n",
      "9                  XGBRegressor  1.206669   3.330584  1.824989 -0.662758   \n",
      "11                     LightGBM  1.244956   3.454913  1.858740 -0.724828   \n",
      "4       Random Forest Regressor  1.244109   3.481328  1.865832 -0.738015   \n",
      "12                          SVM  1.375426   3.860902  1.964918 -0.927513   \n",
      "14                     boosting  1.209690   3.352406  1.830958 -0.673652   \n",
      "7              BaggingRegressor  1.115796   2.826829  1.681318 -0.411264   \n",
      "6            Adaboost Regressor  1.259839   3.476847  1.864631 -0.735778   \n",
      "13                      bagging  1.203672   3.193476  1.787030 -0.594308   \n",
      "3       Decision Tree Regressor  1.219312   3.406915  1.845783 -0.700865   \n",
      "2              Lasso Regression  1.204424   2.977013  1.725402 -0.486242   \n",
      "15                     stacking  1.116037   2.481579  1.575303 -0.238902   \n",
      "0             Linear Regression  2.854281  17.105149  4.135837 -7.539559   \n",
      "\n",
      "      Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8    3.335311           0.104800          0.084718          0.012165  \n",
      "10   3.088797           0.181286          0.134898          0.034846  \n",
      "5    2.875495           0.181731          0.135356          0.033943  \n",
      "1    2.627756           0.192937          0.148941          0.038751  \n",
      "9    3.078447           0.192962          0.128487          0.044093  \n",
      "11   3.156035           0.193088          0.154855          0.038729  \n",
      "4    3.172519           0.195279          0.148884          0.040379  \n",
      "12   3.409392           0.196118          0.150636          0.039374  \n",
      "14   3.092065           0.208576          0.143925          0.048860  \n",
      "7    2.764080           0.209597          0.150490          0.046731  \n",
      "6    3.169723           0.218471          0.166535          0.051007  \n",
      "13   2.992885           0.229856          0.174681          0.055696  \n",
      "3    3.126082           0.274488          0.185907          0.080880  \n",
      "2    2.857802           0.369270          0.297379          0.137308  \n",
      "15   2.548627           0.435909          0.357059          0.193565  \n",
      "0   11.674449           0.519758          0.416594          0.313609  \n",
      "Predictions for the next 12 periods (118-129) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.27668083 12.73914139 12.30252872 12.16459068 11.95717207 11.96055007\n",
      " 12.05578802 12.19505207 12.24326012 12.49769957 12.52391052 11.93143551]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.5162266  -0.59403171 -0.65722837 -0.67719394 -0.70721635 -0.70672741\n",
      " -0.69294237 -0.67278487 -0.66580708 -0.62897874 -0.62518489 -0.71094154]\n",
      "This is the 19th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.281163  3.694883  1.922208 -0.844630   \n",
      "5   Gradient Boosting Regressor  1.129495  2.890369  1.700108 -0.442985   \n",
      "10               XGBRFRegressor  1.193875  3.278795  1.810744 -0.636903   \n",
      "14                     boosting  1.262406  3.596047  1.896325 -0.795287   \n",
      "9                  XGBRegressor  1.197973  3.291811  1.814335 -0.643401   \n",
      "4       Random Forest Regressor  1.249441  3.490452  1.868275 -0.742570   \n",
      "1              Ridge Regression  1.192764  2.610935  1.615839 -0.303481   \n",
      "11                     LightGBM  1.293461  3.719497  1.928600 -0.856919   \n",
      "12                          SVM  1.376044  3.863824  1.965661 -0.928972   \n",
      "7              BaggingRegressor  1.277679  3.587132  1.893972 -0.790836   \n",
      "6            Adaboost Regressor  1.217313  3.304503  1.817829 -0.649737   \n",
      "13                      bagging  1.207027  3.166870  1.779570 -0.581025   \n",
      "3       Decision Tree Regressor  1.294340  3.857504  1.964053 -0.925817   \n",
      "2              Lasso Regression  1.204957  2.981890  1.726815 -0.488676   \n",
      "15                     stacking  1.338323  3.432137  1.852603 -0.713457   \n",
      "0             Linear Regression  1.093613  2.589947  1.609331 -0.293003   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   3.305787           0.103637          0.082156          0.011563  \n",
      "5   2.803731           0.161302          0.123036          0.029695  \n",
      "10  3.046128           0.177510          0.132302          0.034768  \n",
      "14  3.244109           0.183359          0.128283          0.039068  \n",
      "9   3.054251           0.184735          0.127359          0.041384  \n",
      "4   3.178213           0.186522          0.140688          0.037156  \n",
      "1   2.629351           0.189599          0.144689          0.037702  \n",
      "11  3.321148           0.189707          0.151448          0.038473  \n",
      "12  3.411215           0.193863          0.149519          0.038723  \n",
      "7   3.238545           0.202384          0.153381          0.046256  \n",
      "6   3.062171           0.206770          0.156382          0.045418  \n",
      "13  2.976282           0.214242          0.165609          0.048068  \n",
      "3   3.407271           0.248296          0.180876          0.064096  \n",
      "2   2.860845           0.368013          0.297017          0.136753  \n",
      "15  3.141821           0.425293          0.351848          0.187027  \n",
      "0   2.616253           0.545439          0.437238          0.344249  \n",
      "Predictions for the next 12 periods (119-130) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[12.64241361 12.32093103 12.21797858 11.85888553 11.82070828 11.92978723\n",
      " 12.15947944 12.21370312 12.49089924 12.3872251  12.10480088 11.95639311]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.60803238 -0.65456476 -0.66946641 -0.72144264 -0.72696854 -0.71118011\n",
      " -0.67793376 -0.67008526 -0.62996304 -0.64496915 -0.6858481  -0.7073291 ]\n",
      "This is the 20th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.263229  3.635793  1.906776 -0.815130   \n",
      "5   Gradient Boosting Regressor  1.138451  2.950067  1.717576 -0.472789   \n",
      "9                  XGBRegressor  1.193004  3.265785  1.807148 -0.630408   \n",
      "10               XGBRFRegressor  1.186622  3.256788  1.804657 -0.625916   \n",
      "4       Random Forest Regressor  1.251766  3.506538  1.872575 -0.750601   \n",
      "14                     boosting  1.246604  3.519154  1.875941 -0.756899   \n",
      "11                     LightGBM  1.262876  3.653519  1.911418 -0.823980   \n",
      "1              Ridge Regression  1.190980  2.605515  1.614161 -0.300775   \n",
      "12                          SVM  1.376702  3.866963  1.966459 -0.930539   \n",
      "7              BaggingRegressor  1.177118  3.156637  1.776693 -0.575917   \n",
      "13                      bagging  1.218657  3.255382  1.804268 -0.625214   \n",
      "6            Adaboost Regressor  1.236325  3.394904  1.842527 -0.694869   \n",
      "3       Decision Tree Regressor  1.368343  4.069559  2.017315 -1.031683   \n",
      "2              Lasso Regression  1.205491  2.986798  1.728235 -0.491126   \n",
      "15                     stacking  1.211524  2.841778  1.685758 -0.418727   \n",
      "0             Linear Regression  0.644440  0.936032  0.967487  0.532696   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   3.268913           0.099655          0.078747          0.010359  \n",
      "5   2.840986           0.176395          0.125989          0.032914  \n",
      "9   3.038009           0.184245          0.130346          0.041423  \n",
      "10  3.032395           0.186533          0.135502          0.036787  \n",
      "4   3.188251           0.187839          0.139032          0.037376  \n",
      "14  3.196124           0.189693          0.129349          0.042126  \n",
      "11  3.279974           0.190286          0.148383          0.038581  \n",
      "1   2.625969           0.191127          0.141842          0.037235  \n",
      "12  3.413174           0.197289          0.151926          0.039821  \n",
      "7   2.969896           0.209363          0.146841          0.048040  \n",
      "13  3.031518           0.222150          0.171421          0.051545  \n",
      "6   3.118586           0.229774          0.164267          0.056080  \n",
      "3   3.539603           0.245543          0.168634          0.062746  \n",
      "2   2.863908           0.360702          0.293028          0.134149  \n",
      "15  2.773409           0.403918          0.331409          0.169314  \n",
      "0   1.584129           0.589252          0.475487          0.369223  \n",
      "Predictions for the next 12 periods (120-131) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[12.5013359  12.32383429 11.80668044 11.75411135 11.87509807 12.2617483\n",
      " 12.18266307 12.66167848 12.5080283  11.88034019 11.70750039 11.84642907]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.6284524  -0.65414453 -0.72899897 -0.73660798 -0.71909599 -0.66313105\n",
      " -0.67457809 -0.60524393 -0.62748373 -0.71833723 -0.74335459 -0.72324563]\n",
      "This is the 21th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.279750  3.726920  1.930523 -0.860624   \n",
      "5   Gradient Boosting Regressor  1.128263  2.891032  1.700303 -0.443316   \n",
      "11                     LightGBM  1.256336  3.575808  1.890981 -0.785183   \n",
      "10               XGBRFRegressor  1.208918  3.351403  1.830684 -0.673152   \n",
      "9                  XGBRegressor  1.181079  3.190152  1.786100 -0.592648   \n",
      "4       Random Forest Regressor  1.217591  3.331395  1.825211 -0.663163   \n",
      "1              Ridge Regression  1.192641  2.611560  1.616032 -0.303793   \n",
      "7              BaggingRegressor  1.247699  3.444018  1.855807 -0.719388   \n",
      "12                          SVM  1.377790  3.871970  1.967732 -0.933039   \n",
      "14                     boosting  1.291705  3.731142  1.931616 -0.862732   \n",
      "6            Adaboost Regressor  1.277508  3.529205  1.878618 -0.761917   \n",
      "13                      bagging  1.224176  3.268804  1.807983 -0.631915   \n",
      "3       Decision Tree Regressor  1.233485  3.522373  1.876799 -0.758506   \n",
      "15                     stacking  1.030395  2.118063  1.455357 -0.057420   \n",
      "2              Lasso Regression  1.206349  2.994705  1.730522 -0.495074   \n",
      "0             Linear Regression  1.105723  3.410537  1.846764 -0.702673   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   3.325780           0.099845          0.080565          0.010784  \n",
      "5   2.804145           0.161925          0.122745          0.027825  \n",
      "11  3.231479           0.169982          0.136014          0.030407  \n",
      "10  3.091440           0.183625          0.127300          0.036940  \n",
      "9   2.990810           0.184707          0.133291          0.038696  \n",
      "4   3.078953           0.186697          0.136871          0.037245  \n",
      "1   2.629741           0.190996          0.143653          0.037325  \n",
      "7   3.149235           0.194960          0.148802          0.039782  \n",
      "12  3.416298           0.196590          0.150127          0.039452  \n",
      "14  3.328415           0.197792          0.138846          0.043865  \n",
      "6   3.202396           0.210009          0.157440          0.046296  \n",
      "13  3.039893           0.214299          0.163967          0.047619  \n",
      "3   3.198133           0.261458          0.175846          0.071932  \n",
      "15  2.321775           0.361728          0.294148          0.137077  \n",
      "2   2.868842           0.364462          0.296443          0.136587  \n",
      "0   3.128342           0.587854          0.460134          0.364165  \n",
      "Predictions for the next 12 periods (121-132) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[11.6839765  11.39671265 11.54592966 11.5688119  11.77677027 11.80360184\n",
      " 12.14343691 12.05555307 11.76209525 11.66449881 11.68299275 11.72436383]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.74675951 -0.78833897 -0.76674084 -0.76342879 -0.73332826 -0.72944458\n",
      " -0.6802558  -0.69297638 -0.73545237 -0.74957877 -0.7469019  -0.74091373]\n",
      "This is the 22th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.259517  3.646093  1.909475 -0.820272   \n",
      "5   Gradient Boosting Regressor  1.123839  2.896279  1.701846 -0.445936   \n",
      "11                     LightGBM  1.274087  3.635552  1.906712 -0.815010   \n",
      "9                  XGBRegressor  1.253846  3.556661  1.885911 -0.775624   \n",
      "10               XGBRFRegressor  1.195964  3.251198  1.803108 -0.623125   \n",
      "4       Random Forest Regressor  1.233103  3.393405  1.842120 -0.694121   \n",
      "1              Ridge Regression  1.170424  2.532226  1.591297 -0.264186   \n",
      "12                          SVM  1.378875  3.877196  1.969060 -0.935648   \n",
      "14                     boosting  1.266549  3.603884  1.898390 -0.799200   \n",
      "7              BaggingRegressor  1.244798  3.408930  1.846329 -0.701871   \n",
      "6            Adaboost Regressor  1.258825  3.437243  1.853980 -0.716006   \n",
      "13                      bagging  1.239061  3.337555  1.826898 -0.666238   \n",
      "3       Decision Tree Regressor  1.288615  3.709148  1.925915 -0.851752   \n",
      "15                     stacking  0.869727  1.569996  1.252995  0.216197   \n",
      "2              Lasso Regression  1.207125  3.001885  1.732595 -0.498658   \n",
      "0             Linear Regression  1.200580  4.384793  2.093990 -1.189060   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   3.275341           0.105027          0.083881          0.011564  \n",
      "5   2.807419           0.165210          0.122891          0.028765  \n",
      "11  3.268762           0.180368          0.142633          0.033910  \n",
      "9   3.219530           0.184942          0.133400          0.037580  \n",
      "10  3.028906           0.188937          0.135848          0.037159  \n",
      "4   3.117651           0.190802          0.139520          0.038835  \n",
      "1   2.580233           0.194329          0.148061          0.039129  \n",
      "12  3.419560           0.198647          0.151097          0.040303  \n",
      "14  3.249000           0.198704          0.135960          0.042955  \n",
      "7   3.127339           0.209842          0.154850          0.046836  \n",
      "6   3.145008           0.217088          0.156479          0.048977  \n",
      "13  3.082798           0.218833          0.164588          0.049610  \n",
      "3   3.314690           0.265063          0.181582          0.075239  \n",
      "15  1.979754           0.365444          0.289269          0.138991  \n",
      "2   2.873323           0.366962          0.296013          0.136689  \n",
      "0   3.736325           0.587131          0.464057          0.370518  \n",
      "Predictions for the next 12 periods (122-133) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[11.37794778 11.45175356 11.47581532 11.74907862 11.75437159 11.99002216\n",
      " 12.00912162 11.61222435 11.48175649 11.5861939  11.5885814  11.8194821 ]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.79105505 -0.78037218 -0.7768894  -0.73733643 -0.73657031 -0.70246153\n",
      " -0.69969701 -0.75714514 -0.77602946 -0.76091287 -0.76056729 -0.72714602]\n",
      "This is the 23th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.242911  3.615899  1.901552 -0.805198   \n",
      "5   Gradient Boosting Regressor  1.083274  2.781895  1.667901 -0.388831   \n",
      "11                     LightGBM  1.271680  3.679999  1.918332 -0.837199   \n",
      "14                     boosting  1.200973  3.344940  1.828918 -0.669925   \n",
      "10               XGBRFRegressor  1.152179  3.102316  1.761339 -0.548798   \n",
      "9                  XGBRegressor  1.171037  3.280655  1.811258 -0.637831   \n",
      "4       Random Forest Regressor  1.215383  3.345925  1.829187 -0.670417   \n",
      "12                          SVM  1.344450  3.714727  1.927363 -0.854537   \n",
      "7              BaggingRegressor  1.175777  3.103443  1.761659 -0.549360   \n",
      "1              Ridge Regression  1.129175  2.367838  1.538778 -0.182117   \n",
      "6            Adaboost Regressor  1.234625  3.320653  1.822266 -0.657800   \n",
      "13                      bagging  1.226479  3.300095  1.816616 -0.647537   \n",
      "3       Decision Tree Regressor  1.253030  3.597467  1.896699 -0.795996   \n",
      "15                     stacking  1.045195  2.168910  1.472722 -0.082805   \n",
      "2              Lasso Regression  1.207220  3.002768  1.732850 -0.499099   \n",
      "0             Linear Regression  1.482027  6.749424  2.597965 -2.369577   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   3.256498           0.113926          0.087696          0.013646  \n",
      "5   2.736038           0.173559          0.131754          0.031436  \n",
      "11  3.296499           0.180202          0.141130          0.033875  \n",
      "14  3.087406           0.189030          0.132896          0.038707  \n",
      "10  2.935997           0.190596          0.136462          0.038084  \n",
      "9   3.047289           0.193615          0.142176          0.040003  \n",
      "4   3.088021           0.196080          0.141693          0.040283  \n",
      "12  3.318171           0.204976          0.155760          0.043130  \n",
      "7   2.936700           0.205770          0.148334          0.043466  \n",
      "1   2.477647           0.209853          0.160129          0.046388  \n",
      "6   3.072250           0.212962          0.160282          0.048103  \n",
      "13  3.059421           0.215878          0.161811          0.047947  \n",
      "3   3.244996           0.261799          0.187520          0.074018  \n",
      "15  2.353506           0.359674          0.287598          0.135039  \n",
      "2   2.873874           0.364867          0.293319          0.135423  \n",
      "0   5.211971           0.603766          0.478799          0.392294  \n",
      "Predictions for the next 12 periods (123-134) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[11.61213631 11.58633647 11.84496932 11.9601788  12.22346414 12.23708235\n",
      " 11.83229457 11.71688554 11.8292205  11.6980497  11.80723754 11.80375532]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.75715788 -0.76089223 -0.72345692 -0.70678114 -0.66867242 -0.66670127\n",
      " -0.7252915  -0.74199616 -0.72573645 -0.74472252 -0.72891833 -0.72942236]\n",
      "This is the 24th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.188665  3.406744  1.845737 -0.700780   \n",
      "5   Gradient Boosting Regressor  1.065676  2.751187  1.658670 -0.373500   \n",
      "11                     LightGBM  1.255139  3.611395  1.900367 -0.802949   \n",
      "10               XGBRFRegressor  1.148919  3.135521  1.770740 -0.565375   \n",
      "14                     boosting  1.231848  3.553421  1.885052 -0.774007   \n",
      "7              BaggingRegressor  1.199052  3.278410  1.810638 -0.636710   \n",
      "9                  XGBRegressor  1.103074  2.953553  1.718590 -0.474529   \n",
      "4       Random Forest Regressor  1.178144  3.201514  1.789278 -0.598321   \n",
      "12                          SVM  1.302202  3.536185  1.880475 -0.765402   \n",
      "6            Adaboost Regressor  1.173814  3.080180  1.755044 -0.537747   \n",
      "1              Ridge Regression  1.122510  2.359526  1.536075 -0.177968   \n",
      "13                      bagging  1.192965  3.178616  1.782867 -0.586890   \n",
      "3       Decision Tree Regressor  1.260222  3.635089  1.906591 -0.814779   \n",
      "2              Lasso Regression  1.207126  3.001895  1.732598 -0.498663   \n",
      "15                     stacking  0.914543  1.712236  1.308524  0.145185   \n",
      "0             Linear Regression  1.326545  5.422564  2.328640 -1.707156   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   3.125975           0.112315          0.089434          0.013308  \n",
      "5   2.716875           0.167117          0.120553          0.029376  \n",
      "11  3.253687           0.176251          0.138789          0.032184  \n",
      "10  2.956719           0.185346          0.136082          0.036421  \n",
      "14  3.217508           0.187585          0.133091          0.038647  \n",
      "7   3.045888           0.192653          0.148638          0.039640  \n",
      "9   2.843161           0.193785          0.142435          0.041223  \n",
      "4   2.997901           0.193811          0.143765          0.039843  \n",
      "12  3.206752           0.209549          0.159159          0.045277  \n",
      "6   2.922183           0.210773          0.155833          0.046699  \n",
      "1   2.472460           0.217296          0.167122          0.049096  \n",
      "13  2.983612           0.219523          0.170293          0.051533  \n",
      "3   3.268473           0.278239          0.195853          0.083231  \n",
      "2   2.873329           0.359894          0.291113          0.133741  \n",
      "15  2.068519           0.367112          0.295386          0.138594  \n",
      "0   4.383945           0.570277          0.455655          0.353615  \n",
      "Predictions for the next 12 periods (124-135) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.16868736 12.86842289 13.03503798 13.02503086 13.39730233 12.83418385\n",
      " 12.64613825 12.51371733 12.52129588 12.49813587 12.63557217 12.50178451]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.5318579  -0.57531911 -0.55120273 -0.55265119 -0.49876747 -0.58027497\n",
      " -0.60749327 -0.62666028 -0.62556334 -0.62891559 -0.60902263 -0.62838747]\n",
      "This is the 25th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.163482  3.311266  1.819689 -0.653114   \n",
      "9                  XGBRegressor  1.011328  2.496097  1.579904 -0.246149   \n",
      "5   Gradient Boosting Regressor  1.062649  2.729252  1.652045 -0.362549   \n",
      "10               XGBRFRegressor  1.145223  3.125248  1.767837 -0.560246   \n",
      "11                     LightGBM  1.205314  3.351988  1.830843 -0.673443   \n",
      "14                     boosting  1.184367  3.302296  1.817222 -0.648635   \n",
      "4       Random Forest Regressor  1.191803  3.281273  1.811429 -0.638140   \n",
      "7              BaggingRegressor  1.233412  3.438915  1.854431 -0.716841   \n",
      "12                          SVM  1.222204  3.218234  1.793944 -0.606668   \n",
      "1              Ridge Regression  1.125467  2.409649  1.552304 -0.202991   \n",
      "13                      bagging  1.191987  3.189383  1.785884 -0.592264   \n",
      "6            Adaboost Regressor  1.210266  3.257447  1.804840 -0.626245   \n",
      "3       Decision Tree Regressor  1.286986  3.847205  1.961429 -0.920675   \n",
      "2              Lasso Regression  1.207069  3.001366  1.732445 -0.498399   \n",
      "15                     stacking  0.922377  1.723932  1.312986  0.139346   \n",
      "0             Linear Regression  0.956719  2.806857  1.675368 -0.401293   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   3.066392           0.103181          0.084886          0.011414  \n",
      "9   2.557687           0.170127          0.120199          0.031821  \n",
      "5   2.703187           0.174559          0.127587          0.032584  \n",
      "10  2.950308           0.186081          0.136978          0.036977  \n",
      "11  3.091804           0.186555          0.145780          0.036803  \n",
      "14  3.060794           0.189822          0.130558          0.041051  \n",
      "4   3.047675           0.190221          0.137918          0.038742  \n",
      "7   3.146051           0.200968          0.148766          0.043472  \n",
      "12  3.008335           0.202615          0.156239          0.042545  \n",
      "1   2.503739           0.208459          0.165010          0.045314  \n",
      "13  2.990331           0.210727          0.164296          0.047571  \n",
      "6   3.032806           0.217160          0.160921          0.049747  \n",
      "3   3.400844           0.277309          0.197476          0.081297  \n",
      "2   2.872999           0.353927          0.286765          0.130221  \n",
      "15  2.075818           0.356836          0.287337          0.132956  \n",
      "0   2.751616           0.535340          0.429634          0.303103  \n",
      "Predictions for the next 12 periods (125-136) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.81713071 13.60861361 13.54710132 13.58884154 13.29742845 13.25879816\n",
      " 13.05917452 13.07847124 13.16412746 13.36850466 13.35826428 13.19292475]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.43800022 -0.46818163 -0.47708511 -0.4710435  -0.51322352 -0.51881499\n",
      " -0.54770913 -0.54491606 -0.53251792 -0.50293574 -0.50441796 -0.52834971]\n",
      "This is the 26th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.079641  2.876087  1.695903 -0.435855   \n",
      "5   Gradient Boosting Regressor  1.084855  2.897609  1.702236 -0.446600   \n",
      "9                  XGBRegressor  1.003372  2.516183  1.586248 -0.256177   \n",
      "14                     boosting  1.100457  2.977625  1.725580 -0.486547   \n",
      "10               XGBRFRegressor  1.111784  2.987205  1.728353 -0.491329   \n",
      "11                     LightGBM  1.206060  3.413843  1.847659 -0.704324   \n",
      "4       Random Forest Regressor  1.142182  3.067198  1.751342 -0.531265   \n",
      "7              BaggingRegressor  1.125210  2.926972  1.710839 -0.461259   \n",
      "12                          SVM  1.197524  3.105908  1.762359 -0.550591   \n",
      "1              Ridge Regression  1.135410  2.530181  1.590654 -0.263165   \n",
      "13                      bagging  1.179471  3.101715  1.761169 -0.548497   \n",
      "6            Adaboost Regressor  1.198622  3.221189  1.794767 -0.608144   \n",
      "3       Decision Tree Regressor  1.216078  3.617776  1.902045 -0.806135   \n",
      "2              Lasso Regression  1.206571  2.996759  1.731115 -0.496099   \n",
      "15                     stacking  0.972363  1.896177  1.377017  0.053354   \n",
      "0             Linear Regression  1.002963  3.105927  1.762364 -0.550600   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   2.794819           0.109642          0.087950          0.013164  \n",
      "5   2.808250           0.173107          0.135818          0.033181  \n",
      "9   2.570221           0.177450          0.130657          0.034785  \n",
      "14  2.858184           0.182646          0.132673          0.041504  \n",
      "10  2.864162           0.184017          0.140088          0.037297  \n",
      "11  3.130405           0.189878          0.149700          0.038896  \n",
      "4   2.914082           0.191286          0.142997          0.040033  \n",
      "7   2.826573           0.201856          0.157132          0.044533  \n",
      "12  2.938238           0.205601          0.157114          0.043392  \n",
      "1   2.578956           0.214460          0.169816          0.047833  \n",
      "13  2.935621           0.218118          0.168264          0.052071  \n",
      "6   3.010179           0.219350          0.169554          0.052792  \n",
      "3   3.257669           0.262181          0.180526          0.073241  \n",
      "2   2.870124           0.354233          0.287317          0.130163  \n",
      "15  2.183307           0.362065          0.294960          0.135891  \n",
      "0   2.938250           0.486309          0.388571          0.256357  \n",
      "Predictions for the next 12 periods (126-137) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[13.79047532 13.59270591 13.73155    13.4304379  13.40622632 13.15797387\n",
      " 13.25313699 13.26803657 13.54785741 13.56859018 13.46777952 13.22498537]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.44185841 -0.47048416 -0.45038744 -0.49397133 -0.49747579 -0.53340861\n",
      " -0.51963441 -0.51747779 -0.47697567 -0.47397474 -0.48856639 -0.52370916]\n",
      "This is the 27th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  1.027285  2.639717  1.624721 -0.317850   \n",
      "9                  XGBRegressor  1.081455  2.967231  1.722565 -0.481358   \n",
      "5   Gradient Boosting Regressor  1.070293  2.829231  1.682032 -0.412463   \n",
      "10               XGBRFRegressor  1.070339  2.814226  1.677566 -0.404972   \n",
      "11                     LightGBM  1.160386  3.222971  1.795263 -0.609033   \n",
      "14                     boosting  1.060541  2.781698  1.667842 -0.388732   \n",
      "4       Random Forest Regressor  1.082563  2.792496  1.671076 -0.394123   \n",
      "12                          SVM  1.120719  2.800253  1.673396 -0.397996   \n",
      "1              Ridge Regression  1.169408  2.792292  1.671015 -0.394021   \n",
      "6            Adaboost Regressor  1.114657  2.816445  1.678227 -0.406079   \n",
      "7              BaggingRegressor  1.131870  2.927465  1.710984 -0.461505   \n",
      "13                      bagging  1.125396  2.890663  1.700195 -0.443132   \n",
      "3       Decision Tree Regressor  0.919299  2.074349  1.440260 -0.035596   \n",
      "15                     stacking  1.059325  2.251982  1.500660 -0.124277   \n",
      "2              Lasso Regression  1.205648  2.988238  1.728652 -0.491845   \n",
      "0             Linear Regression  1.140046  4.173186  2.042838 -1.083417   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   2.647313           0.114749          0.092471          0.014044  \n",
      "9   2.851697           0.185889          0.136206          0.036627  \n",
      "5   2.765578           0.187264          0.144651          0.038465  \n",
      "10  2.756215           0.196592          0.147595          0.041169  \n",
      "11  3.011291           0.207747          0.160050          0.045398  \n",
      "14  2.735916           0.208494          0.145557          0.049111  \n",
      "4   2.742654           0.208979          0.155508          0.046720  \n",
      "12  2.747495           0.212317          0.161202          0.046073  \n",
      "1   2.742526           0.219765          0.177365          0.051047  \n",
      "6   2.757599           0.228146          0.173007          0.055864  \n",
      "7   2.826881           0.228150          0.171543          0.056244  \n",
      "13  2.803915           0.233131          0.178786          0.058177  \n",
      "3   2.294495           0.293461          0.215572          0.095710  \n",
      "15  2.405347           0.345666          0.282773          0.126268  \n",
      "2   2.864807           0.355998          0.289717          0.131567  \n",
      "0   3.604272           0.498890          0.412498          0.299029  \n",
      "Predictions for the next 12 periods (127-138) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[15.67434646 15.43364585 15.21699411 15.19720739 15.20507527 15.16532041\n",
      " 14.90234492 14.73949618 14.76629842 14.58422959 14.55109778 14.15464014]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.16918111 -0.20402086 -0.2353797  -0.23824369 -0.23710487 -0.24285911\n",
      " -0.28092299 -0.30449421 -0.30061477 -0.32696798 -0.33176358 -0.38914807]\n",
      "This is the 28th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.901563  2.115574  1.454501 -0.056177   \n",
      "5   Gradient Boosting Regressor  0.875494  1.932596  1.390178  0.035173   \n",
      "9                  XGBRegressor  1.007458  2.680325  1.637170 -0.338123   \n",
      "10               XGBRFRegressor  1.029705  2.648272  1.627351 -0.322121   \n",
      "4       Random Forest Regressor  0.944189  2.182717  1.477402 -0.089698   \n",
      "11                     LightGBM  1.058039  2.748919  1.657986 -0.372368   \n",
      "12                          SVM  1.068192  2.590622  1.609541 -0.293340   \n",
      "14                     boosting  0.956884  2.352891  1.533914 -0.174655   \n",
      "1              Ridge Regression  1.244424  3.390146  1.841235 -0.692494   \n",
      "7              BaggingRegressor  1.045712  2.565408  1.601689 -0.280752   \n",
      "6            Adaboost Regressor  1.005547  2.353511  1.534116 -0.174965   \n",
      "13                      bagging  1.053243  2.557620  1.599256 -0.276864   \n",
      "3       Decision Tree Regressor  0.838810  1.837965  1.355715  0.082416   \n",
      "15                     stacking  1.088463  2.386341  1.544779 -0.191355   \n",
      "2              Lasso Regression  1.203527  2.968819  1.723026 -0.482151   \n",
      "0             Linear Regression  1.158029  4.336154  2.082343 -1.164778   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   2.320221           0.120110          0.090171          0.016778  \n",
      "5   2.206034           0.186749          0.143597          0.037651  \n",
      "9   2.672654           0.193874          0.141698          0.040817  \n",
      "10  2.652651           0.197381          0.148230          0.041613  \n",
      "4   2.362122           0.213440          0.158073          0.049138  \n",
      "11  2.715460           0.214612          0.160204          0.050879  \n",
      "12  2.616674           0.215102          0.162057          0.048114  \n",
      "14  2.468319           0.220344          0.146148          0.053359  \n",
      "1   3.115617           0.224063          0.182808          0.052761  \n",
      "7   2.600940           0.236031          0.177517          0.063594  \n",
      "6   2.468706           0.236064          0.180525          0.059922  \n",
      "13  2.596080           0.247649          0.190343          0.065372  \n",
      "3   2.146980           0.258901          0.175144          0.070776  \n",
      "15  2.489194           0.358631          0.292396          0.134795  \n",
      "2   2.852688           0.371295          0.299847          0.143208  \n",
      "0   3.705972           0.434419          0.348201          0.202479  \n",
      "Predictions for the next 12 periods (128-139) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[16.83347042 16.64589664 16.67264464 16.77768859 16.85998421 16.60089418\n",
      " 16.4761745  16.24321309 15.90448541 14.93441841 14.58283151 14.30871623]\n",
      "Predictions for the next 12 periods:\n",
      "[-0.00140595 -0.02855596 -0.02468437 -0.00947998  0.00243174 -0.03506975\n",
      " -0.05312206 -0.08684161 -0.13587009 -0.27628057 -0.32717034 -0.36684663]\n",
      "This is the 29th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.664581  1.181343  1.086896  0.410227   \n",
      "5   Gradient Boosting Regressor  0.667460  1.121221  1.058877  0.440242   \n",
      "9                  XGBRegressor  0.958467  2.609549  1.615410 -0.302789   \n",
      "10               XGBRFRegressor  0.957611  2.444040  1.563343 -0.220160   \n",
      "14                     boosting  0.485442  0.598417  0.773574  0.701247   \n",
      "12                          SVM  1.008495  2.345677  1.531560 -0.171054   \n",
      "11                     LightGBM  0.892706  1.931375  1.389739  0.035782   \n",
      "4       Random Forest Regressor  0.770527  1.382683  1.175876  0.309710   \n",
      "1              Ridge Regression  1.372216  4.378288  2.092436 -1.185812   \n",
      "7              BaggingRegressor  0.800808  1.479599  1.216388  0.261326   \n",
      "6            Adaboost Regressor  0.784273  1.373370  1.171909  0.314360   \n",
      "13                      bagging  0.920737  1.918986  1.385275  0.041967   \n",
      "3       Decision Tree Regressor  0.551058  0.777978  0.882031  0.611603   \n",
      "2              Lasso Regression  1.201005  2.936949  1.713753 -0.466240   \n",
      "15                     stacking  1.243546  3.091173  1.758173 -0.543234   \n",
      "0             Linear Regression  1.258472  5.074614  2.252690 -1.533446   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.737216           0.129486          0.096471          0.019653  \n",
      "5   1.699697           0.205083          0.151679          0.047386  \n",
      "9   2.628486           0.213621          0.157213          0.050889  \n",
      "10  2.525201           0.222126          0.164663          0.054112  \n",
      "14  1.373442           0.224645          0.156897          0.059030  \n",
      "12  2.463817           0.232340          0.168659          0.058448  \n",
      "11  2.205273           0.234523          0.167564          0.065241  \n",
      "4   1.862862           0.234527          0.173561          0.063502  \n",
      "1   3.732266           0.240232          0.193150          0.059748  \n",
      "7   1.923342           0.241535          0.174148          0.071140  \n",
      "6   1.857050           0.255755          0.193016          0.071257  \n",
      "13  2.197541           0.266306          0.201279          0.079942  \n",
      "3   1.485497           0.301617          0.210055          0.101340  \n",
      "2   2.832800           0.407013          0.318871          0.175645  \n",
      "15  2.929043           0.409111          0.325300          0.179896  \n",
      "0   4.166807           0.435535          0.343900          0.216646  \n",
      "Predictions for the next 12 periods (129-140) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[21.47582101 21.09343338 21.30176212 21.25384447 21.00544866 20.70148862\n",
      " 19.17596219 18.42715255 16.48007221 15.96094918 15.84825534 15.24973103]\n",
      "Predictions for the next 12 periods:\n",
      "[ 0.67054213  0.61519417  0.64534831  0.63841256  0.60245899  0.55846288\n",
      "  0.3376535   0.2292685  -0.05255789 -0.12769735 -0.14400901 -0.23064125]\n",
      "This is the 30th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.327570  0.359263  0.599386  0.820642   \n",
      "5   Gradient Boosting Regressor  0.376743  0.435204  0.659700  0.782729   \n",
      "9                  XGBRegressor  0.942641  2.609928  1.615527 -0.302978   \n",
      "14                     boosting  0.398315  0.498101  0.705763  0.751328   \n",
      "10               XGBRFRegressor  0.902449  2.239929  1.496639 -0.118260   \n",
      "1              Ridge Regression  1.632119  6.494121  2.548357 -2.242119   \n",
      "4       Random Forest Regressor  0.391652  0.397947  0.630830  0.801329   \n",
      "7              BaggingRegressor  0.652841  0.964396  0.982037  0.518536   \n",
      "12                          SVM  0.880600  1.850147  1.360201  0.076334   \n",
      "11                     LightGBM  0.698724  1.145091  1.070089  0.428326   \n",
      "6            Adaboost Regressor  0.489264  0.526326  0.725483  0.737238   \n",
      "13                      bagging  0.617213  0.765070  0.874683  0.618047   \n",
      "3       Decision Tree Regressor  0.473412  0.718639  0.847726  0.641227   \n",
      "0             Linear Regression  1.604418  7.747563  2.783445 -2.867887   \n",
      "15                     stacking  0.908360  1.642805  1.281719  0.179848   \n",
      "2              Lasso Regression  1.200798  2.882698  1.697851 -0.439155   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.224198           0.149939          0.102175          0.035230  \n",
      "5   1.271588           0.223001          0.152464          0.063046  \n",
      "9   2.628723           0.233987          0.151433          0.069295  \n",
      "14  1.310839           0.248302          0.158143          0.070248  \n",
      "10  2.397825           0.252886          0.173433          0.075992  \n",
      "1   5.052649           0.256730          0.199246          0.072333  \n",
      "4   1.248338           0.257330          0.174325          0.084829  \n",
      "7   1.601830           0.271416          0.193575          0.088965  \n",
      "12  2.154582           0.281403          0.187873          0.108221  \n",
      "11  1.714593           0.287914          0.196330          0.117933  \n",
      "6   1.328453           0.301412          0.226272          0.101376  \n",
      "13  1.477441           0.308602          0.215664          0.121700  \n",
      "3   1.448466           0.379259          0.235546          0.183439  \n",
      "0   5.834858           0.436318          0.359010          0.205757  \n",
      "15  2.025190           0.439996          0.327960          0.248392  \n",
      "2   2.798944           0.473046          0.349823          0.272827  \n",
      "Predictions for the next 12 periods (130-141) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[25.89964417 25.67932301 24.87385927 24.65441554 24.28163711 23.88860055\n",
      " 22.96750036 22.58294712 22.21365204 22.35412267 22.40104224 21.53987643]\n",
      "Predictions for the next 12 periods:\n",
      "[1.31085988 1.27896992 1.16238462 1.13062166 1.07666457 1.01977525\n",
      " 0.88645238 0.83079096 0.77733806 0.79767021 0.80446149 0.67981371]\n",
      "This is the 31th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.326025  0.381434  0.617603  0.809573   \n",
      "5   Gradient Boosting Regressor  0.338222  0.349865  0.591493  0.825334   \n",
      "4       Random Forest Regressor  0.380252  0.418948  0.647262  0.790845   \n",
      "1              Ridge Regression  1.592377  6.183099  2.486584 -2.086845   \n",
      "14                     boosting  0.246428  0.259190  0.509107  0.870602   \n",
      "9                  XGBRegressor  0.836595  2.243032  1.497676 -0.119809   \n",
      "7              BaggingRegressor  0.344197  0.408276  0.638965  0.796173   \n",
      "12                          SVM  0.789908  1.507824  1.227935  0.247235   \n",
      "6            Adaboost Regressor  0.433673  0.377384  0.614316  0.811595   \n",
      "10               XGBRFRegressor  0.861326  2.094343  1.447184 -0.045578   \n",
      "11                     LightGBM  0.589847  0.801724  0.895390  0.599748   \n",
      "13                      bagging  0.518179  0.555324  0.745200  0.722761   \n",
      "3       Decision Tree Regressor  0.346612  0.436236  0.660481  0.782214   \n",
      "0             Linear Regression  1.542222  7.243203  2.691320 -2.616090   \n",
      "15                     stacking  0.637697  0.757620  0.870414  0.621766   \n",
      "2              Lasso Regression  1.201294  2.835895  1.684011 -0.415789   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.238033           0.130953          0.097432          0.020792  \n",
      "5   1.218333           0.216334          0.153971          0.055083  \n",
      "4   1.261444           0.233704          0.165768          0.062168  \n",
      "1   4.858556           0.242603          0.193799          0.064268  \n",
      "14  1.161747           0.256909          0.174061          0.079441  \n",
      "9   2.399762           0.266155          0.169748          0.100199  \n",
      "7   1.254784           0.279974          0.199732          0.093902  \n",
      "12  1.940956           0.286396          0.191622          0.105085  \n",
      "6   1.235506           0.286461          0.217594          0.093667  \n",
      "10  2.306972           0.286964          0.195690          0.107219  \n",
      "11  1.500315           0.293443          0.206826          0.110361  \n",
      "13  1.346549           0.306090          0.215208          0.111192  \n",
      "3   1.272232           0.336153          0.230653          0.147255  \n",
      "0   5.520113           0.400349          0.318643          0.187572  \n",
      "15  1.472792           0.448634          0.321526          0.252073  \n",
      "2   2.769737           0.526114          0.377088          0.343907  \n",
      "Predictions for the next 12 periods (131-142) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[33.95581356 32.84430181 31.90647615 31.13149138 31.08761108 30.38513653\n",
      " 29.24260679 27.91303213 27.76845394 28.92568671 29.03567009 27.18922361]\n",
      "Predictions for the next 12 periods:\n",
      "[2.47693458 2.31605095 2.18030719 2.06813351 2.06178214 1.96010382\n",
      " 1.79473055 1.60228384 1.58135714 1.74885857 1.7647779  1.49751757]\n",
      "This is the 32th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.348963  0.433533  0.658433  0.783563   \n",
      "5   Gradient Boosting Regressor  0.329839  0.354103  0.595065  0.823218   \n",
      "14                     boosting  0.286991  0.279683  0.528850  0.860371   \n",
      "9                  XGBRegressor  0.833797  2.235472  1.495149 -0.116035   \n",
      "10               XGBRFRegressor  0.743404  1.528286  1.236239  0.237020   \n",
      "4       Random Forest Regressor  0.340253  0.357735  0.598109  0.821405   \n",
      "1              Ridge Regression  1.395041  4.735010  2.176008 -1.363902   \n",
      "7              BaggingRegressor  0.458169  0.577729  0.760085  0.711575   \n",
      "12                          SVM  0.693540  1.186935  1.089465  0.407436   \n",
      "6            Adaboost Regressor  0.301047  0.199386  0.446527  0.900459   \n",
      "11                     LightGBM  0.526842  0.647233  0.804508  0.676876   \n",
      "13                      bagging  0.460873  0.459149  0.677605  0.770775   \n",
      "3       Decision Tree Regressor  0.438239  1.000768  1.000384  0.500378   \n",
      "0             Linear Regression  1.337748  5.685508  2.384430 -1.838428   \n",
      "15                     stacking  0.537315  0.545181  0.738364  0.727824   \n",
      "2              Lasso Regression  1.201741  2.794812  1.671769 -0.395279   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.270546           0.128729          0.094210          0.023193  \n",
      "5   1.220977           0.189975          0.140645          0.039998  \n",
      "14  1.174536           0.218171          0.149343          0.051963  \n",
      "9   2.395044           0.228795          0.154494          0.065257  \n",
      "10  1.953725           0.235146          0.172623          0.065752  \n",
      "4   1.223244           0.244264          0.177713          0.075270  \n",
      "1   3.954877           0.257283          0.201332          0.074309  \n",
      "7   1.360531           0.258500          0.200081          0.074258  \n",
      "12  1.740705           0.274866          0.191894          0.094363  \n",
      "6   1.124427           0.301164          0.227244          0.116228  \n",
      "11  1.403905           0.304718          0.217316          0.110392  \n",
      "13  1.286531           0.312428          0.226213          0.121730  \n",
      "3   1.624528           0.323372          0.214341          0.126272  \n",
      "0   4.548035           0.357954          0.276162          0.134169  \n",
      "15  1.340220           0.432015          0.313546          0.263930  \n",
      "2   2.744099           0.567855          0.402971          0.404628  \n",
      "Predictions for the next 12 periods (132-143) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[32.48948108 31.40699264 30.41181761 30.06464079 28.78389112 27.98809086\n",
      " 26.83684357 25.169104   26.03388213 26.45117103 24.72072859 22.76018403]\n",
      "Predictions for the next 12 periods:\n",
      "[2.26469311 2.10801041 1.96396572 1.91371428 1.72833464 1.61314807\n",
      " 1.446513   1.20511925 1.33028989 1.39068957 1.14022002 0.85644478]\n",
      "This is the 33th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.326716  0.374750  0.612169  0.812910   \n",
      "5   Gradient Boosting Regressor  0.278091  0.333684  0.577654  0.833412   \n",
      "4       Random Forest Regressor  0.322063  0.322548  0.567933  0.838972   \n",
      "14                     boosting  0.261968  0.315963  0.562106  0.842259   \n",
      "7              BaggingRegressor  0.384869  0.464690  0.681682  0.768009   \n",
      "1              Ridge Regression  1.214728  3.604596  1.898577 -0.799555   \n",
      "12                          SVM  0.588412  0.907297  0.952522  0.547042   \n",
      "3       Decision Tree Regressor  0.342376  0.633166  0.795717  0.683899   \n",
      "6            Adaboost Regressor  0.407677  0.574401  0.757892  0.713237   \n",
      "10               XGBRFRegressor  0.390222  0.455589  0.674973  0.772552   \n",
      "13                      bagging  0.423747  0.421434  0.649180  0.789603   \n",
      "11                     LightGBM  0.469757  0.531838  0.729272  0.734486   \n",
      "9                  XGBRegressor  0.332698  0.581769  0.762738  0.709558   \n",
      "15                     stacking  0.348299  0.279578  0.528751  0.860424   \n",
      "0             Linear Regression  0.835132  2.562620  1.600819 -0.279360   \n",
      "2              Lasso Regression  1.202232  2.750912  1.658587 -0.373363   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.233863           0.139665          0.101317          0.022630  \n",
      "5   1.208235           0.213081          0.150839          0.050459  \n",
      "4   1.201285           0.225516          0.167718          0.058341  \n",
      "14  1.197176           0.237700          0.161486          0.066258  \n",
      "7   1.289989           0.252390          0.187736          0.073605  \n",
      "1   3.249444           0.259805          0.203128          0.072210  \n",
      "12  1.566198           0.265008          0.190712          0.078388  \n",
      "3   1.395126           0.271261          0.198956          0.080620  \n",
      "6   1.358454           0.275197          0.218815          0.081110  \n",
      "10  1.284310           0.283177          0.189557          0.107279  \n",
      "13  1.262996           0.290227          0.210540          0.096132  \n",
      "11  1.331893           0.303346          0.226109          0.099246  \n",
      "9   1.363052           0.315714          0.185835          0.137607  \n",
      "15  1.174470           0.317403          0.251670          0.115320  \n",
      "0   2.599200           0.368511          0.298258          0.139910  \n",
      "2   2.716703           0.632015          0.429435          0.469500  \n",
      "Predictions for the next 12 periods (133-144) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[31.92446881 30.7496811  31.46260067 30.25179365 28.66836605 27.28115551\n",
      " 26.66835308 26.21778763 26.05708234 24.74324238 24.12895459 22.72866414]\n",
      "Predictions for the next 12 periods:\n",
      "[2.1829115  2.01286912 2.11605929 1.94080336 1.71161319 1.51082407\n",
      " 1.42212517 1.35690894 1.33364796 1.14347873 1.05456483 0.85188249]\n",
      "This is the 34th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.289306  0.344691  0.587104  0.827917   \n",
      "5   Gradient Boosting Regressor  0.288983  0.316841  0.562886  0.841821   \n",
      "14                     boosting  0.290402  0.350948  0.592409  0.824793   \n",
      "4       Random Forest Regressor  0.329841  0.413749  0.643233  0.793440   \n",
      "10               XGBRFRegressor  0.377385  0.616300  0.785048  0.692319   \n",
      "12                          SVM  0.510425  0.731896  0.855509  0.634609   \n",
      "9                  XGBRegressor  0.350478  0.690130  0.830740  0.655460   \n",
      "13                      bagging  0.374876  0.431681  0.657025  0.784488   \n",
      "1              Ridge Regression  0.972289  2.310372  1.519991 -0.153428   \n",
      "7              BaggingRegressor  0.309922  0.264716  0.514506  0.867843   \n",
      "6            Adaboost Regressor  0.313596  0.298981  0.546791  0.850737   \n",
      "3       Decision Tree Regressor  0.311983  0.426756  0.653266  0.786947   \n",
      "11                     LightGBM  0.408289  0.439566  0.662998  0.780551   \n",
      "15                     stacking  0.442585  0.540240  0.735011  0.730291   \n",
      "0             Linear Regression  0.452219  0.765910  0.875163  0.617628   \n",
      "2              Lasso Regression  1.202744  2.706391  1.645111 -0.351136   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.215104           0.138418          0.100909          0.021246  \n",
      "5   1.197724           0.200857          0.145569          0.042889  \n",
      "14  1.219009           0.236140          0.164778          0.066125  \n",
      "4   1.258199           0.239293          0.179195          0.062259  \n",
      "10  1.384601           0.256504          0.178330          0.074205  \n",
      "12  1.456739           0.260294          0.189075          0.073818  \n",
      "9   1.430675           0.273415          0.176485          0.093857  \n",
      "13  1.269390           0.279931          0.206166          0.085145  \n",
      "1   2.441785           0.285507          0.219122          0.085644  \n",
      "7   1.165196           0.293154          0.206686          0.099588  \n",
      "6   1.186579           0.295749          0.223875          0.092759  \n",
      "3   1.266317           0.309450          0.212405          0.117000  \n",
      "11  1.274311           0.318226          0.252127          0.111645  \n",
      "15  1.337136           0.390436          0.291001          0.165848  \n",
      "0   1.477965           0.413786          0.325312          0.182423  \n",
      "2   2.688920           0.691054          0.461211          0.556096  \n",
      "Predictions for the next 12 periods (134-145) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[32.48075664 32.20182458 30.80620362 29.7533218  28.09872774 27.74742409\n",
      " 26.86307533 28.06262637 26.10682887 24.94615918 23.33901045 22.12139094]\n",
      "Predictions for the next 12 periods:\n",
      "[2.26343031 2.22305682 2.02105036 1.86865301 1.62916199 1.57831322\n",
      " 1.45030986 1.62393657 1.34084843 1.17284953 0.94022589 0.7639839 ]\n",
      "This is the 35th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.242957  0.237325  0.487160  0.881518   \n",
      "5   Gradient Boosting Regressor  0.287192  0.304430  0.551751  0.848017   \n",
      "4       Random Forest Regressor  0.329482  0.402831  0.634689  0.798891   \n",
      "14                     boosting  0.250233  0.297582  0.545510  0.851436   \n",
      "12                          SVM  0.471224  0.638986  0.799366  0.680993   \n",
      "9                  XGBRegressor  0.310880  0.556895  0.746254  0.721976   \n",
      "7              BaggingRegressor  0.352049  0.454005  0.673799  0.773343   \n",
      "10               XGBRFRegressor  0.351808  0.493709  0.702644  0.753521   \n",
      "13                      bagging  0.400754  0.518256  0.719900  0.741266   \n",
      "1              Ridge Regression  0.672293  1.078265  1.038396  0.461688   \n",
      "6            Adaboost Regressor  0.358299  0.375469  0.612755  0.812551   \n",
      "3       Decision Tree Regressor  0.292098  0.372595  0.610405  0.813986   \n",
      "11                     LightGBM  0.368191  0.433624  0.658501  0.783518   \n",
      "0             Linear Regression  0.426056  0.694819  0.833558  0.653119   \n",
      "15                     stacking  0.442675  0.486357  0.697393  0.757191   \n",
      "2              Lasso Regression  1.203218  2.666485  1.632938 -0.331214   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.148102           0.135196          0.098252          0.020871  \n",
      "5   1.189979           0.201723          0.143850          0.043890  \n",
      "4   1.251386           0.221368          0.159366          0.052186  \n",
      "14  1.185705           0.238312          0.159544          0.069095  \n",
      "12  1.398759           0.245205          0.179601          0.064355  \n",
      "9   1.347530           0.261225          0.169385          0.093777  \n",
      "7   1.283322           0.261542          0.188823          0.076908  \n",
      "10  1.308099           0.263708          0.177434          0.080146  \n",
      "13  1.323417           0.279810          0.206406          0.085162  \n",
      "1   1.672890           0.286862          0.218053          0.089759  \n",
      "6   1.234311           0.291171          0.219270          0.091331  \n",
      "3   1.232517           0.300457          0.214503          0.096564  \n",
      "11  1.270602           0.305947          0.237466          0.095938  \n",
      "0   1.433601           0.324768          0.261816          0.108770  \n",
      "15  1.303511           0.380694          0.258051          0.173838  \n",
      "2   2.664017           0.753103          0.484704          0.614512  \n",
      "Predictions for the next 12 periods (135-146) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[33.22700931 31.99855853 31.18718269 28.73061334 28.08248062 27.05655001\n",
      " 26.64334134 25.68899955 24.40115217 23.23219279 22.76108618 21.92455497]\n",
      "Predictions for the next 12 periods:\n",
      "[2.37144521 2.19363547 2.07619444 1.72062305 1.62681033 1.47831398\n",
      " 1.41850489 1.28037053 1.09396354 0.92476478 0.85657536 0.73549326]\n",
      "This is the 36th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 44.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.288661  0.343831  0.586371  0.828346   \n",
      "5   Gradient Boosting Regressor  0.278920  0.295521  0.543619  0.852464   \n",
      "10               XGBRFRegressor  0.353856  0.569842  0.754878  0.715513   \n",
      "4       Random Forest Regressor  0.323398  0.392108  0.626185  0.804244   \n",
      "7              BaggingRegressor  0.310463  0.356264  0.596879  0.822139   \n",
      "9                  XGBRegressor  0.314009  0.563728  0.750818  0.718565   \n",
      "14                     boosting  0.218983  0.202066  0.449517  0.899121   \n",
      "12                          SVM  0.470783  0.635871  0.797415  0.682548   \n",
      "13                      bagging  0.377866  0.445462  0.667430  0.777608   \n",
      "11                     LightGBM  0.350859  0.429832  0.655616  0.785411   \n",
      "1              Ridge Regression  0.389166  0.349236  0.590962  0.825648   \n",
      "6            Adaboost Regressor  0.423719  0.614669  0.784009  0.693133   \n",
      "3       Decision Tree Regressor  0.279433  0.361568  0.601305  0.819491   \n",
      "0             Linear Regression  0.516189  1.096704  1.047236  0.452483   \n",
      "15                     stacking  0.404885  0.327360  0.572154  0.836569   \n",
      "2              Lasso Regression  1.204340  2.633295  1.622743 -0.314644   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.214568           0.139745          0.100853          0.022389  \n",
      "5   1.184420           0.181291          0.137018          0.035942  \n",
      "10  1.355609           0.222352          0.163488          0.053464  \n",
      "4   1.244695           0.225098          0.164705          0.054922  \n",
      "7   1.222326           0.225501          0.164281          0.054703  \n",
      "9   1.351794           0.233084          0.156229          0.064796  \n",
      "14  1.126099           0.242586          0.165882          0.074745  \n",
      "12  1.396815           0.247755          0.183401          0.066009  \n",
      "13  1.277990           0.277077          0.207224          0.080586  \n",
      "11  1.268236           0.290982          0.215555          0.090697  \n",
      "1   1.217941           0.302448          0.231859          0.096727  \n",
      "6   1.383584           0.305695          0.229421          0.105880  \n",
      "3   1.225636           0.344048          0.240064          0.132056  \n",
      "0   1.684397           0.387072          0.278252          0.176126  \n",
      "15  1.204289           0.506336          0.339091          0.332001  \n",
      "2   2.643305           0.756146          0.510044          0.663239  \n",
      "Predictions for the next 12 periods (136-147) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[33.80168019 32.00984396 29.638863   28.40235185 27.33314019 27.52351169\n",
      " 26.18576517 24.86135172 23.74141095 23.17125404 22.91624433 22.40121164]\n",
      "Predictions for the next 12 periods:\n",
      "[2.45462484 2.19526896 1.85208589 1.67310947 1.5183485  1.54590345\n",
      " 1.35227391 1.16057424 0.99847057 0.91594431 0.87903342 0.80448601]\n",
      "This is the 37th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.293335  0.380876  0.617151  0.809852   \n",
      "5   Gradient Boosting Regressor  0.306586  0.374460  0.611931  0.813055   \n",
      "4       Random Forest Regressor  0.327627  0.378433  0.615169  0.811071   \n",
      "9                  XGBRegressor  0.288228  0.389263  0.623910  0.805665   \n",
      "10               XGBRFRegressor  0.323756  0.412771  0.642473  0.793928   \n",
      "12                          SVM  0.482949  0.677247  0.822950  0.661892   \n",
      "7              BaggingRegressor  0.366692  0.459635  0.677964  0.770532   \n",
      "14                     boosting  0.213203  0.197927  0.444890  0.901187   \n",
      "13                      bagging  0.370243  0.392815  0.626750  0.803891   \n",
      "3       Decision Tree Regressor  0.485244  1.065089  1.032032  0.468266   \n",
      "11                     LightGBM  0.349800  0.417164  0.645882  0.791735   \n",
      "6            Adaboost Regressor  0.378058  0.390555  0.624944  0.805020   \n",
      "1              Ridge Regression  0.195860  0.081232  0.285012  0.959446   \n",
      "0             Linear Regression  0.480126  0.950838  0.975109  0.525304   \n",
      "2              Lasso Regression  1.205226  2.609615  1.615430 -0.302822   \n",
      "15                     stacking  1.444107  3.745016  1.935204 -0.869659   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.237685           0.163873          0.116987          0.029864  \n",
      "5   1.233681           0.208827          0.157205          0.048628  \n",
      "4   1.236161           0.235848          0.177966          0.062794  \n",
      "9   1.242919           0.240267          0.175891          0.062338  \n",
      "10  1.257589           0.240946          0.177809          0.060594  \n",
      "12  1.422635           0.246949          0.187959          0.068543  \n",
      "7   1.286835           0.250527          0.186428          0.068839  \n",
      "14  1.123516           0.253322          0.186090          0.070727  \n",
      "13  1.245136           0.280386          0.216021          0.087924  \n",
      "3   1.664668           0.293962          0.215630          0.091731  \n",
      "11  1.260331           0.304526          0.238847          0.099951  \n",
      "6   1.243725           0.307377          0.232489          0.103481  \n",
      "1   1.050693           0.308427          0.243228          0.104160  \n",
      "0   1.593369           0.353061          0.270624          0.141180  \n",
      "2   2.628527           0.771191          0.526920          0.690463  \n",
      "15  3.337073           0.780480          0.485934          0.795209  \n",
      "Predictions for the next 12 periods (137-148) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[31.68792445 29.45994312 28.42131372 27.74923003 27.44718965 26.49110152\n",
      " 25.07256425 23.11894244 21.41232339 21.32404614 20.97341062 20.94585887]\n",
      "Predictions for the next 12 periods:\n",
      "[2.14867334 1.82618848 1.67585407 1.57857462 1.53485636 1.39646923\n",
      " 1.19114579 0.90837257 0.66135129 0.64857377 0.59782171 0.59383378]\n",
      "This is the 38th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.240596  0.258284  0.508217  0.871054   \n",
      "5   Gradient Boosting Regressor  0.268692  0.390496  0.624897  0.805049   \n",
      "7              BaggingRegressor  0.352234  0.441683  0.664592  0.779495   \n",
      "10               XGBRFRegressor  0.335140  0.482759  0.694808  0.758988   \n",
      "4       Random Forest Regressor  0.308176  0.362704  0.602249  0.818924   \n",
      "14                     boosting  0.169267  0.160165  0.400207  0.920039   \n",
      "12                          SVM  0.440205  0.535869  0.732031  0.732473   \n",
      "9                  XGBRegressor  0.290184  0.506716  0.711840  0.747028   \n",
      "13                      bagging  0.370575  0.416418  0.645305  0.792108   \n",
      "6            Adaboost Regressor  0.410990  0.602500  0.776209  0.699208   \n",
      "1              Ridge Regression  0.192380  0.076419  0.276441  0.961848   \n",
      "11                     LightGBM  0.339329  0.442419  0.665146  0.779127   \n",
      "3       Decision Tree Regressor  0.270564  0.391362  0.625590  0.804617   \n",
      "0             Linear Regression  0.491059  1.014753  1.007350  0.493395   \n",
      "2              Lasso Regression  1.206340  2.580459  1.606381 -0.288266   \n",
      "15                     stacking  1.426991  3.551470  1.884534 -0.773032   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.161182           0.156004          0.112944          0.029327  \n",
      "5   1.243689           0.220411          0.158049          0.054290  \n",
      "7   1.275632           0.230557          0.174001          0.060588  \n",
      "10  1.301265           0.231124          0.172617          0.057336  \n",
      "4   1.226345           0.232695          0.175106          0.059122  \n",
      "14  1.099951           0.238463          0.169650          0.066727  \n",
      "12  1.334408           0.256664          0.194390          0.073788  \n",
      "9   1.316216           0.256958          0.182523          0.073878  \n",
      "13  1.259865           0.278910          0.211315          0.084895  \n",
      "6   1.375989           0.287545          0.225048          0.085283  \n",
      "1   1.047689           0.290666          0.233442          0.092585  \n",
      "11  1.276091           0.292865          0.227442          0.088465  \n",
      "3   1.244229           0.316766          0.219579          0.108789  \n",
      "0   1.633256           0.348636          0.269909          0.138731  \n",
      "2   2.610332           0.798203          0.546879          0.728765  \n",
      "15  3.216291           1.006319          0.637503          1.260901  \n",
      "Predictions for the next 12 periods (138-149) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[26.5345548  26.83034533 25.60069218 25.09640448 23.45790048 22.16863923\n",
      " 21.03003813 20.82112543 20.25615103 20.0516151  19.77197307 19.92402738]\n",
      "Predictions for the next 12 periods:\n",
      "[1.40275879 1.44557242 1.26758865 1.1945965  0.9574344  0.77082277\n",
      " 0.60601815 0.57577948 0.49400335 0.46439819 0.42392195 0.44593075]\n",
      "This is the 39th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.162833  0.150121  0.387454  0.925054   \n",
      "5   Gradient Boosting Regressor  0.233667  0.308099  0.555066  0.846185   \n",
      "10               XGBRFRegressor  0.389594  0.768417  0.876594  0.616376   \n",
      "4       Random Forest Regressor  0.301839  0.359287  0.599405  0.820630   \n",
      "9                  XGBRegressor  0.347527  0.831995  0.912138  0.584635   \n",
      "12                          SVM  0.376848  0.351854  0.593173  0.824341   \n",
      "7              BaggingRegressor  0.307063  0.271757  0.521303  0.864328   \n",
      "14                     boosting  0.102926  0.065328  0.255593  0.967386   \n",
      "11                     LightGBM  0.354221  0.545950  0.738884  0.727440   \n",
      "1              Ridge Regression  0.192192  0.078322  0.279861  0.960899   \n",
      "13                      bagging  0.359697  0.426264  0.652889  0.787192   \n",
      "0             Linear Regression  0.519843  1.165702  1.079677  0.418036   \n",
      "6            Adaboost Regressor  0.320586  0.412356  0.642149  0.794136   \n",
      "3       Decision Tree Regressor  0.368266  0.906359  0.952029  0.547510   \n",
      "2              Lasso Regression  1.207864  2.544339  1.595098 -0.270233   \n",
      "15                     stacking  1.544984  4.259906  2.063954 -1.126712   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.093683           0.187060          0.122004          0.046453  \n",
      "5   1.192269           0.236328          0.166617          0.064665  \n",
      "10  1.479530           0.255856          0.185758          0.069703  \n",
      "4   1.224213           0.265218          0.184356          0.082201  \n",
      "9   1.519206           0.267307          0.185383          0.079662  \n",
      "12  1.219574           0.275116          0.197199          0.087653  \n",
      "7   1.169590           0.278277          0.204869          0.085994  \n",
      "14  1.040768           0.280532          0.184107          0.090815  \n",
      "11  1.340699           0.284949          0.215247          0.089880  \n",
      "1   1.048877           0.308565          0.234991          0.104149  \n",
      "13  1.266009           0.309362          0.224424          0.110481  \n",
      "0   1.727455           0.320344          0.249909          0.105579  \n",
      "6   1.257330           0.333213          0.245379          0.119224  \n",
      "3   1.565612           0.379684          0.259108          0.160106  \n",
      "2   2.587792           0.855424          0.575657          0.791168  \n",
      "15  3.658390           1.089384          0.683955          1.291419  \n",
      "Predictions for the next 12 periods (139-150) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[28.31569712 28.29356251 27.93353829 26.53004311 25.40785196 24.70708116\n",
      " 23.60594615 23.14026625 23.25538568 22.56779874 22.650757   22.58324607]\n",
      "Predictions for the next 12 periods:\n",
      "[1.6605668  1.65736297 1.60525196 1.40210576 1.23967636 1.13824465\n",
      " 0.97886298 0.91145905 0.92812179 0.82859834 0.84060597 0.83083423]\n",
      "This is the 40th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.165540  0.162759  0.403434  0.918744   \n",
      "5   Gradient Boosting Regressor  0.248302  0.406833  0.637834  0.796893   \n",
      "10               XGBRFRegressor  0.380303  0.747478  0.864568  0.626830   \n",
      "9                  XGBRegressor  0.351019  0.841374  0.917264  0.579953   \n",
      "4       Random Forest Regressor  0.270473  0.331192  0.575493  0.834656   \n",
      "7              BaggingRegressor  0.373727  0.545794  0.738779  0.727518   \n",
      "14                     boosting  0.126345  0.100734  0.317386  0.949710   \n",
      "12                          SVM  0.311388  0.229493  0.479055  0.885428   \n",
      "13                      bagging  0.343268  0.353317  0.594405  0.823610   \n",
      "11                     LightGBM  0.392069  0.701945  0.837822  0.649562   \n",
      "1              Ridge Regression  0.192912  0.068741  0.262186  0.965682   \n",
      "6            Adaboost Regressor  0.302381  0.303273  0.550702  0.848594   \n",
      "0             Linear Regression  0.391550  0.691129  0.831342  0.654961   \n",
      "3       Decision Tree Regressor  0.321576  0.723425  0.850544  0.638838   \n",
      "15                     stacking  2.151630  8.180134  2.860093 -3.083843   \n",
      "2              Lasso Regression  1.210195  2.509918  1.584272 -0.253049   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.101569           0.160307          0.119338          0.036344  \n",
      "5   1.253884           0.221990          0.165895          0.055963  \n",
      "10  1.466463           0.238782          0.178156          0.064257  \n",
      "9   1.525058           0.245197          0.175232          0.070960  \n",
      "4   1.206680           0.260752          0.192407          0.078814  \n",
      "7   1.340602           0.265273          0.195804          0.081862  \n",
      "14  1.062863           0.265429          0.179436          0.078821  \n",
      "12  1.143215           0.281472          0.203999          0.089444  \n",
      "13  1.220487           0.286789          0.214330          0.096380  \n",
      "11  1.438048           0.302040          0.235841          0.098033  \n",
      "1   1.042898           0.303312          0.239233          0.101362  \n",
      "6   1.189257           0.316571          0.244420          0.107335  \n",
      "0   1.431298           0.376087          0.278238          0.151364  \n",
      "3   1.451453           0.386573          0.265597          0.177721  \n",
      "15  6.104803           0.831378          0.552344          0.794411  \n",
      "2   2.566311           0.868550          0.601465          0.856985  \n",
      "Predictions for the next 12 periods (140-151) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[32.67526159 30.73709826 28.04666833 26.25682772 25.50135076 24.5750726\n",
      " 22.9291674  22.25069793 22.27461046 22.43692051 22.59768218 22.53610325]\n",
      "Predictions for the next 12 periods:\n",
      "[2.29158355 2.01104784 1.62162675 1.36255972 1.25320967 1.11913732\n",
      " 0.88090395 0.78270019 0.78616137 0.80965462 0.83292376 0.82401064]\n",
      "This is the 41th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.162242  0.166504  0.408049  0.916875   \n",
      "5   Gradient Boosting Regressor  0.223041  0.341058  0.584002  0.829730   \n",
      "10               XGBRFRegressor  0.375121  0.735360  0.857531  0.632880   \n",
      "4       Random Forest Regressor  0.262318  0.326254  0.571187  0.837121   \n",
      "9                  XGBRegressor  0.322088  0.765386  0.874864  0.617889   \n",
      "14                     boosting  0.152876  0.170765  0.413237  0.914748   \n",
      "7              BaggingRegressor  0.286438  0.322903  0.568245  0.838794   \n",
      "12                          SVM  0.275486  0.184140  0.429115  0.908070   \n",
      "11                     LightGBM  0.402398  0.782189  0.884414  0.609501   \n",
      "13                      bagging  0.370422  0.421072  0.648900  0.789785   \n",
      "1              Ridge Regression  0.194551  0.071817  0.267987  0.964146   \n",
      "6            Adaboost Regressor  0.332362  0.453649  0.673535  0.773521   \n",
      "3       Decision Tree Regressor  0.270796  0.593181  0.770182  0.703861   \n",
      "0             Linear Regression  0.315329  0.510372  0.714403  0.745202   \n",
      "2              Lasso Regression  1.212311  2.479641  1.574687 -0.237934   \n",
      "15                     stacking  1.831043  5.888357  2.426594 -1.939698   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.103906           0.155400          0.113516          0.028010  \n",
      "5   1.212837           0.225741          0.161061          0.053901  \n",
      "10  1.458900           0.232960          0.175406          0.056626  \n",
      "4   1.203599           0.245864          0.179960          0.064772  \n",
      "9   1.477638           0.256747          0.179254          0.074440  \n",
      "14  1.106566           0.261492          0.179704          0.078160  \n",
      "7   1.201507           0.264904          0.194586          0.079736  \n",
      "12  1.114912           0.275019          0.203339          0.080823  \n",
      "11  1.488124           0.279754          0.217089          0.080905  \n",
      "13  1.262769           0.280144          0.211543          0.084379  \n",
      "1   1.044817           0.290496          0.227197          0.090776  \n",
      "6   1.283099           0.309067          0.234151          0.102690  \n",
      "3   1.370174           0.333391          0.244077          0.119118  \n",
      "0   1.318497           0.388818          0.292809          0.165144  \n",
      "2   2.547417           0.919008          0.630619          0.915140  \n",
      "15  4.674623           0.928180          0.583707          0.940800  \n",
      "fine\n",
      "Predictions for the next 12 periods (141-152) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.51353113 33.47491103 30.05752556 28.15673961 25.71798408 25.20407713\n",
      " 23.90262495 22.56448781 22.35173138 22.67065712 22.96726242 23.16941727]\n",
      "Predictions for the next 12 periods:\n",
      "[2.7024034  2.40732727 1.9126844  1.6375588  1.28456584 1.21018137\n",
      " 1.02180518 0.82811911 0.79732409 0.84348638 0.88641794 0.91567845]\n",
      "This is the 42th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.154427  0.160421  0.400526  0.919912   \n",
      "5   Gradient Boosting Regressor  0.173173  0.194342  0.440843  0.902977   \n",
      "10               XGBRFRegressor  0.277808  0.405892  0.637096  0.797363   \n",
      "4       Random Forest Regressor  0.264237  0.314256  0.560586  0.843111   \n",
      "9                  XGBRegressor  0.212814  0.369902  0.608196  0.815330   \n",
      "7              BaggingRegressor  0.289852  0.273973  0.523424  0.863222   \n",
      "12                          SVM  0.292800  0.204087  0.451760  0.898112   \n",
      "14                     boosting  0.079987  0.047304  0.217495  0.976384   \n",
      "1              Ridge Regression  0.224111  0.108524  0.329429  0.945821   \n",
      "11                     LightGBM  0.336564  0.543062  0.736927  0.728882   \n",
      "13                      bagging  0.323152  0.324970  0.570062  0.837762   \n",
      "6            Adaboost Regressor  0.235300  0.133280  0.365076  0.933461   \n",
      "0             Linear Regression  0.245844  0.359130  0.599274  0.820708   \n",
      "3       Decision Tree Regressor  0.202844  0.335651  0.579354  0.832430   \n",
      "2              Lasso Regression  1.213746  2.459648  1.568327 -0.227953   \n",
      "15                     stacking  1.821054  5.770854  2.402260 -1.881036   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.100111           0.155329          0.115906          0.029093  \n",
      "5   1.121279           0.211490          0.149974          0.049712  \n",
      "10  1.253296           0.243791          0.182218          0.061300  \n",
      "4   1.196111           0.247260          0.183683          0.065724  \n",
      "9   1.230837           0.253494          0.180272          0.072106  \n",
      "7   1.170973           0.273578          0.208475          0.080899  \n",
      "12  1.127360           0.273970          0.202173          0.078957  \n",
      "14  1.029520           0.285679          0.188658          0.087685  \n",
      "1   1.067724           0.291309          0.228382          0.089909  \n",
      "11  1.338897           0.297137          0.226993          0.093974  \n",
      "13  1.202797           0.303956          0.223490          0.099679  \n",
      "6   1.083173           0.310372          0.239091          0.102163  \n",
      "0   1.224114           0.353288          0.276691          0.129019  \n",
      "3   1.209462           0.353344          0.250738          0.133986  \n",
      "2   2.534941           0.917949          0.642710          0.927116  \n",
      "15  4.601295           0.984933          0.629983          1.089873  \n",
      "fine\n",
      "Predictions for the next 12 periods (142-153) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 32.76090503 30.03166969 27.15660782 25.60282698 23.81244945\n",
      " 23.54587444 22.00293947 21.29076818 21.59774463 22.01118586 22.13488978]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 2.30397985 1.90894194 1.49279666 1.26789765 1.00875291\n",
      " 0.97016802 0.74683887 0.64375701 0.68818973 0.74803248 0.76593777]\n",
      "This is the 43th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.143235  0.136574  0.369559  0.931817   \n",
      "10               XGBRFRegressor  0.263308  0.352429  0.593657  0.824054   \n",
      "5   Gradient Boosting Regressor  0.186332  0.222109  0.471284  0.889115   \n",
      "4       Random Forest Regressor  0.235254  0.227987  0.477480  0.886180   \n",
      "11                     LightGBM  0.314534  0.467142  0.683478  0.766785   \n",
      "9                  XGBRegressor  0.209365  0.358927  0.599105  0.820809   \n",
      "14                     boosting  0.077566  0.045641  0.213638  0.977214   \n",
      "12                          SVM  0.287914  0.194492  0.441013  0.902902   \n",
      "7              BaggingRegressor  0.310925  0.480906  0.693474  0.759913   \n",
      "13                      bagging  0.309022  0.311571  0.558186  0.844451   \n",
      "1              Ridge Regression  0.210359  0.094573  0.307527  0.952786   \n",
      "6            Adaboost Regressor  0.322099  0.376025  0.613208  0.812274   \n",
      "3       Decision Tree Regressor  0.208059  0.350217  0.591791  0.825158   \n",
      "0             Linear Regression  0.229445  0.331048  0.575368  0.834728   \n",
      "2              Lasso Regression  1.215156  2.440427  1.562187 -0.218357   \n",
      "15                     stacking  1.748658  5.419802  2.328047 -1.705777   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.085229           0.159726          0.116618          0.029158  \n",
      "10  1.219933           0.236880          0.177778          0.057347  \n",
      "5   1.138607           0.236944          0.168961          0.063243  \n",
      "4   1.142275           0.244517          0.180793          0.064834  \n",
      "11  1.291519           0.255643          0.200295          0.068766  \n",
      "9   1.223988           0.260326          0.179882          0.074418  \n",
      "14  1.028482           0.264635          0.180607          0.078107  \n",
      "12  1.121373           0.267932          0.200780          0.077284  \n",
      "7   1.300109           0.277449          0.200255          0.085600  \n",
      "13  1.194436           0.279444          0.212047          0.085809  \n",
      "1   1.059018           0.287145          0.228114          0.088120  \n",
      "6   1.234658           0.295674          0.227685          0.095024  \n",
      "3   1.218552           0.362871          0.246554          0.142148  \n",
      "0   1.206590           0.374071          0.284474          0.155452  \n",
      "2   2.522946           0.922115          0.661804          0.956760  \n",
      "15  4.382222           1.032362          0.696247          1.162000  \n",
      "fine\n",
      "Predictions for the next 12 periods (143-154) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 27.69360093 26.64672702 26.08400655 25.12594127\n",
      " 24.40304617 23.4949657  22.78945215 22.5690649  22.66057804 23.14651908]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 1.86111556 1.57052269 1.41899495 1.33754506 1.19887175\n",
      " 1.09423769 0.96279933 0.86068113 0.82878161 0.8420275  0.9123641 ]\n",
      "This is the 44th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.141838  0.185015  0.430134  0.907633   \n",
      "5   Gradient Boosting Regressor  0.200384  0.319332  0.565095  0.840577   \n",
      "10               XGBRFRegressor  0.297593  0.510742  0.714662  0.745018   \n",
      "9                  XGBRegressor  0.250789  0.543581  0.737279  0.728623   \n",
      "4       Random Forest Regressor  0.235100  0.248879  0.498878  0.875750   \n",
      "7              BaggingRegressor  0.198788  0.126964  0.356319  0.936615   \n",
      "12                          SVM  0.281869  0.189051  0.434800  0.905618   \n",
      "14                     boosting  0.104086  0.092102  0.303484  0.954019   \n",
      "13                      bagging  0.330364  0.322611  0.567989  0.838940   \n",
      "1              Ridge Regression  0.178715  0.066498  0.257872  0.966802   \n",
      "11                     LightGBM  0.335686  0.515915  0.718272  0.742435   \n",
      "6            Adaboost Regressor  0.313950  0.408245  0.638940  0.796188   \n",
      "3       Decision Tree Regressor  0.256724  0.563371  0.750580  0.718743   \n",
      "0             Linear Regression  0.190405  0.220628  0.469711  0.889854   \n",
      "2              Lasso Regression  1.216951  2.416541  1.554523 -0.206432   \n",
      "15                     stacking  1.548015  4.120960  2.030015 -1.057345   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.115458           0.178286          0.122211          0.040867  \n",
      "5   1.199279           0.237704          0.168629          0.063290  \n",
      "10  1.318728           0.256166          0.187770          0.071916  \n",
      "9   1.339221           0.259015          0.179818          0.072545  \n",
      "4   1.155313           0.265589          0.192816          0.082451  \n",
      "7   1.079231           0.274070          0.198155          0.085632  \n",
      "12  1.117977           0.286182          0.213224          0.090336  \n",
      "14  1.057476           0.290872          0.192149          0.095293  \n",
      "13  1.201325           0.292805          0.226781          0.098564  \n",
      "1   1.041498           0.303449          0.238838          0.102721  \n",
      "11  1.321956           0.307333          0.227277          0.104968  \n",
      "6   1.254765           0.312880          0.245923          0.106841  \n",
      "3   1.351571           0.346718          0.245878          0.125998  \n",
      "0   1.137683           0.357669          0.268353          0.137234  \n",
      "2   2.508040           0.948432          0.683296          0.995947  \n",
      "15  3.571681           1.099649          0.734526          1.394763  \n",
      "fine\n",
      "Predictions for the next 12 periods (144-155) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 28.55658159 27.26075791 26.36309759\n",
      " 25.87116693 25.65930646 24.87655805 24.74434345 25.15697836 25.15513408]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 1.86111556 1.85671248 1.69543316 1.50787166 1.37794155\n",
      " 1.306738   1.27607266 1.16277525 1.1436381  1.20336415 1.2030972 ]\n",
      "This is the 45th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.147371  0.210280  0.458563  0.895020   \n",
      "5   Gradient Boosting Regressor  0.180982  0.267156  0.516872  0.866625   \n",
      "10               XGBRFRegressor  0.308570  0.566416  0.752606  0.717223   \n",
      "9                  XGBRegressor  0.281451  0.682075  0.825878  0.659481   \n",
      "4       Random Forest Regressor  0.260657  0.312151  0.558705  0.844162   \n",
      "11                     LightGBM  0.339930  0.577257  0.759774  0.711811   \n",
      "1              Ridge Regression  0.166597  0.057942  0.240712  0.971073   \n",
      "7              BaggingRegressor  0.360405  0.586287  0.765694  0.707303   \n",
      "12                          SVM  0.295723  0.250656  0.500656  0.874863   \n",
      "14                     boosting  0.179056  0.266747  0.516476  0.866829   \n",
      "13                      bagging  0.321789  0.345807  0.588054  0.827360   \n",
      "6            Adaboost Regressor  0.306906  0.344068  0.586573  0.828228   \n",
      "0             Linear Regression  0.165638  0.178875  0.422936  0.910699   \n",
      "3       Decision Tree Regressor  0.280170  0.678066  0.823448  0.661483   \n",
      "2              Lasso Regression  1.218964  2.390556  1.546142 -0.193459   \n",
      "15                     stacking  1.700907  5.073937  2.252540 -1.533108   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.131225           0.164353          0.116811          0.030809  \n",
      "5   1.166719           0.219063          0.160587          0.052677  \n",
      "10  1.353471           0.244968          0.184093          0.062494  \n",
      "9   1.425648           0.257703          0.171124          0.072590  \n",
      "4   1.194798           0.261705          0.188230          0.075189  \n",
      "11  1.360237           0.280937          0.205191          0.084087  \n",
      "1   1.036159           0.286208          0.225025          0.087716  \n",
      "7   1.365872           0.292765          0.206899          0.096576  \n",
      "12  1.156422           0.295080          0.221430          0.094199  \n",
      "14  1.166463           0.296856          0.197008          0.094169  \n",
      "13  1.215800           0.304923          0.225183          0.102320  \n",
      "6   1.214715           0.331439          0.250139          0.115437  \n",
      "0   1.111627           0.357928          0.274941          0.140328  \n",
      "3   1.423146           0.371186          0.244724          0.146701  \n",
      "2   2.491824           1.001447          0.705308          1.035635  \n",
      "15  4.166385           1.288222          0.790072          1.753465  \n",
      "fine\n",
      "Predictions for the next 12 periods (145-156) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 33.43224095 30.69267289 27.54484906\n",
      " 26.07486908 24.94468806 24.20867069 24.30970028 24.83256242 24.6748023 ]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 1.86111556 1.85671248 2.40115107 2.00461757 1.54899189\n",
      " 1.33622247 1.1726366  1.06610318 1.08072652 1.15640719 1.13357251]\n",
      "This is the 46th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.166957  0.280392  0.529521  0.860017   \n",
      "5   Gradient Boosting Regressor  0.162497  0.234538  0.484291  0.882910   \n",
      "9                  XGBRegressor  0.194323  0.390993  0.625294  0.804801   \n",
      "10               XGBRFRegressor  0.280223  0.461848  0.679594  0.769428   \n",
      "4       Random Forest Regressor  0.252551  0.297325  0.545275  0.851564   \n",
      "14                     boosting  0.052051  0.027364  0.165419  0.986339   \n",
      "11                     LightGBM  0.321862  0.503843  0.709819  0.748462   \n",
      "12                          SVM  0.297827  0.252316  0.502311  0.874034   \n",
      "1              Ridge Regression  0.177011  0.068928  0.262541  0.965588   \n",
      "13                      bagging  0.334475  0.324550  0.569693  0.837972   \n",
      "7              BaggingRegressor  0.310015  0.421161  0.648969  0.789740   \n",
      "6            Adaboost Regressor  0.290348  0.332035  0.576225  0.834235   \n",
      "0             Linear Regression  0.189304  0.232242  0.481915  0.884056   \n",
      "3       Decision Tree Regressor  0.180243  0.330587  0.574967  0.834958   \n",
      "2              Lasso Regression  1.220391  2.372648  1.540340 -0.184518   \n",
      "15                     stacking  1.910079  6.527585  2.554914 -2.258826   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.174979           0.167243          0.117044          0.031905  \n",
      "5   1.146363           0.204787          0.150112          0.043175  \n",
      "9   1.243999           0.237985          0.161836          0.060153  \n",
      "10  1.288215           0.254954          0.185043          0.065851  \n",
      "4   1.185545           0.256802          0.182992          0.068940  \n",
      "14  1.017076           0.276051          0.184928          0.081608  \n",
      "11  1.314422           0.278523          0.201639          0.080881  \n",
      "12  1.157458           0.281154          0.211344          0.085946  \n",
      "1   1.043014           0.287872          0.226128          0.087506  \n",
      "13  1.202535           0.295078          0.217696          0.091991  \n",
      "7   1.262825           0.302891          0.214474          0.096152  \n",
      "6   1.207206           0.331123          0.252550          0.112774  \n",
      "0   1.144931           0.344913          0.271213          0.129694  \n",
      "3   1.206303           0.361329          0.247382          0.151015  \n",
      "2   2.480648           0.992964          0.724001          1.062564  \n",
      "15  5.073532           1.234521          0.802672          1.719481  \n",
      "fine\n",
      "Predictions for the next 12 periods (146-157) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 33.43224095 35.71014558 33.00805781\n",
      " 31.33097968 29.81205148 29.19580931 29.41381476 30.00888127 30.23012514]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 1.86111556 1.85671248 2.40115107 2.73086198 2.3397535\n",
      " 2.09700806 1.87715373 1.78795694 1.81951172 1.90564348 1.93766699]\n",
      "This is the 47th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.154514  0.269480  0.519114  0.865465   \n",
      "5   Gradient Boosting Regressor  0.146033  0.191986  0.438163  0.904153   \n",
      "10               XGBRFRegressor  0.220835  0.292034  0.540402  0.854205   \n",
      "9                  XGBRegressor  0.160159  0.289343  0.537906  0.855549   \n",
      "4       Random Forest Regressor  0.221650  0.235257  0.485033  0.882551   \n",
      "7              BaggingRegressor  0.201677  0.197523  0.444436  0.901389   \n",
      "12                          SVM  0.293676  0.241552  0.491479  0.879408   \n",
      "14                     boosting  0.091022  0.080642  0.283975  0.959740   \n",
      "11                     LightGBM  0.262344  0.329652  0.574153  0.835425   \n",
      "1              Ridge Regression  0.149184  0.043555  0.208698  0.978256   \n",
      "13                      bagging  0.317926  0.331802  0.576022  0.834352   \n",
      "6            Adaboost Regressor  0.266374  0.267965  0.517653  0.866221   \n",
      "3       Decision Tree Regressor  0.199966  0.490035  0.700025  0.755355   \n",
      "0             Linear Regression  0.146210  0.158907  0.398631  0.920668   \n",
      "2              Lasso Regression  1.221527  2.358685  1.535801 -0.177548   \n",
      "15                     stacking  1.929399  6.513678  2.552191 -2.251883   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.168168           0.180632          0.125190          0.036922  \n",
      "5   1.119809           0.225875          0.164320          0.053109  \n",
      "10  1.182244           0.240966          0.178700          0.061724  \n",
      "9   1.180564           0.255678          0.178953          0.070964  \n",
      "4   1.146812           0.261408          0.191226          0.075217  \n",
      "7   1.123264           0.279972          0.195446          0.084107  \n",
      "12  1.150740           0.287655          0.218234          0.089167  \n",
      "14  1.050325           0.290369          0.188710          0.091220  \n",
      "11  1.205719           0.291537          0.213810          0.091671  \n",
      "1   1.027180           0.292587          0.232529          0.092723  \n",
      "13  1.207060           0.295144          0.226664          0.095488  \n",
      "6   1.167223           0.330443          0.253273          0.116548  \n",
      "3   1.305806           0.343596          0.233455          0.137785  \n",
      "0   1.099165           0.359785          0.258040          0.135887  \n",
      "2   2.471935           0.989162          0.731640          1.072891  \n",
      "15  5.064853           1.229094          0.808697          1.750187  \n",
      "fine\n",
      "Predictions for the next 12 periods (147-158) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 33.43224095 35.71014558 30.50069868\n",
      " 29.64534523 28.94579184 28.51182717 28.05212678 27.93913256 28.37078256]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 1.86111556 1.85671248 2.40115107 2.73086198 1.97683064\n",
      " 1.85302415 1.75176865 1.68895527 1.62241682 1.60606169 1.66854004]\n",
      "This is the 48th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.103243  0.143204  0.378423  0.928507   \n",
      "5   Gradient Boosting Regressor  0.116455  0.127265  0.356743  0.936464   \n",
      "10               XGBRFRegressor  0.155126  0.127185  0.356630  0.936504   \n",
      "4       Random Forest Regressor  0.182636  0.150265  0.387640  0.924982   \n",
      "14                     boosting  0.086194  0.093512  0.305797  0.953315   \n",
      "11                     LightGBM  0.171148  0.108465  0.329341  0.945850   \n",
      "9                  XGBRegressor  0.089051  0.106556  0.326429  0.946803   \n",
      "12                          SVM  0.267130  0.177479  0.421283  0.911395   \n",
      "1              Ridge Regression  0.139357  0.037211  0.192901  0.981423   \n",
      "7              BaggingRegressor  0.199522  0.143390  0.378668  0.928414   \n",
      "13                      bagging  0.271294  0.218999  0.467973  0.890667   \n",
      "6            Adaboost Regressor  0.168924  0.058064  0.240964  0.971012   \n",
      "3       Decision Tree Regressor  0.083369  0.093432  0.305666  0.953355   \n",
      "0             Linear Regression  0.133865  0.141349  0.375964  0.929433   \n",
      "2              Lasso Regression  1.222163  2.350998  1.533296 -0.173710   \n",
      "15                     stacking  1.972335  7.314159  2.704470 -2.651514   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.089366           0.177957          0.123288          0.035118  \n",
      "5   1.079420           0.213426          0.157190          0.047620  \n",
      "10  1.079370           0.252854          0.190106          0.067403  \n",
      "4   1.093773           0.262855          0.189886          0.072542  \n",
      "14  1.058356           0.265914          0.184204          0.079813  \n",
      "11  1.067688           0.279199          0.199648          0.083258  \n",
      "9   1.066496           0.281700          0.188608          0.089050  \n",
      "12  1.110756           0.289198          0.218011          0.087175  \n",
      "1   1.023221           0.299448          0.234581          0.093099  \n",
      "7   1.089482           0.300271          0.207399          0.093852  \n",
      "13  1.136666           0.301626          0.223114          0.094795  \n",
      "6   1.036235           0.320085          0.250197          0.108434  \n",
      "3   1.058306           0.322873          0.219387          0.119619  \n",
      "0   1.088209           0.336885          0.254317          0.116873  \n",
      "2   2.467137           1.021996          0.736447          1.063899  \n",
      "15  5.564393           1.162950          0.754321          1.461686  \n",
      "fine\n",
      "Predictions for the next 12 periods (148-159) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 33.43224095 35.71014558 30.50069868\n",
      " 27.96098937 28.15199712 27.3952115  28.07664755 28.24318486 28.23828333]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 1.86111556 1.85671248 2.40115107 2.73086198 1.97683064\n",
      " 1.60922531 1.63687236 1.52733289 1.62596603 1.65007116 1.64936169]\n",
      "This is the 49th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.056352  0.054809  0.234113  0.972637   \n",
      "5   Gradient Boosting Regressor  0.056903  0.027039  0.164435  0.986501   \n",
      "4       Random Forest Regressor  0.131538  0.052346  0.228792  0.973867   \n",
      "10               XGBRFRegressor  0.103198  0.036693  0.191553  0.981682   \n",
      "11                     LightGBM  0.122683  0.040810  0.202016  0.979626   \n",
      "9                  XGBRegressor  0.027661  0.012956  0.113826  0.993532   \n",
      "7              BaggingRegressor  0.173223  0.076467  0.276527  0.961825   \n",
      "14                     boosting  0.042229  0.025884  0.160886  0.987078   \n",
      "1              Ridge Regression  0.139303  0.037812  0.194452  0.981123   \n",
      "12                          SVM  0.248540  0.142477  0.377461  0.928870   \n",
      "6            Adaboost Regressor  0.149296  0.036464  0.190956  0.981796   \n",
      "3       Decision Tree Regressor  0.032386  0.018186  0.134857  0.990921   \n",
      "13                      bagging  0.247307  0.142666  0.377712  0.928776   \n",
      "0             Linear Regression  0.114401  0.111767  0.334316  0.944201   \n",
      "2              Lasso Regression  1.222320  2.349106  1.532679 -0.172766   \n",
      "15                     stacking  1.368020  3.570740  1.889640 -0.782653   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.034203           0.183864          0.127933          0.041328  \n",
      "5   1.016874           0.232524          0.168327          0.058495  \n",
      "4   1.032666           0.257631          0.191118          0.075556  \n",
      "10  1.022898           0.262339          0.194379          0.073397  \n",
      "11  1.025468           0.270170          0.187142          0.079930  \n",
      "9   1.008085           0.273911          0.185852          0.082416  \n",
      "7   1.047719           0.280899          0.207569          0.088650  \n",
      "14  1.016153           0.287781          0.194767          0.088472  \n",
      "1   1.023596           0.294913          0.234887          0.096311  \n",
      "12  1.088913           0.294984          0.222766          0.094535  \n",
      "6   1.022756           0.303092          0.239271          0.096648  \n",
      "3   1.011349           0.306136          0.218789          0.101950  \n",
      "13  1.089031           0.310180          0.231116          0.109225  \n",
      "0   1.069748           0.349906          0.262948          0.136206  \n",
      "2   2.465957           1.012190          0.734289          1.059482  \n",
      "15  3.228316           1.272818          0.829159          1.734671  \n",
      "fine\n",
      "Predictions for the next 12 periods (149-160) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 33.43224095 35.71014558 30.50069868\n",
      " 27.96098937 23.35208319 23.83722596 24.53523343 25.00827488 24.76983842]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 1.86111556 1.85671248 2.40115107 2.73086198 1.97683064\n",
      " 1.60922531 0.94211808 1.01233913 1.11337088 1.18184035 1.14732832]\n",
      "This is the 50th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.017667  0.009553  0.097737  0.995231   \n",
      "5   Gradient Boosting Regressor  0.023223  0.000917  0.030280  0.999542   \n",
      "4       Random Forest Regressor  0.110820  0.023248  0.152474  0.988394   \n",
      "10               XGBRFRegressor  0.070788  0.008609  0.092787  0.995702   \n",
      "11                     LightGBM  0.113519  0.026782  0.163651  0.986630   \n",
      "7              BaggingRegressor  0.087402  0.021512  0.146670  0.989260   \n",
      "14                     boosting  0.007836  0.001197  0.034592  0.999403   \n",
      "9                  XGBRegressor  0.003746  0.000498  0.022306  0.999752   \n",
      "1              Ridge Regression  0.134363  0.035806  0.189224  0.982124   \n",
      "12                          SVM  0.216213  0.096989  0.311430  0.951579   \n",
      "0             Linear Regression  0.096427  0.087583  0.295945  0.956275   \n",
      "13                      bagging  0.209655  0.086179  0.293562  0.956976   \n",
      "3       Decision Tree Regressor  0.003332  0.000502  0.022414  0.999749   \n",
      "6            Adaboost Regressor  0.128682  0.026316  0.162224  0.986862   \n",
      "2              Lasso Regression  1.222046  2.352409  1.533756 -0.174414   \n",
      "15                     stacking  1.081132  2.248949  1.499650 -0.122763   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.005961           0.173475          0.123198          0.036300  \n",
      "5   1.000572           0.215776          0.163937          0.051480  \n",
      "4   1.014508           0.249534          0.188163          0.070980  \n",
      "10  1.005373           0.255089          0.193986          0.070205  \n",
      "11  1.016713           0.269692          0.195491          0.085595  \n",
      "7   1.013425           0.274808          0.216325          0.084180  \n",
      "14  1.000747           0.287309          0.203180          0.093165  \n",
      "9   1.000311           0.288056          0.199380          0.101324  \n",
      "1   1.022344           0.288641          0.228881          0.088156  \n",
      "12  1.060526           0.300335          0.225086          0.099367  \n",
      "0   1.054656           0.305249          0.238557          0.102294  \n",
      "13  1.053780           0.313023          0.241098          0.110073  \n",
      "3   1.000314           0.317704          0.224856          0.111603  \n",
      "6   1.016423           0.331870          0.261259          0.118978  \n",
      "2   2.468018           1.010458          0.730817          1.055998  \n",
      "15  2.403454           1.360238          0.835101          1.990028  \n",
      "fine\n",
      "Predictions for the next 12 periods (150-161) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 31.36417151 29.67082715 33.43224095 35.71014558 30.50069868\n",
      " 27.96098937 23.35208319 18.86110472 20.76500474 21.46243005 21.75363719]\n",
      "Predictions for the next 12 periods:\n",
      "[2.71527578 2.10181235 1.85671248 2.40115107 2.73086198 1.97683064\n",
      " 1.60922531 0.94211808 0.29208006 0.5676564  0.66860388 0.7107541 ]\n",
      "This is the 51th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model       MAE       MSE      RMSE       R^2  \\\n",
      "8           ExtraTreesRegressor  0.008590  0.003763  0.061342  0.998121   \n",
      "5   Gradient Boosting Regressor  0.024058  0.001017  0.031889  0.999492   \n",
      "4       Random Forest Regressor  0.098257  0.019034  0.137965  0.990497   \n",
      "11                     LightGBM  0.109399  0.024710  0.157193  0.987664   \n",
      "1              Ridge Regression  0.134178  0.035871  0.189397  0.982092   \n",
      "10               XGBRFRegressor  0.065344  0.006837  0.082688  0.996587   \n",
      "9                  XGBRegressor  0.002442  0.000203  0.014255  0.999899   \n",
      "14                     boosting  0.008347  0.000840  0.028984  0.999581   \n",
      "7              BaggingRegressor  0.121410  0.026651  0.163252  0.986695   \n",
      "0             Linear Regression  0.073063  0.045893  0.214227  0.977088   \n",
      "12                          SVM  0.201139  0.085457  0.292331  0.957336   \n",
      "3       Decision Tree Regressor  0.003332  0.000566  0.023793  0.999717   \n",
      "13                      bagging  0.229454  0.082723  0.287615  0.958702   \n",
      "6            Adaboost Regressor  0.141346  0.031664  0.177944  0.984192   \n",
      "2              Lasso Regression  1.221889  2.354305  1.534375 -0.175361   \n",
      "15                     stacking  1.551140  4.771714  2.184425 -1.382226   \n",
      "\n",
      "     Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.002348           0.190215          0.132068          0.046563  \n",
      "5   1.000635           0.242343          0.177934          0.068764  \n",
      "4   1.011878           0.277293          0.203619          0.085598  \n",
      "11  1.015420           0.282525          0.200599          0.092713  \n",
      "1   1.022385           0.282588          0.223575          0.085932  \n",
      "10  1.004267           0.283531          0.211851          0.088786  \n",
      "9   1.000127           0.289371          0.207907          0.093918  \n",
      "14  1.000524           0.291997          0.200897          0.095163  \n",
      "7   1.016632           0.296578          0.222848          0.098731  \n",
      "0   1.028640           0.304284          0.233628          0.101723  \n",
      "12  1.053330           0.305475          0.227277          0.102939  \n",
      "3   1.000353           0.312818          0.228238          0.111627  \n",
      "13  1.051623           0.326979          0.246346          0.120573  \n",
      "6   1.019760           0.339367          0.260956          0.126598  \n",
      "2   2.469202           0.977830          0.725805          1.053014  \n",
      "15  3.977783           1.150787          0.783041          1.837372  \n",
      "fine\n",
      "Predictions for the next 12 periods (151-162) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 33.43224095 35.71014558 30.50069868\n",
      " 27.96098937 23.35208319 18.86110472 14.71293448 16.80675106 18.08840321]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.71527578  1.86111556  1.85671248  2.40115107  2.73086198  1.97683064\n",
      "  1.60922531  0.94211808  0.29208006 -0.30833884 -0.00527339  0.18023688]\n",
      "This is the 52th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Model           MAE           MSE          RMSE  \\\n",
      "8           ExtraTreesRegressor  1.563292e-15  5.948076e-30  2.438868e-15   \n",
      "5   Gradient Boosting Regressor  2.073504e-02  5.888280e-04  2.426578e-02   \n",
      "4       Random Forest Regressor  9.373104e-02  1.783698e-02  1.335552e-01   \n",
      "11                     LightGBM  9.621507e-02  2.011503e-02  1.418275e-01   \n",
      "9                  XGBRegressor  4.668909e-04  3.761290e-07  6.132936e-04   \n",
      "14                     boosting  8.006706e-04  1.349634e-05  3.673737e-03   \n",
      "10               XGBRFRegressor  6.974170e-02  7.228738e-03  8.502199e-02   \n",
      "1              Ridge Regression  1.337603e-01  3.569330e-02  1.889267e-01   \n",
      "7              BaggingRegressor  9.746590e-02  3.220167e-02  1.794482e-01   \n",
      "12                          SVM  1.987862e-01  8.451823e-02  2.907202e-01   \n",
      "6            Adaboost Regressor  1.301169e-01  2.561155e-02  1.600361e-01   \n",
      "13                      bagging  2.051223e-01  7.730591e-02  2.780394e-01   \n",
      "3       Decision Tree Regressor  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "0             Linear Regression  4.776393e-02  3.562870e-03  5.968979e-02   \n",
      "2              Lasso Regression  1.221614e+00  2.357634e+00  1.535459e+00   \n",
      "15                     stacking  1.645400e+00  5.431450e+00  2.330547e+00   \n",
      "\n",
      "         R^2   Adj R^2  Average RMSE (CV)  Average MAE (CV)  Average MSE (CV)  \n",
      "8   1.000000  1.000000           0.170090          0.120953          0.031767  \n",
      "5   0.999706  1.000367           0.218851          0.163596          0.050718  \n",
      "4   0.991095  1.011131           0.253787          0.195977          0.069878  \n",
      "11  0.989958  1.012553           0.267807          0.197451          0.075951  \n",
      "9   1.000000  1.000000           0.271972          0.195818          0.082315  \n",
      "14  0.999993  1.000008           0.279029          0.191401          0.087119  \n",
      "10  0.996391  1.004511           0.279085          0.203737          0.082298  \n",
      "1   0.982181  1.022274           0.285578          0.226181          0.086458  \n",
      "7   0.983924  1.020095           0.295766          0.219364          0.094714  \n",
      "12  0.957805  1.052744           0.295940          0.220116          0.092039  \n",
      "6   0.987214  1.015983           0.302923          0.239221          0.098829  \n",
      "13  0.961406  1.048243           0.313497          0.237027          0.107711  \n",
      "3   1.000000  1.000000           0.337194          0.243907          0.119976  \n",
      "0   0.998221  1.002223           0.345705          0.263820          0.139148  \n",
      "2  -0.177023  2.471279           0.999725          0.719982          1.038104  \n",
      "15 -1.711592  4.389490           1.319922          0.825295          2.041758  \n",
      "fine\n",
      "Predictions for the next 12 periods (152-163) using ExtraTreesRegressor:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[35.60246376 29.70124709 29.67082715 33.43224095 35.71014558 30.50069868\n",
      " 27.96098937 23.35208319 18.86110472 14.71293448 15.81659505 17.14818685]\n",
      "Predictions for the next 12 periods:\n",
      "[ 2.71527578  1.86111556  1.85671248  2.40115107  2.73086198  1.97683064\n",
      "  1.60922531  0.94211808  0.29208006 -0.30833884 -0.14859161  0.04414707]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\tensorflow\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 创建基础模型对象\n",
    "base_model_b = RandomForestRegressor()\n",
    "# 创建基础模型对象\n",
    "base_model_o = DecisionTreeRegressor()\n",
    "# 创建基础模型对象\n",
    "base_models = [\n",
    "    ('model1', DecisionTreeRegressor()),\n",
    "    ('model2', Ridge())\n",
    "]\n",
    "\n",
    "# 创建Bagging模型对象\n",
    "bagging_model = BaggingRegressor(estimator=base_model_b)\n",
    "# 创建Boosting模型对象\n",
    "boosting_model = AdaBoostRegressor(estimator=base_model_o)\n",
    "# 创建Stacking模型对象\n",
    "stacking_model = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "names = [\"Linear Regression\", \"Ridge Regression\", \"Lasso Regression\",\n",
    "         \"Decision Tree Regressor\", \"Random Forest Regressor\", \"Gradient Boosting Regressor\",\n",
    "         \"Adaboost Regressor\", \"BaggingRegressor\", \"ExtraTreesRegressor\",\n",
    "         \"XGBRegressor\", \"XGBRFRegressor\", \"LightGBM\", \"SVM\",\"bagging\", 'boosting', 'stacking']\n",
    "\n",
    "models = [LinearRegression(), Ridge(), Lasso(), DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(), GradientBoostingRegressor(),\n",
    "          AdaBoostRegressor(), BaggingRegressor(), ExtraTreesRegressor(),\n",
    "          XGBRegressor(), XGBRFRegressor(), LGBMRegressor(), SVR(),bagging_model, boosting_model, stacking_model]\n",
    "\n",
    "# 指定训练集和测试集的范围\n",
    "train_num = 1\n",
    "train_start = 12\n",
    "train_end = 100\n",
    "test_start = 101\n",
    "test_end = 151\n",
    "current_train_end = train_end\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "\n",
    "# 划分训练集和测试集\n",
    "# 获取 'num' 列对应数字为 train_start:current_train_end 范围内的行索引\n",
    "num_indices_te = X_final_data_feature_lag12.loc[(X_final_data_feature_lag12['num'] >= test_start) & (X_final_data_feature_lag12['num'] <= test_end)].index\n",
    "\n",
    "# 使用相同的行索引选择测试集特征和目标变量\n",
    "X_test = X_final_data_feature_lag12.loc[num_indices_te, X_final_data_feature_lag12.columns != 'num']\n",
    "y_test = y_final_data_feature_lag12.loc[num_indices_te, 'Hog prices']\n",
    "\n",
    "while train_end <= test_end:\n",
    "    # 打印循环次数\n",
    "    print(\"This is the {}th loop.\".format(train_num))\n",
    "    \n",
    "    # 清空评估结果列表\n",
    "    evaluation_results.clear()\n",
    "\n",
    "     # 划分训练集和测试集\n",
    "    # 获取 'num' 列对应数字为 train_start:current_train_end 范围内的行索引\n",
    "    num_indices_tr = (X_final_data_feature_lag12['num'] >= train_start) & (X_final_data_feature_lag12['num'] <= current_train_end)\n",
    "    # 获取 'num' 列对应数字为 test_start:test_end 范围内的行索引\n",
    "    num_indices_te = (X_final_data_feature_lag12['num'] >= test_start) & (X_final_data_feature_lag12['num'] <= test_end)\n",
    "    # 选择对应行索引的其他列数据作为训练集特征，同时移除 'num' 列\n",
    "    X_train_features = X_final_data_feature_lag12.drop('num', axis=1)\n",
    "#     X_train_features = X_train_features.loc[num_indices_tr]\n",
    "    X_train_features = X_train_features.loc[num_indices_tr, :]\n",
    "\n",
    "\n",
    "    # 选择对应行索引的其他列数据作为测试集特征，同时移除 'num' 列\n",
    "    X_test_features = X_final_data_feature_lag12.drop('num', axis=1)\n",
    "#     X_test_features = X_test_features.loc[num_indices_te]\n",
    "    X_test_features = X_test_features.loc[num_indices_te, :]\n",
    "    y_test = y_final_data_feature_lag12.loc[num_indices_te].drop('num', axis=1)['Hog prices']\n",
    "    y_train = y_final_data_feature_lag12.loc[num_indices_tr].drop('num', axis=1)['Hog prices']\n",
    "    \n",
    "    \n",
    "    # 初始化评估指标列表\n",
    "    MAE = []\n",
    "    MSE = []\n",
    "    RMSE = []\n",
    "    R_Square = []\n",
    "    adj_rsquared = []\n",
    "    CV = []\n",
    "    \n",
    "    def evaluate(true, predicted, variable_of_model):\n",
    "        MAE.append(mean_absolute_error(true, predicted))\n",
    "        MSE.append(mean_squared_error(true, predicted))\n",
    "        RMSE.append(np.sqrt(mean_squared_error(true, predicted)))\n",
    "        R_Square.append(variable_of_model.score(X_test_features, y_test))  # 修改此行\n",
    "        n = X_test_features.shape[0]\n",
    "        p = X_test_features.shape[1] - 1\n",
    "        adj_rsquared.append(1 - (1 - R_Square[-1]) * ((n - 1) / (n - p - 1)))\n",
    "        cv_accuracies = cross_val_score(estimator=variable_of_model, X=X_train_features, y=y_train.ravel(), cv=5, verbose=1)\n",
    "        CV.append(cv_accuracies.mean())\n",
    "\n",
    "    def print_evaluate(true, predicted):\n",
    "        mae = mean_absolute_error(true, predicted)\n",
    "        mse = mean_squared_error(true, predicted)\n",
    "        rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "        r2_square = r2_score(true, predicted)\n",
    "        n = X_test_features.shape[0]\n",
    "        p = X_test_features.shape[1] - 1\n",
    "        adj_rsquared = 1 - (1 - r2_square) * ((n - 1) / (n - p - 1))\n",
    "        print(\"MAE:\", mae)\n",
    "        print(\"MSE:\", mse)\n",
    "        print(\"RMSE:\", rmse)\n",
    "        print(\"R2 Square\", r2_square)\n",
    "        print(\"adj R Square\", adj_rsquared)\n",
    "\n",
    "\n",
    "    def fit_and_predict(name, model):\n",
    "        variable_of_model = model\n",
    "        variable_of_model.fit(X_train_features, y_train.ravel())\n",
    "        pred = variable_of_model.predict(X_test_features)\n",
    "        evaluate(y_test, pred, variable_of_model)\n",
    "\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "        mae_scores = []\n",
    "        mse_scores = []\n",
    "\n",
    "        for train_index, val_index in kf.split(X_train_features):\n",
    "            X_train_fold, X_val_fold = X_train_features.iloc[train_index], X_train_features.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "            # Check if the resulting DataFrames are empty\n",
    "            if X_train_fold.empty or X_val_fold.empty:\n",
    "                continue\n",
    "\n",
    "            variable_of_model.fit(X_train_fold, y_train_fold.ravel())\n",
    "            pred_val = variable_of_model.predict(X_val_fold)\n",
    "\n",
    "            mse = mean_squared_error(y_val_fold, pred_val)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_val_fold, pred_val)\n",
    "            cv_scores.append(rmse)\n",
    "            mae_scores.append(mae)\n",
    "            mse_scores.append(mse)\n",
    "\n",
    "        avg_rmse_cv = np.mean(cv_scores)\n",
    "        avg_mae_cv = np.mean(mae_scores)\n",
    "        avg_mse_cv = np.mean(mse_scores)\n",
    "\n",
    "        # Store the cross-validated metrics in evaluation_results list\n",
    "        evaluation_results.append({\"Model\": name, \"MAE\": MAE[-1], \"MSE\": MSE[-1], \"RMSE\": RMSE[-1], \"R^2\": R_Square[-1], \"Adj R^2\": adj_rsquared[-1], \"Average RMSE (CV)\": avg_rmse_cv, \"Average MAE (CV)\": avg_mae_cv, \"Average MSE (CV)\": avg_mse_cv})\n",
    "\n",
    "    for name, model in zip(names, models):\n",
    "        fit_and_predict(name, model)\n",
    "\n",
    "    # 创建评估结果DataFrame\n",
    "    evaluation_dataframe = pd.DataFrame(evaluation_results)\n",
    "    evaluation_dataframe = evaluation_dataframe.sort_values(\"Average RMSE (CV)\")\n",
    "    \n",
    "      # 打印评估结果DataFrame\n",
    "    print(evaluation_dataframe)\n",
    "    \n",
    "    # 找到评估结果DataFrame中最小Average RMSE (CV)对应的算法\n",
    "    best_row = evaluation_dataframe.loc[evaluation_dataframe['Average RMSE (CV)'].idxmin()]\n",
    "    best_model_name = best_row['Model']\n",
    "    best_model = models[names.index(best_model_name)]\n",
    "\n",
    "\n",
    "    # 使用最小RMSE的模型进行未来12期的预测\n",
    "    num_indices_p = (X_final_data_feature_lag12['num'] >= current_train_end + 1) & (X_final_data_feature_lag12['num'] <= current_train_end + 12)\n",
    "\n",
    "    if num_indices_p.sum() == 12:\n",
    "        future_X_features = X_final_data_feature_lag12.drop('num', axis=1)\n",
    "        future_X_features = future_X_features.loc[num_indices_p]\n",
    "        future_predictions = best_model.predict(future_X_features)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        future_predictions = []\n",
    "        current_input_sequence = X_final_data_feature_lag12_cnn[-12:].values\n",
    "        print('fine')\n",
    "\n",
    "        for _ in range(12):\n",
    "            current_input_sequence = current_input_sequence.reshape((12, 91))\n",
    "#             print(\"current_input_sequence shape:\", current_input_sequence.shape)\n",
    "            prediction = best_model.predict(current_input_sequence)\n",
    "            future_predictions.append(prediction)\n",
    "            current_input_sequence = np.roll(current_input_sequence, -1, axis=0)\n",
    "            current_input_sequence[-1] = np.squeeze(prediction)[-1]\n",
    "            prediction = np.squeeze(prediction)\n",
    "            \n",
    "\n",
    "    # 打印预测结果\n",
    "    future_predictions = np.array(best_model.predict(future_X_features))\n",
    "    mean = raw_data[\"Hog prices\"].mean()\n",
    "    std = raw_data[\"Hog prices\"].std()\n",
    "\n",
    "    # Reverse standardization and print the predictions\n",
    "    print(\"Predictions for the next 12 periods ({}-{}) using {}:\".format(current_train_end+1, current_train_end+12, best_model_name))\n",
    "    future_predictions_reversed = future_predictions * std + mean\n",
    "    print(\"Reversed Predictions for the next 12 periods:\")\n",
    "    print(future_predictions_reversed)\n",
    "    print(\"Predictions for the next 12 periods:\")\n",
    "    print(future_predictions)\n",
    "    \n",
    "\n",
    "    # 更新下一个训练集和测试集的起始和结束行数\n",
    "    current_train_end += 1\n",
    "    train_end += 1\n",
    "    train_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce51662",
   "metadata": {},
   "source": [
    "## Normal RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a4abefe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T18:28:52.634189Z",
     "start_time": "2023-07-01T18:28:52.602891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "# 去掉 'num' 列\n",
    "X_final_data_feature_lag12_cnn = X_final_data_feature_lag12.drop('num', axis=1)\n",
    "y_final_data_feature_lag12_cnn = y_final_data_feature_lag12.drop('num', axis=1)\n",
    "\n",
    "\n",
    "# 将 DataFrame 转换为 numpy 数组\n",
    "data_array = X_final_data_feature_lag12_cnn.values\n",
    "\n",
    "# 将数据重新塑造为 LSTM 模型的输入格式\n",
    "# 假设每个样本有 12 个时间步，特征数为 8\n",
    "time_steps = 12\n",
    "num_features = 91 #特征变量\n",
    "\n",
    "# 计算样本数量\n",
    "num_samples = len(data_array) - time_steps + 1\n",
    "\n",
    "# 初始化输入数据数组\n",
    "X_lstm = np.zeros((num_samples, time_steps, num_features))\n",
    "\n",
    "# 填充输入数据数组\n",
    "for i in range(num_samples):\n",
    "    X_lstm[i] = data_array[i:i+time_steps]\n",
    "\n",
    "# X_lstm 现在是符合 LSTM 模型输入格式的数据\n",
    "\n",
    "print(len(X_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e0a97e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T06:34:53.932798Z",
     "start_time": "2023-07-02T06:28:01.830014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 1th loop.\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Average RMSE (CV) 0.0937254250494971\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predictions for the next 12 periods (101-112) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[ 9.119696]\n",
      " [11.002014]\n",
      " [12.694689]\n",
      " [13.14573 ]\n",
      " [11.812584]\n",
      " [11.706816]\n",
      " [12.035307]\n",
      " [12.299135]\n",
      " [11.368427]\n",
      " [ 9.777324]\n",
      " [ 9.06897 ]\n",
      " [ 8.855903]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-1.1179214 ]\n",
      " [-0.8454688 ]\n",
      " [-0.6004659 ]\n",
      " [-0.53518075]\n",
      " [-0.72814435]\n",
      " [-0.74345356]\n",
      " [-0.6959068 ]\n",
      " [-0.6577196 ]\n",
      " [-0.7924331 ]\n",
      " [-1.0227343 ]\n",
      " [-1.1252637 ]\n",
      " [-1.1561036 ]]\n",
      "This is the 2th loop.\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Average RMSE (CV) 0.09511083630489199\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predictions for the next 12 periods (102-113) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[11.448385]\n",
      " [12.959856]\n",
      " [12.866734]\n",
      " [11.833872]\n",
      " [11.573333]\n",
      " [11.860804]\n",
      " [12.333355]\n",
      " [11.296818]\n",
      " [ 9.93763 ]\n",
      " [10.27136 ]\n",
      " [10.744361]\n",
      " [11.22483 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.7808596 ]\n",
      " [-0.5620847 ]\n",
      " [-0.5755636 ]\n",
      " [-0.72506315]\n",
      " [-0.7627744 ]\n",
      " [-0.72116506]\n",
      " [-0.6527664 ]\n",
      " [-0.802798  ]\n",
      " [-0.9995311 ]\n",
      " [-0.9512258 ]\n",
      " [-0.8827623 ]\n",
      " [-0.8132178 ]]\n",
      "This is the 3th loop.\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Average RMSE (CV) 0.07567501224924672\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predictions for the next 12 periods (103-114) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[12.738396 ]\n",
      " [12.972016 ]\n",
      " [12.042176 ]\n",
      " [12.153454 ]\n",
      " [12.574778 ]\n",
      " [13.15761  ]\n",
      " [12.097292 ]\n",
      " [10.379189 ]\n",
      " [ 9.830328 ]\n",
      " [10.1865835]\n",
      " [10.467899 ]\n",
      " [10.93512  ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.5941395 ]\n",
      " [-0.56032467]\n",
      " [-0.69491255]\n",
      " [-0.6788059 ]\n",
      " [-0.6178223 ]\n",
      " [-0.5334612 ]\n",
      " [-0.6869349 ]\n",
      " [-0.9356185 ]\n",
      " [-1.0150622 ]\n",
      " [-0.96349674]\n",
      " [-0.92277825]\n",
      " [-0.85515136]]\n",
      "This is the 4th loop.\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Average RMSE (CV) 0.10822533389304083\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predictions for the next 12 periods (104-115) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[13.230516 ]\n",
      " [12.023728 ]\n",
      " [11.50309  ]\n",
      " [11.986862 ]\n",
      " [12.59255  ]\n",
      " [11.90626  ]\n",
      " [10.778151 ]\n",
      " [10.994129 ]\n",
      " [11.205437 ]\n",
      " [11.560962 ]\n",
      " [11.8883705]\n",
      " [12.786486 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.5229085 ]\n",
      " [-0.6975828 ]\n",
      " [-0.7729415 ]\n",
      " [-0.7029189 ]\n",
      " [-0.6152498 ]\n",
      " [-0.71458554]\n",
      " [-0.87787145]\n",
      " [-0.84661007]\n",
      " [-0.81602484]\n",
      " [-0.764565  ]\n",
      " [-0.7171748 ]\n",
      " [-0.5871789 ]]\n",
      "This is the 5th loop.\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Average RMSE (CV) 0.10237145910408327\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predictions for the next 12 periods (105-116) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[13.129246 ]\n",
      " [12.729572 ]\n",
      " [13.111431 ]\n",
      " [13.285295 ]\n",
      " [12.2627735]\n",
      " [11.06988  ]\n",
      " [11.325436 ]\n",
      " [12.023126 ]\n",
      " [12.790292 ]\n",
      " [13.417103 ]\n",
      " [14.140066 ]\n",
      " [13.918778 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.5375667 ]\n",
      " [-0.5954167 ]\n",
      " [-0.54014534]\n",
      " [-0.5149798 ]\n",
      " [-0.6629825 ]\n",
      " [-0.83564574]\n",
      " [-0.7986557 ]\n",
      " [-0.69767   ]\n",
      " [-0.586628  ]\n",
      " [-0.49590138]\n",
      " [-0.39125744]\n",
      " [-0.42328742]]\n",
      "This is the 6th loop.\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Average RMSE (CV) 0.08283207026402124\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predictions for the next 12 periods (106-117) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[12.801657 ]\n",
      " [13.120328 ]\n",
      " [13.691782 ]\n",
      " [12.6589985]\n",
      " [11.735411 ]\n",
      " [11.571812 ]\n",
      " [12.167329 ]\n",
      " [12.485678 ]\n",
      " [13.189262 ]\n",
      " [13.58898  ]\n",
      " [12.985807 ]\n",
      " [11.710083 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.584983  ]\n",
      " [-0.5388576 ]\n",
      " [-0.45614356]\n",
      " [-0.6056317 ]\n",
      " [-0.7393148 ]\n",
      " [-0.7629946 ]\n",
      " [-0.67679757]\n",
      " [-0.6307187 ]\n",
      " [-0.5288797 ]\n",
      " [-0.4710235 ]\n",
      " [-0.5583285 ]\n",
      " [-0.7429808 ]]\n",
      "This is the 7th loop.\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Average RMSE (CV) 0.08859974338603396\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predictions for the next 12 periods (107-118) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[12.821564]\n",
      " [13.283847]\n",
      " [12.129021]\n",
      " [10.792429]\n",
      " [10.781336]\n",
      " [11.25315 ]\n",
      " [11.956629]\n",
      " [12.752672]\n",
      " [13.414891]\n",
      " [12.665638]\n",
      " [10.797816]\n",
      " [ 9.005068]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.5821016 ]\n",
      " [-0.5151893 ]\n",
      " [-0.6823424 ]\n",
      " [-0.8758048 ]\n",
      " [-0.87741053]\n",
      " [-0.8091186 ]\n",
      " [-0.70729494]\n",
      " [-0.5920731 ]\n",
      " [-0.49622157]\n",
      " [-0.60467076]\n",
      " [-0.87502503]\n",
      " [-1.1345129 ]]\n",
      "This is the 8th loop.\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Average RMSE (CV) 0.06107003325275249\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predictions for the next 12 periods (108-119) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[13.036881 ]\n",
      " [11.87808  ]\n",
      " [10.823342 ]\n",
      " [11.104791 ]\n",
      " [11.493795 ]\n",
      " [11.96139  ]\n",
      " [11.993227 ]\n",
      " [11.794622 ]\n",
      " [10.853815 ]\n",
      " [ 8.734673 ]\n",
      " [ 6.2558746]\n",
      " [ 5.3068857]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.55093586]\n",
      " [-0.71866435]\n",
      " [-0.8713303 ]\n",
      " [-0.83059263]\n",
      " [-0.7742869 ]\n",
      " [-0.70660585]\n",
      " [-0.7019975 ]\n",
      " [-0.7307442 ]\n",
      " [-0.8669196 ]\n",
      " [-1.1736507 ]\n",
      " [-1.5324396 ]\n",
      " [-1.6697992 ]]\n",
      "This is the 9th loop.\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Average RMSE (CV) 0.06955887356229404\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predictions for the next 12 periods (109-120) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[11.163359 ]\n",
      " [10.281265 ]\n",
      " [10.589956 ]\n",
      " [11.195885 ]\n",
      " [11.658428 ]\n",
      " [11.709284 ]\n",
      " [11.668225 ]\n",
      " [10.550648 ]\n",
      " [ 8.162601 ]\n",
      " [ 6.181834 ]\n",
      " [ 4.7699623]\n",
      " [ 1.9624443]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.82211524]\n",
      " [-0.94979215]\n",
      " [-0.9051114 ]\n",
      " [-0.8174075 ]\n",
      " [-0.7504575 ]\n",
      " [-0.7430965 ]\n",
      " [-0.74903935]\n",
      " [-0.91080105]\n",
      " [-1.2564541 ]\n",
      " [-1.5431565 ]\n",
      " [-1.7475152 ]\n",
      " [-2.153884  ]]\n",
      "This is the 10th loop.\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Average RMSE (CV) 0.06413750651985183\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predictions for the next 12 periods (110-121) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[11.039652 ]\n",
      " [11.580814 ]\n",
      " [12.064535 ]\n",
      " [12.70285  ]\n",
      " [13.308962 ]\n",
      " [13.698506 ]\n",
      " [12.913635 ]\n",
      " [11.19199  ]\n",
      " [ 9.318989 ]\n",
      " [ 8.440991 ]\n",
      " [ 6.021641 ]\n",
      " [ 2.8241892]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.84002095]\n",
      " [-0.76169145]\n",
      " [-0.6916763 ]\n",
      " [-0.59928447]\n",
      " [-0.51155406]\n",
      " [-0.45517024]\n",
      " [-0.56877494]\n",
      " [-0.8179712 ]\n",
      " [-1.089075  ]\n",
      " [-1.2161591 ]\n",
      " [-1.5663434 ]\n",
      " [-2.0291524 ]]\n",
      "This is the 11th loop.\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Average RMSE (CV) 0.07960867779083494\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predictions for the next 12 periods (111-122) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[13.166469 ]\n",
      " [13.614844 ]\n",
      " [14.5058975]\n",
      " [15.218519 ]\n",
      " [16.379974 ]\n",
      " [16.601204 ]\n",
      " [14.931903 ]\n",
      " [13.028887 ]\n",
      " [12.551577 ]\n",
      " [10.016471 ]\n",
      " [ 7.2144566]\n",
      " [ 4.0275965]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.532179  ]\n",
      " [-0.46727976]\n",
      " [-0.33830592]\n",
      " [-0.23515885]\n",
      " [-0.06704644]\n",
      " [-0.03502474]\n",
      " [-0.27664462]\n",
      " [-0.552093  ]\n",
      " [-0.6211804 ]\n",
      " [-0.98811936]\n",
      " [-1.3936915 ]\n",
      " [-1.8549675 ]]\n",
      "This is the 12th loop.\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Average RMSE (CV) 0.08264593780908754\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predictions for the next 12 periods (112-123) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[15.227646]\n",
      " [15.876618]\n",
      " [16.84881 ]\n",
      " [17.797592]\n",
      " [18.509106]\n",
      " [17.493002]\n",
      " [16.278826]\n",
      " [16.02075 ]\n",
      " [14.366525]\n",
      " [11.08815 ]\n",
      " [ 8.237646]\n",
      " [ 4.561898]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-2.3383784e-01]\n",
      " [-1.3990355e-01]\n",
      " [ 8.1443461e-04]\n",
      " [ 1.3814402e-01]\n",
      " [ 2.4113083e-01]\n",
      " [ 9.4056726e-02]\n",
      " [-8.1686854e-02]\n",
      " [-1.1904144e-01]\n",
      " [-3.5847926e-01]\n",
      " [-8.3300120e-01]\n",
      " [-1.2455920e+00]\n",
      " [-1.7776310e+00]]\n",
      "This is the 13th loop.\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Average RMSE (CV) 0.08705509316222601\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predictions for the next 12 periods (113-124) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[15.523794 ]\n",
      " [16.286737 ]\n",
      " [17.67369  ]\n",
      " [18.000751 ]\n",
      " [16.561457 ]\n",
      " [15.548909 ]\n",
      " [15.165286 ]\n",
      " [13.944248 ]\n",
      " [10.596123 ]\n",
      " [ 7.1625967]\n",
      " [ 4.1803904]\n",
      " [ 3.878811 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.19097242]\n",
      " [-0.08054165]\n",
      " [ 0.12021013]\n",
      " [ 0.16754988]\n",
      " [-0.04077796]\n",
      " [-0.18733725]\n",
      " [-0.24286398]\n",
      " [-0.4196008 ]\n",
      " [-0.9042188 ]\n",
      " [-1.4011979 ]\n",
      " [-1.8328516 ]\n",
      " [-1.8765031 ]]\n",
      "This is the 14th loop.\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Average RMSE (CV) 0.11728305932271268\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predictions for the next 12 periods (114-125) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[16.702564 ]\n",
      " [18.475456 ]\n",
      " [19.275433 ]\n",
      " [18.194258 ]\n",
      " [16.672512 ]\n",
      " [15.396533 ]\n",
      " [12.743555 ]\n",
      " [ 7.8299875]\n",
      " [ 3.1736727]\n",
      " [-1.8814201]\n",
      " [-4.810711 ]\n",
      " [-7.15267  ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.02035379]\n",
      " [ 0.23626031]\n",
      " [ 0.3520512 ]\n",
      " [ 0.19555874]\n",
      " [-0.02470355]\n",
      " [-0.20939259]\n",
      " [-0.5933927 ]\n",
      " [-1.3045977 ]\n",
      " [-1.978567  ]\n",
      " [-2.7102568 ]\n",
      " [-3.1342514 ]\n",
      " [-3.4732337 ]]\n",
      "This is the 15th loop.\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Average RMSE (CV) 0.1226725467132435\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predictions for the next 12 periods (115-126) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[19.839422  ]\n",
      " [20.608921  ]\n",
      " [20.029015  ]\n",
      " [18.824963  ]\n",
      " [18.216019  ]\n",
      " [15.9988165 ]\n",
      " [11.808271  ]\n",
      " [ 7.812169  ]\n",
      " [ 3.5268698 ]\n",
      " [ 0.9862976 ]\n",
      " [-0.74422264]\n",
      " [-1.4811954 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 0.4336847 ]\n",
      " [ 0.54506445]\n",
      " [ 0.46112704]\n",
      " [ 0.2868489 ]\n",
      " [ 0.19870828]\n",
      " [-0.12221623]\n",
      " [-0.7287687 ]\n",
      " [-1.3071768 ]\n",
      " [-1.9274442 ]\n",
      " [-2.2951744 ]\n",
      " [-2.5456553 ]\n",
      " [-2.652327  ]]\n",
      "This is the 16th loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Average RMSE (CV) 0.11104391273972194\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Predictions for the next 12 periods (116-127) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[24.012732 ]\n",
      " [23.970896 ]\n",
      " [22.657131 ]\n",
      " [22.61872  ]\n",
      " [21.207512 ]\n",
      " [17.484068 ]\n",
      " [13.918627 ]\n",
      " [ 9.13318  ]\n",
      " [ 6.532401 ]\n",
      " [ 5.396202 ]\n",
      " [ 5.2347403]\n",
      " [ 7.048357 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 1.0377424 ]\n",
      " [ 1.031687  ]\n",
      " [ 0.84152853]\n",
      " [ 0.83596885]\n",
      " [ 0.6317063 ]\n",
      " [ 0.09276369]\n",
      " [-0.42330942]\n",
      " [-1.1159697 ]\n",
      " [-1.4924144 ]\n",
      " [-1.6568713 ]\n",
      " [-1.6802418 ]\n",
      " [-1.4177333 ]]\n",
      "This is the 17th loop.\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Average RMSE (CV) 0.11024542587227959\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predictions for the next 12 periods (117-128) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[27.854239 ]\n",
      " [26.873936 ]\n",
      " [26.12857  ]\n",
      " [24.858143 ]\n",
      " [22.782516 ]\n",
      " [20.319147 ]\n",
      " [14.960444 ]\n",
      " [10.924453 ]\n",
      " [ 7.7784147]\n",
      " [ 7.937462 ]\n",
      " [11.176273 ]\n",
      " [12.099249 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 1.593774  ]\n",
      " [ 1.4518818 ]\n",
      " [ 1.3439956 ]\n",
      " [ 1.1601099 ]\n",
      " [ 0.8596773 ]\n",
      " [ 0.5031216 ]\n",
      " [-0.27251345]\n",
      " [-0.8566953 ]\n",
      " [-1.3120625 ]\n",
      " [-1.2890415 ]\n",
      " [-0.82024604]\n",
      " [-0.6866516 ]]\n",
      "This is the 18th loop.\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Average RMSE (CV) 0.13668012175185473\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predictions for the next 12 periods (118-129) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[37.551163]\n",
      " [38.38468 ]\n",
      " [35.511856]\n",
      " [36.046787]\n",
      " [34.989235]\n",
      " [33.07534 ]\n",
      " [27.881128]\n",
      " [22.33994 ]\n",
      " [19.860355]\n",
      " [22.711084]\n",
      " [23.997864]\n",
      " [15.232214]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.9973369 ]\n",
      " [ 3.1179824 ]\n",
      " [ 2.7021613 ]\n",
      " [ 2.7795887 ]\n",
      " [ 2.6265152 ]\n",
      " [ 2.349492  ]\n",
      " [ 1.597666  ]\n",
      " [ 0.79561734]\n",
      " [ 0.4367148 ]\n",
      " [ 0.84933805]\n",
      " [ 1.0355904 ]\n",
      " [-0.23317668]]\n",
      "This is the 19th loop.\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Average RMSE (CV) 0.14514431419073257\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Predictions for the next 12 periods (119-130) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[36.2305  ]\n",
      " [36.44053 ]\n",
      " [37.86115 ]\n",
      " [38.416843]\n",
      " [34.920105]\n",
      " [30.830883]\n",
      " [26.614477]\n",
      " [25.996267]\n",
      " [29.043285]\n",
      " [29.986801]\n",
      " [23.67092 ]\n",
      " [14.406066]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.8061795 ]\n",
      " [ 2.83658   ]\n",
      " [ 3.0422049 ]\n",
      " [ 3.1226377 ]\n",
      " [ 2.616509  ]\n",
      " [ 2.0246224 ]\n",
      " [ 1.4143271 ]\n",
      " [ 1.3248456 ]\n",
      " [ 1.7658801 ]\n",
      " [ 1.9024477 ]\n",
      " [ 0.9882674 ]\n",
      " [-0.35275584]]\n",
      "This is the 20th loop.\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Average RMSE (CV) 0.15770766631235592\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predictions for the next 12 periods (120-131) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[ 32.321674 ]\n",
      " [ 29.850632 ]\n",
      " [ 27.035954 ]\n",
      " [ 21.902737 ]\n",
      " [ 15.267065 ]\n",
      " [  8.881477 ]\n",
      " [  2.873476 ]\n",
      " [  1.5296249]\n",
      " [ -1.9294338]\n",
      " [ -7.8729076]\n",
      " [-18.56602  ]\n",
      " [-26.400553 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.2404044 ]\n",
      " [ 1.8827382 ]\n",
      " [ 1.475333  ]\n",
      " [ 0.7323353 ]\n",
      " [-0.22813223]\n",
      " [-1.1524019 ]\n",
      " [-2.0220184 ]\n",
      " [-2.2165315 ]\n",
      " [-2.7172062 ]\n",
      " [-3.577483  ]\n",
      " [-5.125237  ]\n",
      " [-6.259231  ]]\n",
      "This is the 21th loop.\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Average RMSE (CV) 0.14202970340623172\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Predictions for the next 12 periods (121-132) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[34.73995 ]\n",
      " [35.46582 ]\n",
      " [32.508415]\n",
      " [29.688225]\n",
      " [26.354801]\n",
      " [25.140203]\n",
      " [26.965246]\n",
      " [28.374287]\n",
      " [26.462694]\n",
      " [18.916664]\n",
      " [12.271836]\n",
      " [13.330027]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.5904326 ]\n",
      " [ 2.695498  ]\n",
      " [ 2.2674336 ]\n",
      " [ 1.8592306 ]\n",
      " [ 1.3767406 ]\n",
      " [ 1.2009362 ]\n",
      " [ 1.4650985 ]\n",
      " [ 1.6690471 ]\n",
      " [ 1.3923576 ]\n",
      " [ 0.30012202]\n",
      " [-0.66167086]\n",
      " [-0.50850505]]\n",
      "This is the 22th loop.\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Average RMSE (CV) 0.15933379674547776\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predictions for the next 12 periods (122-133) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[36.429012 ]\n",
      " [34.411026 ]\n",
      " [31.298973 ]\n",
      " [28.373629 ]\n",
      " [27.8409   ]\n",
      " [29.13758  ]\n",
      " [29.17751  ]\n",
      " [25.677471 ]\n",
      " [17.787897 ]\n",
      " [12.307241 ]\n",
      " [11.1512375]\n",
      " [ 9.131287 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.834913  ]\n",
      " [ 2.5428238 ]\n",
      " [ 2.0923753 ]\n",
      " [ 1.6689521 ]\n",
      " [ 1.5918434 ]\n",
      " [ 1.7795287 ]\n",
      " [ 1.7853082 ]\n",
      " [ 1.2787018 ]\n",
      " [ 0.1367408 ]\n",
      " [-0.65654624]\n",
      " [-0.8238697 ]\n",
      " [-1.1162436 ]]\n",
      "This is the 23th loop.\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Average RMSE (CV) 0.1566755279845295\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Predictions for the next 12 periods (123-134) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[31.929455 ]\n",
      " [27.9113   ]\n",
      " [23.832844 ]\n",
      " [24.22955  ]\n",
      " [24.839245 ]\n",
      " [24.534416 ]\n",
      " [19.984093 ]\n",
      " [15.029681 ]\n",
      " [10.883347 ]\n",
      " [11.184887 ]\n",
      " [ 9.236919 ]\n",
      " [ 1.8417349]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.1836333 ]\n",
      " [ 1.6020331 ]\n",
      " [ 1.0117048 ]\n",
      " [ 1.0691252 ]\n",
      " [ 1.1573746 ]\n",
      " [ 1.1132526 ]\n",
      " [ 0.4546248 ]\n",
      " [-0.2624919 ]\n",
      " [-0.86264515]\n",
      " [-0.81899923]\n",
      " [-1.100954  ]\n",
      " [-2.1713557 ]]\n",
      "This is the 24th loop.\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Average RMSE (CV) 0.1523063876720474\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predictions for the next 12 periods (124-135) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[27.602444]\n",
      " [24.493643]\n",
      " [24.208185]\n",
      " [24.397068]\n",
      " [21.973866]\n",
      " [18.323887]\n",
      " [12.20512 ]\n",
      " [ 9.470026]\n",
      " [ 9.333831]\n",
      " [ 7.43526 ]\n",
      " [ 1.351018]\n",
      " [-6.17449 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 1.5573283 ]\n",
      " [ 1.1073511 ]\n",
      " [ 1.066033  ]\n",
      " [ 1.0933726 ]\n",
      " [ 0.74263066]\n",
      " [ 0.21432166]\n",
      " [-0.67132765]\n",
      " [-1.0672134 ]\n",
      " [-1.0869268 ]\n",
      " [-1.3617318 ]\n",
      " [-2.2423837 ]\n",
      " [-3.3316488 ]]\n",
      "This is the 25th loop.\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Average RMSE (CV) 0.18592190535686226\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predictions for the next 12 periods (125-136) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[ 22.349699  ]\n",
      " [ 21.533554  ]\n",
      " [ 22.088512  ]\n",
      " [ 20.821318  ]\n",
      " [ 17.166698  ]\n",
      " [ 11.035852  ]\n",
      " [  6.8933325 ]\n",
      " [  6.8703213 ]\n",
      " [  5.037898  ]\n",
      " [ -0.40376854]\n",
      " [ -8.961163  ]\n",
      " [-14.275976  ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 0.79703003]\n",
      " [ 0.67889875]\n",
      " [ 0.75922495]\n",
      " [ 0.5758073 ]\n",
      " [ 0.04682659]\n",
      " [-0.84057105]\n",
      " [-1.440172  ]\n",
      " [-1.4435028 ]\n",
      " [-1.7087333 ]\n",
      " [-2.4963768 ]\n",
      " [-3.7350004 ]\n",
      " [-4.504283  ]]\n",
      "This is the 26th loop.\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Average RMSE (CV) 0.1545084540017312\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predictions for the next 12 periods (126-137) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[35.76052 ]\n",
      " [37.586914]\n",
      " [36.93707 ]\n",
      " [34.93946 ]\n",
      " [34.222733]\n",
      " [33.76886 ]\n",
      " [32.879425]\n",
      " [30.137375]\n",
      " [26.453419]\n",
      " [23.628012]\n",
      " [20.598085]\n",
      " [20.659763]]\n",
      "Predictions for the next 12 periods:\n",
      "[[2.738154 ]\n",
      " [3.002511 ]\n",
      " [2.9084508]\n",
      " [2.6193104]\n",
      " [2.5155694]\n",
      " [2.4498746]\n",
      " [2.321135 ]\n",
      " [1.924242 ]\n",
      " [1.391015 ]\n",
      " [0.9820568]\n",
      " [0.5434961]\n",
      " [0.5524234]]\n",
      "This is the 27th loop.\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Average RMSE (CV) 0.15103823251346576\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predictions for the next 12 periods (127-138) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[42.00944 ]\n",
      " [42.56892 ]\n",
      " [39.46824 ]\n",
      " [36.81582 ]\n",
      " [37.26346 ]\n",
      " [39.165863]\n",
      " [38.31275 ]\n",
      " [31.129335]\n",
      " [24.6532  ]\n",
      " [21.657011]\n",
      " [21.844046]\n",
      " [24.956026]]\n",
      "Predictions for the next 12 periods:\n",
      "[[3.6426415]\n",
      " [3.7236223]\n",
      " [3.2748199]\n",
      " [2.8909006]\n",
      " [2.9556937]\n",
      " [3.2310529]\n",
      " [3.1075716]\n",
      " [2.0678215]\n",
      " [1.1304458]\n",
      " [0.6967682]\n",
      " [0.7238401]\n",
      " [1.1742778]]\n",
      "This is the 28th loop.\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Average RMSE (CV) 0.1776948378152607\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predictions for the next 12 periods (128-139) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[32.6232   ]\n",
      " [28.930443 ]\n",
      " [25.92392  ]\n",
      " [25.670744 ]\n",
      " [24.1127   ]\n",
      " [20.056293 ]\n",
      " [15.761538 ]\n",
      " [11.405687 ]\n",
      " [ 6.5406475]\n",
      " [ 4.0636883]\n",
      " [ 4.0508785]\n",
      " [ 0.941967 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.284048  ]\n",
      " [ 1.749547  ]\n",
      " [ 1.3143739 ]\n",
      " [ 1.2777282 ]\n",
      " [ 1.0522121 ]\n",
      " [ 0.46507555]\n",
      " [-0.1565607 ]\n",
      " [-0.7870398 ]\n",
      " [-1.4912207 ]\n",
      " [-1.8497435 ]\n",
      " [-1.8515975 ]\n",
      " [-2.301591  ]]\n",
      "This is the 29th loop.\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Average RMSE (CV) 0.15546336808488237\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predictions for the next 12 periods (129-140) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[31.029903]\n",
      " [29.484758]\n",
      " [29.754639]\n",
      " [30.402628]\n",
      " [27.178955]\n",
      " [21.740053]\n",
      " [16.593658]\n",
      " [15.180484]\n",
      " [14.392651]\n",
      " [14.727482]\n",
      " [12.009591]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.0534294 ]\n",
      " [ 1.8297805 ]\n",
      " [ 1.8688439 ]\n",
      " [ 1.9626356 ]\n",
      " [ 1.4960312 ]\n",
      " [ 0.7087879 ]\n",
      " [-0.0361169 ]\n",
      " [-0.24066423]\n",
      " [-0.35469773]\n",
      " [-0.3062331 ]\n",
      " [-0.699629  ]]\n",
      "This is the 30th loop.\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Average RMSE (CV) 0.14848432919086912\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predictions for the next 12 periods (130-141) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[27.518621 ]\n",
      " [26.997086 ]\n",
      " [25.138027 ]\n",
      " [22.223179 ]\n",
      " [16.986513 ]\n",
      " [11.694117 ]\n",
      " [ 8.0734625]\n",
      " [ 6.417555 ]\n",
      " [ 6.5097084]\n",
      " [ 3.7055597]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 1.5451957 ]\n",
      " [ 1.4697069 ]\n",
      " [ 1.2006211 ]\n",
      " [ 0.7787171 ]\n",
      " [ 0.02074587]\n",
      " [-0.7452917 ]\n",
      " [-1.2693564 ]\n",
      " [-1.5090375 ]\n",
      " [-1.4956989 ]\n",
      " [-1.9015801 ]]\n",
      "This is the 31th loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Average RMSE (CV) 0.14385719397111144\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predictions for the next 12 periods (131-142) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[29.396473]\n",
      " [30.46563 ]\n",
      " [26.810184]\n",
      " [20.485954]\n",
      " [16.61027 ]\n",
      " [15.024834]\n",
      " [16.43293 ]\n",
      " [18.078302]\n",
      " [15.133411]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 1.8170016 ]\n",
      " [ 1.9717548 ]\n",
      " [ 1.4426543 ]\n",
      " [ 0.52726597]\n",
      " [-0.0337128 ]\n",
      " [-0.26319355]\n",
      " [-0.05938142]\n",
      " [ 0.17877501]\n",
      " [-0.24747771]]\n",
      "This is the 32th loop.\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Average RMSE (CV) 0.16473879351797055\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predictions for the next 12 periods (132-143) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[32.953186]\n",
      " [28.834602]\n",
      " [22.64302 ]\n",
      " [18.18862 ]\n",
      " [18.258377]\n",
      " [19.225235]\n",
      " [19.780128]\n",
      " [15.856249]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.3318117 ]\n",
      " [ 1.7356746 ]\n",
      " [ 0.8394863 ]\n",
      " [ 0.19474255]\n",
      " [ 0.2048394 ]\n",
      " [ 0.34478545]\n",
      " [ 0.4251026 ]\n",
      " [-0.14285202]]\n",
      "This is the 33th loop.\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Average RMSE (CV) 0.19337168498998772\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predictions for the next 12 periods (133-144) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[31.144855]\n",
      " [24.357426]\n",
      " [19.247557]\n",
      " [17.911585]\n",
      " [17.717049]\n",
      " [18.928238]\n",
      " [15.95606 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 2.070068  ]\n",
      " [ 1.0876344 ]\n",
      " [ 0.34801635]\n",
      " [ 0.15464374]\n",
      " [ 0.12648594]\n",
      " [ 0.30179712]\n",
      " [-0.12840492]]\n",
      "This is the 34th loop.\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Average RMSE (CV) 0.16089274703753798\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Predictions for the next 12 periods (134-145) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[26.082043]\n",
      " [21.274809]\n",
      " [20.129017]\n",
      " [20.597544]\n",
      " [20.553596]\n",
      " [17.041622]]\n",
      "Predictions for the next 12 periods:\n",
      "[[1.337261  ]\n",
      " [0.641447  ]\n",
      " [0.47560155]\n",
      " [0.54341763]\n",
      " [0.5370565 ]\n",
      " [0.02872274]]\n",
      "This is the 35th loop.\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Average RMSE (CV) 0.1706994718325933\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predictions for the next 12 periods (135-146) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[25.511227]\n",
      " [24.45293 ]\n",
      " [24.404142]\n",
      " [24.479532]\n",
      " [20.984114]]\n",
      "Predictions for the next 12 periods:\n",
      "[[1.2546393]\n",
      " [1.1014581]\n",
      " [1.0943965]\n",
      " [1.1053085]\n",
      " [0.599371 ]]\n",
      "This is the 36th loop.\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Average RMSE (CV) 0.1392420424587198\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predictions for the next 12 periods (136-147) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[21.23938 ]\n",
      " [21.737488]\n",
      " [21.005028]\n",
      " [18.239664]]\n",
      "Predictions for the next 12 periods:\n",
      "[[0.63631886]\n",
      " [0.7084165 ]\n",
      " [0.6023983 ]\n",
      " [0.20213099]]\n",
      "This is the 37th loop.\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Average RMSE (CV) 0.17730374177749664\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Predictions for the next 12 periods (137-148) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[18.673262]\n",
      " [18.576302]\n",
      " [16.139431]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 0.26489106]\n",
      " [ 0.25085676]\n",
      " [-0.10186328]]\n",
      "This is the 38th loop.\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Average RMSE (CV) 0.16192359980640975\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Predictions for the next 12 periods (138-149) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[14.341993]\n",
      " [12.689819]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.36203003]\n",
      " [-0.6011708 ]]\n",
      "This is the 39th loop.\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Average RMSE (CV) 0.15755458732507216\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predictions for the next 12 periods (139-150) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[13.127069]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.5378818]]\n",
      "This is the 40th loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Average RMSE (CV) 0.21362262399086768\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[283], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m future_X \u001b[38;5;241m=\u001b[39m X_final_data_feature_lag12_cnn\u001b[38;5;241m.\u001b[39miloc[train_end:train_end\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m12\u001b[39m, :]\n\u001b[0;32m     65\u001b[0m future_X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(future_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m future_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# 将预测结果添加到evaluation_results中\u001b[39;00m\n\u001b[0;32m     69\u001b[0m evaluation_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m: future_predictions\n\u001b[0;32m     72\u001b[0m })\n",
      "File \u001b[1;32mD:\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:2278\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2274\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(\n\u001b[0;32m   2275\u001b[0m                     end_step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs}\n\u001b[0;32m   2276\u001b[0m                 )\n\u001b[0;32m   2277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected result of `predict_function` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2280\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Empty batch_outputs). Please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2281\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2282\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2284\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2285\u001b[0m         )\n\u001b[0;32m   2286\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[0;32m   2287\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure_up_to(\n\u001b[0;32m   2288\u001b[0m     batch_outputs, potentially_ragged_concat, outputs\n\u001b[0;32m   2289\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# 获取数据集，假设您已经将数据加载到X_final_data_feature_lag12和y_final_data_feature_lag12中\n",
    "\n",
    "# 定义训练集和测试集的起始和结束行数\n",
    "train_start = 12\n",
    "train_end = 100\n",
    "test_start = 101\n",
    "test_end = 151\n",
    "\n",
    "# 创建空列表存储评估结果\n",
    "evaluation_results = []\n",
    "\n",
    "\n",
    "# 循环训练和预测过程\n",
    "while train_end <= test_end:\n",
    "    # 打印循环次数\n",
    "    print(\"This is the {}th loop.\".format(train_start - 11))\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train = X_final_data_feature_lag12_cnn.iloc[train_start:train_end, :]\n",
    "    y_train = y_final_data_feature_lag12_cnn.iloc[train_start:train_end, :]\n",
    "    X_test = X_final_data_feature_lag12_cnn.iloc[test_start:test_end, :]\n",
    "    y_test = y_final_data_feature_lag12_cnn.iloc[test_start:test_end, :]\n",
    "\n",
    "    # 构建CNN模型\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # 将训练集和测试集转换为3D张量（样本数，时间步数，特征数）\n",
    "    X_train = np.expand_dims(X_train, axis=2)\n",
    "    X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "    # 10折交叉验证\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_scores = []\n",
    "\n",
    "    for train_index, val_index in kfold.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # 拟合模型\n",
    "        model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "        # 在验证集上进行预测\n",
    "        val_predictions = model.predict(X_val_fold)\n",
    "\n",
    "        # 计算验证集的MAE得分\n",
    "        fold_score = mean_absolute_error(y_val_fold, val_predictions)\n",
    "        cv_scores.append(fold_score)\n",
    "\n",
    "    # 打印交叉验证的平均RMSE得分\n",
    "    print('Average RMSE (CV)', np.mean(cv_scores))\n",
    "\n",
    "    # 预测未来12期\n",
    "    future_X = X_final_data_feature_lag12_cnn.iloc[train_end:train_end+12, :]\n",
    "    future_X = np.expand_dims(future_X, axis=2)\n",
    "    future_predictions = model.predict(future_X)\n",
    "\n",
    "    # 将预测结果添加到evaluation_results中\n",
    "    evaluation_results.append({\n",
    "        \"Model\": \"CNN\",\n",
    "        \"Predictions\": future_predictions\n",
    "    })\n",
    "    \n",
    "    mean = raw_data[\"Hog prices\"].mean()\n",
    "    std = raw_data[\"Hog prices\"].std()\n",
    "\n",
    "    # 打印预测结果\n",
    "    # Reverse standardization and print the predictions\n",
    "    print(\"Predictions for the next 12 periods ({}-{}) using CNN:\".format(train_end+1, train_end+12))\n",
    "    future_predictions_reversed = future_predictions * std + mean\n",
    "    print(\"Reversed Predictions for the next 12 periods:\")\n",
    "    print(future_predictions_reversed)\n",
    "    print(\"Predictions for the next 12 periods:\")\n",
    "    print(future_predictions)\n",
    "\n",
    "    # 更新下一个训练集和测试集的起始和结束行数\n",
    "    train_start += 1\n",
    "    train_end += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e43faf",
   "metadata": {},
   "source": [
    "## RNN-GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "dbb22dbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-02T12:11:38.728335Z",
     "start_time": "2023-07-02T09:43:41.426935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 1th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 64, 'kernel_size': 3, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.201444092342051\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Predictions for the next 12 periods (101-112) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[15.4187565]\n",
      " [14.906024 ]\n",
      " [14.766903 ]\n",
      " [14.5663185]\n",
      " [14.535925 ]\n",
      " [14.552016 ]\n",
      " [14.536942 ]\n",
      " [14.316758 ]\n",
      " [14.599759 ]\n",
      " [14.519023 ]\n",
      " [14.962468 ]\n",
      " [14.72116  ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.2061759 ]\n",
      " [-0.28039047]\n",
      " [-0.30052727]\n",
      " [-0.32956043]\n",
      " [-0.33395964]\n",
      " [-0.33163056]\n",
      " [-0.3338126 ]\n",
      " [-0.36568254]\n",
      " [-0.32472017]\n",
      " [-0.33640614]\n",
      " [-0.27222052]\n",
      " [-0.30714822]]\n",
      "This is the 2th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 32, 'kernel_size': 5, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.18934383588182874\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Predictions for the next 12 periods (102-113) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[14.55685  ]\n",
      " [14.564945 ]\n",
      " [14.510456 ]\n",
      " [14.426678 ]\n",
      " [13.9071045]\n",
      " [13.4568205]\n",
      " [13.347105 ]\n",
      " [13.019635 ]\n",
      " [12.617285 ]\n",
      " [12.967544 ]\n",
      " [13.254392 ]\n",
      " [12.894506 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.3309308 ]\n",
      " [-0.3297592 ]\n",
      " [-0.3376462 ]\n",
      " [-0.34977254]\n",
      " [-0.42497715]\n",
      " [-0.4901526 ]\n",
      " [-0.5060332 ]\n",
      " [-0.5534321 ]\n",
      " [-0.6116695 ]\n",
      " [-0.56097203]\n",
      " [-0.51945275]\n",
      " [-0.5715436 ]]\n",
      "This is the 3th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 64, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.19832953839663855\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Predictions for the next 12 periods (103-114) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[12.777905]\n",
      " [12.462642]\n",
      " [12.177713]\n",
      " [12.012801]\n",
      " [12.075268]\n",
      " [12.017134]\n",
      " [11.730841]\n",
      " [11.459521]\n",
      " [11.315923]\n",
      " [11.31032 ]\n",
      " [11.014581]\n",
      " [10.948543]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.58842087]\n",
      " [-0.63405305]\n",
      " [-0.6752944 ]\n",
      " [-0.6991644 ]\n",
      " [-0.6901227 ]\n",
      " [-0.6985373 ]\n",
      " [-0.7399763 ]\n",
      " [-0.7792478 ]\n",
      " [-0.80003273]\n",
      " [-0.8008437 ]\n",
      " [-0.84364986]\n",
      " [-0.8532084 ]]\n",
      "This is the 4th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 32, 'kernel_size': 3, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.20495961655659264\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Predictions for the next 12 periods (104-115) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[16.012869]\n",
      " [16.087738]\n",
      " [16.248356]\n",
      " [16.093287]\n",
      " [15.866475]\n",
      " [15.564107]\n",
      " [15.561031]\n",
      " [15.322334]\n",
      " [15.758174]\n",
      " [15.462803]\n",
      " [15.575054]\n",
      " [15.473642]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.1201822 ]\n",
      " [-0.10934555]\n",
      " [-0.08609722]\n",
      " [-0.10854227]\n",
      " [-0.14137182]\n",
      " [-0.18513745]\n",
      " [-0.1855827 ]\n",
      " [-0.22013235]\n",
      " [-0.15704766]\n",
      " [-0.19980058]\n",
      " [-0.18355298]\n",
      " [-0.19823155]]\n",
      "This is the 5th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 64, 'kernel_size': 5, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.23935169080673355\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Predictions for the next 12 periods (105-116) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[15.146407]\n",
      " [15.172932]\n",
      " [15.22189 ]\n",
      " [15.214886]\n",
      " [15.041063]\n",
      " [14.698043]\n",
      " [14.569035]\n",
      " [14.497408]\n",
      " [14.142512]\n",
      " [13.860986]\n",
      " [13.814313]\n",
      " [13.629917]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.24559662]\n",
      " [-0.24175736]\n",
      " [-0.23467089]\n",
      " [-0.23568487]\n",
      " [-0.26084447]\n",
      " [-0.3104942 ]\n",
      " [-0.32916737]\n",
      " [-0.3395347 ]\n",
      " [-0.39090347]\n",
      " [-0.4316525 ]\n",
      " [-0.43840802]\n",
      " [-0.4650981 ]]\n",
      "This is the 6th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 32, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.21647179433077834\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Predictions for the next 12 periods (106-117) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[14.374051]\n",
      " [14.212248]\n",
      " [14.162889]\n",
      " [14.160199]\n",
      " [14.228096]\n",
      " [14.290627]\n",
      " [13.994555]\n",
      " [13.904071]\n",
      " [13.400696]\n",
      " [13.558132]\n",
      " [13.470738]\n",
      " [13.630128]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.35738978]\n",
      " [-0.38080978]\n",
      " [-0.38795412]\n",
      " [-0.38834336]\n",
      " [-0.3785158 ]\n",
      " [-0.36946496]\n",
      " [-0.41231915]\n",
      " [-0.4254162 ]\n",
      " [-0.49827617]\n",
      " [-0.4754884 ]\n",
      " [-0.48813802]\n",
      " [-0.46506754]]\n",
      "This is the 7th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 64, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.2103507711348583\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (107-118) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[14.020937 ]\n",
      " [13.4592285]\n",
      " [13.839425 ]\n",
      " [13.265007 ]\n",
      " [13.828396 ]\n",
      " [13.391868 ]\n",
      " [13.709738 ]\n",
      " [13.170046 ]\n",
      " [13.54847  ]\n",
      " [12.832375 ]\n",
      " [13.344336 ]\n",
      " [12.565265 ]\n",
      " [13.092556 ]\n",
      " [12.566232 ]\n",
      " [12.704039 ]\n",
      " [12.310762 ]\n",
      " [12.020273 ]\n",
      " [12.219585 ]\n",
      " [11.873128 ]\n",
      " [12.103423 ]\n",
      " [11.944241 ]\n",
      " [11.841009 ]\n",
      " [11.79424  ]\n",
      " [11.657656 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.4085006  -0.4898041 ]\n",
      " [-0.43477324 -0.51791626]\n",
      " [-0.43636963 -0.4995541 ]\n",
      " [-0.45354453 -0.5316613 ]\n",
      " [-0.47688705 -0.5805368 ]\n",
      " [-0.50643396 -0.6191991 ]\n",
      " [-0.54287744 -0.61905915]\n",
      " [-0.59911263 -0.6560365 ]\n",
      " [-0.6980828  -0.66923386]\n",
      " [-0.71938115 -0.6860475 ]\n",
      " [-0.709088   -0.7240302 ]\n",
      " [-0.7307996  -0.75056916]]\n",
      "This is the 8th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 64, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.20982245074985434\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Predictions for the next 12 periods (108-119) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[13.254677]\n",
      " [12.737353]\n",
      " [12.223522]\n",
      " [11.881439]\n",
      " [11.852846]\n",
      " [11.777979]\n",
      " [11.512417]\n",
      " [11.154911]\n",
      " [11.058498]\n",
      " [10.820919]\n",
      " [11.043901]\n",
      " [11.147728]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.51941156]\n",
      " [-0.5942905 ]\n",
      " [-0.66866404]\n",
      " [-0.71817803]\n",
      " [-0.7223167 ]\n",
      " [-0.7331532 ]\n",
      " [-0.7715915 ]\n",
      " [-0.82333803]\n",
      " [-0.83729315]\n",
      " [-0.8716811 ]\n",
      " [-0.8394059 ]\n",
      " [-0.82437766]]\n",
      "This is the 9th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 64, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.20313920420428655\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Predictions for the next 12 periods (109-120) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[11.579716 ]\n",
      " [11.906038 ]\n",
      " [11.401894 ]\n",
      " [11.555855 ]\n",
      " [11.339176 ]\n",
      " [11.066331 ]\n",
      " [11.258343 ]\n",
      " [10.711794 ]\n",
      " [10.878348 ]\n",
      " [10.330498 ]\n",
      " [10.800477 ]\n",
      " [10.2049675]\n",
      " [10.521406 ]\n",
      " [ 9.8315325]\n",
      " [10.040411 ]\n",
      " [ 9.39112  ]\n",
      " [ 9.566757 ]\n",
      " [ 8.869914 ]\n",
      " [ 9.166444 ]\n",
      " [ 8.347018 ]\n",
      " [ 8.711728 ]\n",
      " [ 8.090689 ]\n",
      " [ 8.382013 ]\n",
      " [ 7.865493 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.76185054 -0.71461767]\n",
      " [-0.787589   -0.76530427]\n",
      " [-0.79666704 -0.8361594 ]\n",
      " [-0.8083671  -0.8874762 ]\n",
      " [-0.8633686  -0.9426661 ]\n",
      " [-0.8746399  -0.96083575]\n",
      " [-0.9150334  -1.0148879 ]\n",
      " [-0.9846543  -1.0786346 ]\n",
      " [-1.0532123  -1.1540755 ]\n",
      " [-1.1111549  -1.2297611 ]\n",
      " [-1.1769718  -1.266863  ]\n",
      " [-1.2246958  -1.2994585 ]]\n",
      "This is the 10th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 64, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.1976746280793903\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Predictions for the next 12 periods (110-121) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[13.420235]\n",
      " [13.416269]\n",
      " [13.303063]\n",
      " [13.083986]\n",
      " [12.904247]\n",
      " [12.441835]\n",
      " [12.193463]\n",
      " [11.818668]\n",
      " [11.732374]\n",
      " [11.383474]\n",
      " [11.414236]\n",
      " [11.314257]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.4954482 ]\n",
      " [-0.49602205]\n",
      " [-0.51240784]\n",
      " [-0.5441177 ]\n",
      " [-0.5701338 ]\n",
      " [-0.6370646 ]\n",
      " [-0.6730148 ]\n",
      " [-0.7272637 ]\n",
      " [-0.7397543 ]\n",
      " [-0.7902552 ]\n",
      " [-0.7858025 ]\n",
      " [-0.80027395]]\n",
      "This is the 11th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.22505957095446863\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (111-122) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[14.05854  ]\n",
      " [13.5692215]\n",
      " [12.631624 ]\n",
      " [12.1373825]\n",
      " [11.946836 ]\n",
      " [12.563843 ]\n",
      " [12.6928425]\n",
      " [11.882604 ]\n",
      " [11.5541725]\n",
      " [10.467638 ]\n",
      " [ 9.608554 ]\n",
      " [ 9.356314 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.40305775]\n",
      " [-0.47388327]\n",
      " [-0.6095941 ]\n",
      " [-0.681132  ]\n",
      " [-0.7087124 ]\n",
      " [-0.619405  ]\n",
      " [-0.6007332 ]\n",
      " [-0.7180096 ]\n",
      " [-0.76554763]\n",
      " [-0.92281604]\n",
      " [-1.0471625 ]\n",
      " [-1.0836725 ]]\n",
      "This is the 12th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 64, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.22397265145990009\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (112-123) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[12.515817 ]\n",
      " [14.3691225]\n",
      " [12.38712  ]\n",
      " [14.672606 ]\n",
      " [12.036629 ]\n",
      " [14.849768 ]\n",
      " [11.796423 ]\n",
      " [14.812829 ]\n",
      " [11.444817 ]\n",
      " [14.456343 ]\n",
      " [11.089275 ]\n",
      " [14.304313 ]\n",
      " [10.62338  ]\n",
      " [14.317184 ]\n",
      " [10.519129 ]\n",
      " [14.564778 ]\n",
      " [10.222967 ]\n",
      " [14.769613 ]\n",
      " [ 9.822283 ]\n",
      " [14.984832 ]\n",
      " [ 9.571455 ]\n",
      " [14.4042425]\n",
      " [ 9.496063 ]\n",
      " [13.736389 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.62635636 -0.35810325]\n",
      " [-0.6449843  -0.31417602]\n",
      " [-0.6957156  -0.2885331 ]\n",
      " [-0.7304837  -0.29387975]\n",
      " [-0.78137624 -0.3454786 ]\n",
      " [-0.8328383  -0.36748394]\n",
      " [-0.9002735  -0.3656208 ]\n",
      " [-0.91536313 -0.32978338]\n",
      " [-0.95823056 -0.300135  ]\n",
      " [-1.0162268  -0.26898354]\n",
      " [-1.0525324  -0.35301983]\n",
      " [-1.0634447  -0.4496869 ]]\n",
      "This is the 13th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 64, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.24780235663305122\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (113-124) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[12.718565]\n",
      " [12.002459]\n",
      " [12.559061]\n",
      " [11.848311]\n",
      " [12.190453]\n",
      " [11.758696]\n",
      " [11.829477]\n",
      " [11.538842]\n",
      " [11.503828]\n",
      " [11.46476 ]\n",
      " [11.385512]\n",
      " [11.130367]\n",
      " [10.939228]\n",
      " [10.858931]\n",
      " [10.694336]\n",
      " [10.868137]\n",
      " [10.847624]\n",
      " [10.493071]\n",
      " [10.879839]\n",
      " [10.588806]\n",
      " [10.92174 ]\n",
      " [10.369139]\n",
      " [11.175903]\n",
      " [10.290065]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.5970099  -0.7006615 ]\n",
      " [-0.6200971  -0.7229731 ]\n",
      " [-0.6734505  -0.7359444 ]\n",
      " [-0.7256993  -0.76776665]\n",
      " [-0.7728347  -0.77848953]\n",
      " [-0.7899601  -0.8268906 ]\n",
      " [-0.85455674 -0.86617917]\n",
      " [-0.8900031  -0.8648466 ]\n",
      " [-0.8678158  -0.9191348 ]\n",
      " [-0.86315274 -0.90527785]\n",
      " [-0.85708797 -0.93707323]\n",
      " [-0.8202995  -0.9485186 ]]\n",
      "This is the 14th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 64, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.28119642878801554\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (114-125) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[11.757549 ]\n",
      " [11.827469 ]\n",
      " [11.4118805]\n",
      " [11.715353 ]\n",
      " [10.959515 ]\n",
      " [11.435776 ]\n",
      " [10.58276  ]\n",
      " [11.042992 ]\n",
      " [10.280034 ]\n",
      " [10.705286 ]\n",
      " [10.265938 ]\n",
      " [10.81787  ]\n",
      " [10.162907 ]\n",
      " [11.121042 ]\n",
      " [10.409538 ]\n",
      " [10.889532 ]\n",
      " [10.370718 ]\n",
      " [10.669344 ]\n",
      " [10.265455 ]\n",
      " [10.408945 ]\n",
      " [10.026108 ]\n",
      " [10.521547 ]\n",
      " [10.154491 ]\n",
      " [10.771421 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.7361104  -0.72599   ]\n",
      " [-0.7861434  -0.74221796]\n",
      " [-0.8516203  -0.7826848 ]\n",
      " [-0.906153   -0.83953756]\n",
      " [-0.9499704  -0.8884182 ]\n",
      " [-0.9520108  -0.8721224 ]\n",
      " [-0.9669237  -0.8282402 ]\n",
      " [-0.9312256  -0.86174977]\n",
      " [-0.9368445  -0.89362043]\n",
      " [-0.95208067 -0.93131155]\n",
      " [-0.9867245  -0.9150131 ]\n",
      " [-0.9681419  -0.87884545]]\n",
      "This is the 15th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 64, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.28582264043881284\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Predictions for the next 12 periods (115-126) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[12.114552 ]\n",
      " [11.487606 ]\n",
      " [11.937928 ]\n",
      " [11.059589 ]\n",
      " [11.501135 ]\n",
      " [10.43863  ]\n",
      " [11.343913 ]\n",
      " [10.20385  ]\n",
      " [11.191379 ]\n",
      " [10.376204 ]\n",
      " [11.697424 ]\n",
      " [10.463455 ]\n",
      " [11.569084 ]\n",
      " [10.41098  ]\n",
      " [11.8308735]\n",
      " [10.435913 ]\n",
      " [11.9302845]\n",
      " [10.464247 ]\n",
      " [12.183015 ]\n",
      " [11.112247 ]\n",
      " [12.280226 ]\n",
      " [11.509178 ]\n",
      " [12.248981 ]\n",
      " [11.654726 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.6844367  -0.77518266]\n",
      " [-0.71000177 -0.83713526]\n",
      " [-0.77322453 -0.92701477]\n",
      " [-0.7959813  -0.9609975 ]\n",
      " [-0.8180596  -0.9360505 ]\n",
      " [-0.74481314 -0.92342144]\n",
      " [-0.7633893  -0.9310169 ]\n",
      " [-0.72549725 -0.927408  ]\n",
      " [-0.7111082  -0.923307  ]\n",
      " [-0.67452717 -0.82951325]\n",
      " [-0.66045654 -0.7720604 ]\n",
      " [-0.6649789  -0.7509933 ]]\n",
      "This is the 16th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 64, 'kernel_size': 5, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.303393754807186\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (116-127) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[12.868718 ]\n",
      " [12.868417 ]\n",
      " [12.9977455]\n",
      " [12.8815   ]\n",
      " [12.555216 ]\n",
      " [12.481248 ]\n",
      " [12.345935 ]\n",
      " [12.637724 ]\n",
      " [12.659815 ]\n",
      " [12.61845  ]\n",
      " [12.046057 ]\n",
      " [11.902506 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.5752763 ]\n",
      " [-0.57532   ]\n",
      " [-0.55660045]\n",
      " [-0.5734262 ]\n",
      " [-0.62065357]\n",
      " [-0.63135993]\n",
      " [-0.6509456 ]\n",
      " [-0.60871124]\n",
      " [-0.60551363]\n",
      " [-0.6115008 ]\n",
      " [-0.6943509 ]\n",
      " [-0.71512896]]\n",
      "This is the 17th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 32, 'kernel_size': 3, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.33317817579857734\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (117-128) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[14.303137]\n",
      " [14.271495]\n",
      " [14.165395]\n",
      " [14.437441]\n",
      " [14.355623]\n",
      " [14.423481]\n",
      " [14.083155]\n",
      " [13.310172]\n",
      " [12.749304]\n",
      " [12.849583]\n",
      " [12.493849]\n",
      " [11.249298]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.3676542 ]\n",
      " [-0.37223408]\n",
      " [-0.38759142]\n",
      " [-0.3482146 ]\n",
      " [-0.36005712]\n",
      " [-0.3502352 ]\n",
      " [-0.39949504]\n",
      " [-0.5113789 ]\n",
      " [-0.59256077]\n",
      " [-0.5780461 ]\n",
      " [-0.62953603]\n",
      " [-0.8096762 ]]\n",
      "This is the 18th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 64, 'kernel_size': 3, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.39262815964881204\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "Predictions for the next 12 periods (118-129) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[16.838192]\n",
      " [16.988327]\n",
      " [17.129795]\n",
      " [17.09314 ]\n",
      " [17.242537]\n",
      " [16.952082]\n",
      " [16.97297 ]\n",
      " [16.810286]\n",
      " [17.37501 ]\n",
      " [17.412148]\n",
      " [17.374388]\n",
      " [16.976007]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.00072253]\n",
      " [ 0.02100843]\n",
      " [ 0.04148511]\n",
      " [ 0.0361793 ]\n",
      " [ 0.05780363]\n",
      " [ 0.01576216]\n",
      " [ 0.01878564]\n",
      " [-0.00476162]\n",
      " [ 0.07697819]\n",
      " [ 0.0823537 ]\n",
      " [ 0.07688807]\n",
      " [ 0.01922543]]\n",
      "This is the 19th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 5, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.45550185868876286\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Predictions for the next 12 periods (119-130) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[24.239616]\n",
      " [23.281937]\n",
      " [23.30213 ]\n",
      " [22.092854]\n",
      " [21.358442]\n",
      " [20.116901]\n",
      " [19.753906]\n",
      " [19.333899]\n",
      " [19.36206 ]\n",
      " [19.08052 ]\n",
      " [18.232357]\n",
      " [17.957048]]\n",
      "Predictions for the next 12 periods:\n",
      "[[1.0705823 ]\n",
      " [0.93196493]\n",
      " [0.9348877 ]\n",
      " [0.7598535 ]\n",
      " [0.6535524 ]\n",
      " [0.4738481 ]\n",
      " [0.42130697]\n",
      " [0.3605138 ]\n",
      " [0.36458993]\n",
      " [0.32383913]\n",
      " [0.2010732 ]\n",
      " [0.16122416]]\n",
      "This is the 20th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 32, 'kernel_size': 3, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.4599373144832599\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (120-131) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[20.773521]\n",
      " [18.479176]\n",
      " [21.183508]\n",
      " [18.208874]\n",
      " [21.903645]\n",
      " [18.29798 ]\n",
      " [22.08244 ]\n",
      " [17.722273]\n",
      " [21.722834]\n",
      " [17.364698]\n",
      " [21.71426 ]\n",
      " [16.726048]\n",
      " [21.814983]\n",
      " [16.615648]\n",
      " [21.91599 ]\n",
      " [15.991123]\n",
      " [21.877247]\n",
      " [15.359974]\n",
      " [21.553541]\n",
      " [14.813615]\n",
      " [21.306192]\n",
      " [14.658827]\n",
      " [20.633226]\n",
      " [14.395418]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 0.56888914  0.23679839]\n",
      " [ 0.6282318   0.19767427]\n",
      " [ 0.73246664  0.21057153]\n",
      " [ 0.75834614  0.12724203]\n",
      " [ 0.70629555  0.07548565]\n",
      " [ 0.7050545  -0.01695454]\n",
      " [ 0.71963364 -0.03293404]\n",
      " [ 0.7342538  -0.12332988]\n",
      " [ 0.7286458  -0.21468425]\n",
      " [ 0.6817917  -0.29376605]\n",
      " [ 0.64598954 -0.31617054]\n",
      " [ 0.5485824  -0.354297  ]]\n",
      "This is the 21th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.4728995966816953\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Predictions for the next 12 periods (121-132) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[ 8.993756 ]\n",
      " [ 8.768576 ]\n",
      " [ 7.9778357]\n",
      " [ 7.578184 ]\n",
      " [ 7.5574007]\n",
      " [ 8.45456  ]\n",
      " [ 9.359442 ]\n",
      " [10.61868  ]\n",
      " [11.0780735]\n",
      " [11.224625 ]\n",
      " [12.047169 ]\n",
      " [14.08274  ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-1.1361502 ]\n",
      " [-1.1687435 ]\n",
      " [-1.2831978 ]\n",
      " [-1.3410444 ]\n",
      " [-1.3440528 ]\n",
      " [-1.2141951 ]\n",
      " [-1.0832199 ]\n",
      " [-0.90095377]\n",
      " [-0.8344598 ]\n",
      " [-0.81324744]\n",
      " [-0.6941899 ]\n",
      " [-0.3995551 ]]\n",
      "This is the 22th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 3, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.5308040125545558\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Predictions for the next 12 periods (122-133) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[18.48846 ]\n",
      " [19.301111]\n",
      " [19.23189 ]\n",
      " [20.004217]\n",
      " [20.417164]\n",
      " [20.689955]\n",
      " [20.564743]\n",
      " [20.486929]\n",
      " [20.282495]\n",
      " [20.18735 ]\n",
      " [19.928764]\n",
      " [19.113266]]\n",
      "Predictions for the next 12 periods:\n",
      "[[0.23814243]\n",
      " [0.35576802]\n",
      " [0.3457486 ]\n",
      " [0.45753783]\n",
      " [0.517309  ]\n",
      " [0.5567936 ]\n",
      " [0.5386698 ]\n",
      " [0.527407  ]\n",
      " [0.49781668]\n",
      " [0.48404476]\n",
      " [0.44661632]\n",
      " [0.3285788 ]]\n",
      "This is the 23th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 5, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.5362550798848458\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Predictions for the next 12 periods (123-134) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[15.824223 ]\n",
      " [15.650443 ]\n",
      " [14.991365 ]\n",
      " [14.267709 ]\n",
      " [13.9592   ]\n",
      " [13.928557 ]\n",
      " [14.132459 ]\n",
      " [13.36027  ]\n",
      " [12.82728  ]\n",
      " [13.552358 ]\n",
      " [14.5734005]\n",
      " [15.521739 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.14748748]\n",
      " [-0.17264096]\n",
      " [-0.26803786]\n",
      " [-0.37278217]\n",
      " [-0.41743657]\n",
      " [-0.4218719 ]\n",
      " [-0.3923587 ]\n",
      " [-0.5041276 ]\n",
      " [-0.58127415]\n",
      " [-0.4763242 ]\n",
      " [-0.32853544]\n",
      " [-0.19126993]]\n",
      "This is the 24th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 3, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.4790026921992738\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Predictions for the next 12 periods (124-135) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[10.834684 ]\n",
      " [ 9.583158 ]\n",
      " [ 9.659818 ]\n",
      " [ 9.497988 ]\n",
      " [ 9.353668 ]\n",
      " [ 7.693431 ]\n",
      " [ 7.4112387]\n",
      " [ 7.8962784]\n",
      " [ 9.072924 ]\n",
      " [10.1950035]\n",
      " [10.898207 ]\n",
      " [11.594519 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.8696886 ]\n",
      " [-1.0508385 ]\n",
      " [-1.0397425 ]\n",
      " [-1.0631663 ]\n",
      " [-1.0840554 ]\n",
      " [-1.3243634 ]\n",
      " [-1.3652087 ]\n",
      " [-1.2950026 ]\n",
      " [-1.1246914 ]\n",
      " [-0.96227795]\n",
      " [-0.8604942 ]\n",
      " [-0.75970787]]\n",
      "This is the 25th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.39869678983390544\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Predictions for the next 12 periods (125-136) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[18.329077]\n",
      " [17.66468 ]\n",
      " [16.51612 ]\n",
      " [16.236143]\n",
      " [15.448134]\n",
      " [14.320893]\n",
      " [13.624411]\n",
      " [12.680759]\n",
      " [12.47172 ]\n",
      " [13.006794]\n",
      " [13.436866]\n",
      " [13.689469]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 0.21507274]\n",
      " [ 0.11890599]\n",
      " [-0.04734007]\n",
      " [-0.08786483]\n",
      " [-0.2019237 ]\n",
      " [-0.36508405]\n",
      " [-0.46589512]\n",
      " [-0.602482  ]\n",
      " [-0.6327391 ]\n",
      " [-0.5552908 ]\n",
      " [-0.49304086]\n",
      " [-0.45647833]]\n",
      "This is the 26th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 16, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.3066871353126973\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "Predictions for the next 12 periods (126-137) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[18.880138]\n",
      " [19.50158 ]\n",
      " [19.44374 ]\n",
      " [18.911901]\n",
      " [20.58682 ]\n",
      " [18.260141]\n",
      " [21.444752]\n",
      " [17.150442]\n",
      " [21.436108]\n",
      " [16.37882 ]\n",
      " [21.087677]\n",
      " [15.980583]\n",
      " [20.457508]\n",
      " [15.826966]\n",
      " [20.96206 ]\n",
      " [15.763866]\n",
      " [20.762741]\n",
      " [16.058277]\n",
      " [19.960758]\n",
      " [16.651197]\n",
      " [19.390337]\n",
      " [16.329529]\n",
      " [19.367504]\n",
      " [16.05655 ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[ 0.29483512  0.38478425]\n",
      " [ 0.37641257  0.2994326 ]\n",
      " [ 0.54186565  0.20509493]\n",
      " [ 0.6660451   0.04447355]\n",
      " [ 0.664794   -0.06721325]\n",
      " [ 0.6143609  -0.12485535]\n",
      " [ 0.52314854 -0.14709038]\n",
      " [ 0.5961789  -0.15622365]\n",
      " [ 0.56732875 -0.11360978]\n",
      " [ 0.45124736 -0.02778866]\n",
      " [ 0.36868277 -0.07434807]\n",
      " [ 0.36537796 -0.11385982]]\n",
      "This is the 27th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 3, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.3292263078731087\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (127-138) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[21.112047]\n",
      " [21.644169]\n",
      " [21.898966]\n",
      " [22.575075]\n",
      " [23.212633]\n",
      " [23.350084]\n",
      " [23.878227]\n",
      " [24.662233]\n",
      " [25.192043]\n",
      " [25.004665]\n",
      " [24.96714 ]\n",
      " [25.603796]]\n",
      "Predictions for the next 12 periods:\n",
      "[[0.61788845]\n",
      " [0.6949095 ]\n",
      " [0.73178947]\n",
      " [0.8296517 ]\n",
      " [0.92193377]\n",
      " [0.94182885]\n",
      " [1.0182737 ]\n",
      " [1.1317533 ]\n",
      " [1.2084398 ]\n",
      " [1.1813178 ]\n",
      " [1.1758863 ]\n",
      " [1.2680379 ]]\n",
      "This is the 28th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 5, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.34591830876103324\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (128-139) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[19.893879]\n",
      " [19.731   ]\n",
      " [20.497414]\n",
      " [20.616909]\n",
      " [19.956879]\n",
      " [19.040287]\n",
      " [18.833733]\n",
      " [18.88585 ]\n",
      " [19.099077]\n",
      " [18.703493]\n",
      " [18.751425]\n",
      " [18.558937]]\n",
      "Predictions for the next 12 periods:\n",
      "[[0.44156703]\n",
      " [0.41799146]\n",
      " [0.5289246 ]\n",
      " [0.54622054]\n",
      " [0.45068595]\n",
      " [0.31801564]\n",
      " [0.28811818]\n",
      " [0.29566208]\n",
      " [0.32652488]\n",
      " [0.2692668 ]\n",
      " [0.27620476]\n",
      " [0.24834354]]\n",
      "This is the 29th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 64, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.3846112508013143\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (129-140) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[21.724571]\n",
      " [23.117943]\n",
      " [21.322077]\n",
      " [23.277075]\n",
      " [21.30509 ]\n",
      " [22.97893 ]\n",
      " [21.405087]\n",
      " [22.85394 ]\n",
      " [20.941143]\n",
      " [23.237957]\n",
      " [20.790873]\n",
      " [23.146189]\n",
      " [20.602543]\n",
      " [22.555187]\n",
      " [20.066532]\n",
      " [22.40673 ]\n",
      " [19.888851]\n",
      " [22.119177]\n",
      " [19.409254]\n",
      " [22.559284]\n",
      " [19.14391 ]\n",
      " [22.920746]]\n",
      "Predictions for the next 12 periods:\n",
      "[[0.706547   0.9082278 ]\n",
      " [0.6482888  0.93126124]\n",
      " [0.64583015 0.8881068 ]\n",
      " [0.6603039  0.8700153 ]\n",
      " [0.59315115 0.9255992 ]\n",
      " [0.57140064 0.91231626]\n",
      " [0.54414123 0.8267728 ]\n",
      " [0.4665573  0.8052849 ]\n",
      " [0.44083926 0.7636636 ]\n",
      " [0.37142104 0.8273659 ]\n",
      " [0.33301404 0.8796849 ]]\n",
      "This is the 30th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 16, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.4613546682269819\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (130-141) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[27.671967]\n",
      " [28.395472]\n",
      " [27.336176]\n",
      " [29.227291]\n",
      " [28.102882]\n",
      " [28.068716]\n",
      " [28.955782]\n",
      " [27.582409]\n",
      " [28.64177 ]\n",
      " [27.156921]\n",
      " [28.156712]\n",
      " [26.907755]\n",
      " [27.507235]\n",
      " [27.920767]\n",
      " [26.602661]\n",
      " [27.996702]\n",
      " [26.286762]\n",
      " [27.786068]\n",
      " [26.555058]\n",
      " [26.785923]]\n",
      "Predictions for the next 12 periods:\n",
      "[[1.5673913 1.6721137]\n",
      " [1.518788  1.792514 ]\n",
      " [1.6297636 1.6248181]\n",
      " [1.7532147 1.5544283]\n",
      " [1.7077636 1.492842 ]\n",
      " [1.637555  1.456777 ]\n",
      " [1.5435475 1.6034034]\n",
      " [1.4126168 1.6143945]\n",
      " [1.3668925 1.5839067]\n",
      " [1.4057266 1.4391426]]\n",
      "This is the 31th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 32, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.48190586599710555\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "Predictions for the next 12 periods (131-142) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[26.580067]\n",
      " [26.802813]\n",
      " [27.143513]\n",
      " [27.67926 ]\n",
      " [27.367584]\n",
      " [26.779837]\n",
      " [26.035645]\n",
      " [25.8657  ]\n",
      " [26.072481]]\n",
      "Predictions for the next 12 periods:\n",
      "[[1.4093465]\n",
      " [1.4415873]\n",
      " [1.4909014]\n",
      " [1.5684469]\n",
      " [1.5233341]\n",
      " [1.4382617]\n",
      " [1.3305451]\n",
      " [1.3059467]\n",
      " [1.335877 ]]\n",
      "This is the 32th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.46285157824252166\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Predictions for the next 12 periods (132-143) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[19.30918 ]\n",
      " [19.345   ]\n",
      " [18.79876 ]\n",
      " [18.546871]\n",
      " [17.77983 ]\n",
      " [17.369228]\n",
      " [17.09211 ]\n",
      " [17.308084]]\n",
      "Predictions for the next 12 periods:\n",
      "[[0.35693577]\n",
      " [0.36212057]\n",
      " [0.283056  ]\n",
      " [0.24659711]\n",
      " [0.1355731 ]\n",
      " [0.07614128]\n",
      " [0.0360304 ]\n",
      " [0.06729111]]\n",
      "This is the 33th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 64, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.6071343723504855\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Predictions for the next 12 periods (133-144) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[23.77834 ]\n",
      " [20.20745 ]\n",
      " [23.55566 ]\n",
      " [20.700075]\n",
      " [23.568825]\n",
      " [21.072159]\n",
      " [23.803997]\n",
      " [21.443289]\n",
      " [23.791786]\n",
      " [21.419964]\n",
      " [23.74422 ]\n",
      " [21.676666]\n",
      " [23.491156]\n",
      " [21.923208]]\n",
      "Predictions for the next 12 periods:\n",
      "[[1.0038158  0.4869545 ]\n",
      " [0.9715845  0.5582583 ]\n",
      " [0.97349    0.6121147 ]\n",
      " [1.0075294  0.66583335]\n",
      " [1.0057622  0.6624572 ]\n",
      " [0.9988774  0.69961303]\n",
      " [0.96224785 0.7352984 ]]\n",
      "This is the 34th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 32, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.4325631976303277\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Predictions for the next 12 periods (134-145) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[21.55546 ]\n",
      " [20.04677 ]\n",
      " [20.623013]\n",
      " [19.541441]\n",
      " [20.729918]\n",
      " [19.471313]\n",
      " [20.741446]\n",
      " [19.184147]\n",
      " [20.56728 ]\n",
      " [19.020613]\n",
      " [20.086498]\n",
      " [18.882349]]\n",
      "Predictions for the next 12 periods:\n",
      "[[0.6820693  0.46369696]\n",
      " [0.5471041  0.39055407]\n",
      " [0.5625779  0.38040358]\n",
      " [0.5642465  0.3388381 ]\n",
      " [0.53903705 0.3151679 ]\n",
      " [0.46944723 0.29515505]]\n",
      "This is the 35th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 3, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.3999585878060964\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (135-146) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[16.317762]\n",
      " [15.307753]\n",
      " [14.36105 ]\n",
      " [14.755427]\n",
      " [14.860073]]\n",
      "Predictions for the next 12 periods:\n",
      "[[-0.07605096]\n",
      " [-0.22224297]\n",
      " [-0.3592717 ]\n",
      " [-0.30218822]\n",
      " [-0.28704157]]\n",
      "This is the 36th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 5, 'pool_size': 4}\n",
      "Average RMSE (CV) 0.3909327224514966\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (136-147) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[21.112022]\n",
      " [20.415646]\n",
      " [20.726715]\n",
      " [20.910645]]\n",
      "Predictions for the next 12 periods:\n",
      "[[0.6178847 ]\n",
      " [0.51708907]\n",
      " [0.56211436]\n",
      " [0.58873695]]\n",
      "This is the 37th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 64, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.43719850797477033\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "Predictions for the next 12 periods (137-148) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[23.855175]\n",
      " [23.337767]\n",
      " [23.2767  ]]\n",
      "Predictions for the next 12 periods:\n",
      "[[1.0149373 ]\n",
      " [0.940046  ]\n",
      " [0.93120676]]\n",
      "This is the 38th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 16, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.580443625638284\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "Predictions for the next 12 periods (138-149) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[19.075953]\n",
      " [19.260609]]\n",
      "Predictions for the next 12 periods:\n",
      "[[0.32317775]\n",
      " [0.34990546]]\n",
      "This is the 39th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 2, 'filters': 64, 'kernel_size': 3, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.6425425929564689\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predictions for the next 12 periods (139-150) using CNN:\n",
      "Reversed Predictions for the next 12 periods:\n",
      "[[24.347992]\n",
      " [25.872555]]\n",
      "Predictions for the next 12 periods:\n",
      "[[1.086269  1.3069389]]\n",
      "This is the 40th loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14458\\AppData\\Local\\Temp\\ipykernel_12920\\3896341482.py:43: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_units': 1, 'filters': 64, 'kernel_size': 5, 'pool_size': 2}\n",
      "Average RMSE (CV) 0.5810108067590412\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[292], line 89\u001b[0m\n\u001b[0;32m     87\u001b[0m future_X \u001b[38;5;241m=\u001b[39m X_final_data_feature_lag12_cnn\u001b[38;5;241m.\u001b[39miloc[train_end:train_end\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m12\u001b[39m, :]\n\u001b[0;32m     88\u001b[0m future_X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(future_X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 89\u001b[0m future_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# 将预测结果添加到evaluation_results中\u001b[39;00m\n\u001b[0;32m     92\u001b[0m evaluation_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m: future_predictions\n\u001b[0;32m     95\u001b[0m })\n",
      "File \u001b[1;32mD:\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:2278\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2274\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(\n\u001b[0;32m   2275\u001b[0m                     end_step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs}\n\u001b[0;32m   2276\u001b[0m                 )\n\u001b[0;32m   2277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected result of `predict_function` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2280\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Empty batch_outputs). Please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2281\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2282\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2284\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2285\u001b[0m         )\n\u001b[0;32m   2286\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[0;32m   2287\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure_up_to(\n\u001b[0;32m   2288\u001b[0m     batch_outputs, potentially_ragged_concat, outputs\n\u001b[0;32m   2289\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "#tf.config.run_functions_eagerly(True) #这一行代码是用来修正这一段最后的报错原因的，该错误通常与TensorFlow的eager execution（即即时执行模式）有关，如果错误还未解决，则需要与tf.keras的开发者联系。\n",
    "#我没有再跑一遍的原因是因为这个耗时太大了，时间不够我再跑一遍。\n",
    "\n",
    "# 构建CNN模型\n",
    "def create_model(filters=32, kernel_size=3, pool_size=2, dense_units=1):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# 定义训练集和测试集的起始和结束行数\n",
    "train_start = 12\n",
    "train_end = 100\n",
    "test_start = 101\n",
    "test_end = 151\n",
    "\n",
    "# 创建空列表存储评估结果\n",
    "evaluation_results = []\n",
    "\n",
    "# 循环训练和预测过程\n",
    "while train_end <= test_end:\n",
    "    # 打印循环次数\n",
    "    print(\"This is the {}th loop.\".format(train_start - 11))\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train = X_final_data_feature_lag12_cnn.iloc[train_start:train_end, :]\n",
    "    y_train = y_final_data_feature_lag12_cnn.iloc[train_start:train_end, :]\n",
    "    X_test = X_final_data_feature_lag12_cnn.iloc[test_start:test_end, :]\n",
    "    y_test = y_final_data_feature_lag12_cnn.iloc[test_start:test_end, :]\n",
    "\n",
    "    # 将训练集转换为3D张量\n",
    "    X_train = np.expand_dims(X_train, axis=2)\n",
    "\n",
    "    # 创建KerasRegressor模型\n",
    "    model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "    # 定义参数网格\n",
    "    param_grid = {\n",
    "        'filters': [16, 32, 64],\n",
    "        'kernel_size': [3, 5],\n",
    "        'pool_size': [2, 4],\n",
    "        'dense_units': [1, 2]\n",
    "    }\n",
    "\n",
    "    # 创建GridSearchCV对象\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(n_splits=10))\n",
    "\n",
    "    # 执行网格搜索\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 输出最佳参数组合\n",
    "    print(\"Best Parameters: \", grid_result.best_params_)\n",
    "\n",
    "    # 使用最佳参数训练模型\n",
    "    best_model = grid_result.best_estimator_.model\n",
    "    \n",
    "    # 10折交叉验证\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_scores = []\n",
    "\n",
    "    for train_index, val_index in kfold.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # 拟合模型\n",
    "        model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "        # 在验证集上进行预测\n",
    "        val_predictions = model.predict(X_val_fold)\n",
    "\n",
    "        # 计算验证集的RMSE得分\n",
    "        fold_score = mean_absolute_error(y_val_fold, val_predictions)\n",
    "        cv_scores.append(fold_score)\n",
    "\n",
    "    # 打印交叉验证的平均RMSE得分\n",
    "    print('Average RMSE (CV)', np.mean(cv_scores))\n",
    "    \n",
    "    # 预测未来12期\n",
    "    future_X = X_final_data_feature_lag12_cnn.iloc[train_end:train_end+12, :]\n",
    "    future_X = np.expand_dims(future_X, axis=2)\n",
    "    future_predictions = best_model.predict(future_X)\n",
    "\n",
    "    # 将预测结果添加到evaluation_results中\n",
    "    evaluation_results.append({\n",
    "        \"Model\": \"CNN\",\n",
    "        \"Predictions\": future_predictions\n",
    "    })\n",
    "    \n",
    "    mean = raw_data[\"Hog prices\"].mean()\n",
    "    std = raw_data[\"Hog prices\"].std()\n",
    "\n",
    "    # 打印预测结果\n",
    "    # Reverse standardization and print the predictions\n",
    "    print(\"Predictions for the next 12 periods ({}-{}) using CNN:\".format(train_end+1, train_end+12))\n",
    "#     future_predictions_reversed = future_predictions * std + mean\n",
    "    future_predictions_reversed = future_predictions.reshape(-1, 1) * std + mean\n",
    "    print(\"Reversed Predictions for the next 12 periods:\")\n",
    "    print(future_predictions_reversed)\n",
    "    print(\"Predictions for the next 12 periods:\")\n",
    "    print(future_predictions)\n",
    "\n",
    "    # 更新下一个训练集和测试集的起始和结束行数\n",
    "    train_start += 1\n",
    "    train_end += 1\n",
    "    test_start += 1\n",
    "    test_end += 1\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow(myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
